{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# get the value of the environment variable $TMPDIR\n",
    "tmp_dir = os.environ['TMPDIR']\n",
    "print(tmp_dir)\n",
    "\n",
    "os.makedirs(f'{tmp_dir}/FAUST_r/diffusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import my_code.datasets.shape_dataset as shape_dataset\n",
    "import my_code.datasets.template_dataset as template_dataset\n",
    "\n",
    "\n",
    "\n",
    "dataset_single = shape_dataset.SingleFaustDataset(\n",
    "    phase='train',\n",
    "    data_root = 'data_with_smpl_corr/FAUST_r',\n",
    "    centering = 'bbox',\n",
    "    num_evecs=128,\n",
    "    # lb_cache_dir=f'/home/s94zalek_hpc/shape_matching/data_with_smpl_corr/FAUST_r/diffusion'\n",
    "    lb_cache_dir=f'{tmp_dir}/FAUST_r/diffusion'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'C_gt_xy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      6\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m plotting_utils\u001b[38;5;241m.\u001b[39mplot_Cxy(fig, axs[\u001b[38;5;241m0\u001b[39m], \u001b[43mdataset_single\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m55\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC_gt_xy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      9\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_xy 55\u001b[39m\u001b[38;5;124m'\u001b[39m, l, h, show_grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, show_colorbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m plotting_utils\u001b[38;5;241m.\u001b[39mplot_Cxy(fig, axs[\u001b[38;5;241m1\u001b[39m], dataset_single[\u001b[38;5;241m67\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_gt_xy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     11\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_xy 67\u001b[39m\u001b[38;5;124m'\u001b[39m, l, h, show_grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, show_colorbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m plotting_utils\u001b[38;5;241m.\u001b[39mplot_Cxy(fig, axs[\u001b[38;5;241m2\u001b[39m], dataset_single[\u001b[38;5;241m78\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_gt_xy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     13\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_xy 78\u001b[39m\u001b[38;5;124m'\u001b[39m, l, h, show_grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, show_colorbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'C_gt_xy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "l = 0\n",
    "h = 32\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0], dataset_single[55]['C_gt_xy'][0],\n",
    "                        'C_xy 55', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1], dataset_single[67]['C_gt_xy'][0],\n",
    "                        'C_xy 67', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[2], dataset_single[78]['C_gt_xy'][0],\n",
    "                        'C_xy 78', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networks.diffusion_network as diffusion_network\n",
    "\n",
    "condition_dim = 0\n",
    "start_dim = 0\n",
    "\n",
    "feature_dim = 32\n",
    "evecs_per_support = 4\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = diffusion_network.DiffusionNet(\n",
    "    in_channels=feature_dim,\n",
    "    out_channels=feature_dim // evecs_per_support,\n",
    "    cache_dir=None,\n",
    "    input_type='wks',\n",
    "    k_eig=64,\n",
    "    n_block=6\n",
    "    ).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "# add scheduler, decay by 0.1 every 30k iterations\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(opt, start_factor=1, end_factor=0.1, total_iters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/notebooks/19.06.2024/sign_double_start_0_feat_64.pth'))\n",
    "# net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/notebooks/03.07.2024/sign_double_start_0_feat_64_180xyz_scaling_09_11.pth'))\n",
    "# net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_double_start_0_feat_64_6block_factor4_180xyz_09_11_wks/39360.pth'))\n",
    "# net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_double_start_0_feat_64_6block_factor4_180xyz_09_11_noise0.01_meshLapl/39360.pth'))\n",
    "\n",
    "\n",
    "input_type = 'wks'\n",
    "net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_double_start_0_feat_32_6block_factor4_dataset_SURREAL_train_rot_180_180_180_normal_True_noise_0.0_-0.05_0.05_lapl_mesh_scale_0.9_1.1_wks/40000.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc4ffeb1c4844858c701a2ac1ac029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# predict the sign change\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 72\u001b[0m     sign_pred_1, supp_vec_1, _ \u001b[38;5;241m=\u001b[39m \u001b[43msign_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_sign_change\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevecs_flip_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevecs_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m##############################################\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Calculate the loss\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m##############################################\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# calculate the ground truth sign difference\u001b[39;00m\n\u001b[1;32m     80\u001b[0m sign_diff_gt \u001b[38;5;241m=\u001b[39m sign_gt_1 \u001b[38;5;241m*\u001b[39m sign_gt_0\n",
      "File \u001b[0;32m~/shape_matching/my_code/sign_canonicalization/training.py:32\u001b[0m, in \u001b[0;36mpredict_sign_change\u001b[0;34m(net, verts, faces, evecs_flip, evecs_cond, input_type)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# process the flipped evecs\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m support_vector_flip \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevecs_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [1 x 6890 x 1]\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# normalize the support vector\u001b[39;00m\n\u001b[1;32m     39\u001b[0m support_vector_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(support_vector_flip, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/shape_matching/networks/diffusion_network.py:346\u001b[0m, in \u001b[0;36mDiffusionNet.forward\u001b[0;34m(self, verts, faces, feats)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# ensure reproducibility to first convert to cpu to find the precomputed spectral ops\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m faces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 346\u001b[0m     _, mass, L, evals, evecs, gradX, gradY \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_operators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_eig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     _, mass, L, evals, evecs, gradX, gradY \u001b[38;5;241m=\u001b[39m get_all_operators(verts\u001b[38;5;241m.\u001b[39mcpu(), \u001b[38;5;28;01mNone\u001b[39;00m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_eig,\n\u001b[1;32m    350\u001b[0m                                                                cache_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_dir)\n",
      "File \u001b[0;32m~/shape_matching/utils/geometry_util.py:795\u001b[0m, in \u001b[0;36mget_all_operators\u001b[0;34m(verts, faces, k, normals, cache_dir)\u001b[0m\n\u001b[1;32m    793\u001b[0m         output \u001b[38;5;241m=\u001b[39m get_operators(verts[i], faces[i], k, normals[i], cache_dir)\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 795\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mget_operators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m normals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/shape_matching/utils/geometry_util.py:714\u001b[0m, in \u001b[0;36mget_operators\u001b[0;34m(verts, faces, k, normals, cache_dir, overwrite_cache)\u001b[0m\n\u001b[1;32m    712\u001b[0m evecs \u001b[38;5;241m=\u001b[39m npzfile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevecs\u001b[39m\u001b[38;5;124m'\u001b[39m][:, :k]\n\u001b[1;32m    713\u001b[0m gradX \u001b[38;5;241m=\u001b[39m read_sp_mat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 714\u001b[0m gradY \u001b[38;5;241m=\u001b[39m \u001b[43mread_sp_mat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgradY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m frames \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(frames)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    717\u001b[0m mass \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mass)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/shape_matching/utils/geometry_util.py:702\u001b[0m, in \u001b[0;36mget_operators.<locals>.read_sp_mat\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m    700\u001b[0m data \u001b[38;5;241m=\u001b[39m npzfile[prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    701\u001b[0m indices \u001b[38;5;241m=\u001b[39m npzfile[prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_indices\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 702\u001b[0m indptr \u001b[38;5;241m=\u001b[39m \u001b[43mnpzfile\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_indptr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    703\u001b[0m shape \u001b[38;5;241m=\u001b[39m npzfile[prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_shape\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    704\u001b[0m mat \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsc_matrix((data, indices, indptr), shape\u001b[38;5;241m=\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/numpy/lib/npyio.py:245\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/numpy/lib/format.py:731\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    729\u001b[0m version \u001b[38;5;241m=\u001b[39m read_magic(fp)\n\u001b[1;32m    730\u001b[0m _check_version(version)\n\u001b[0;32m--> 731\u001b[0m shape, fortran_order, dtype \u001b[38;5;241m=\u001b[39m \u001b[43m_read_array_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    733\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/numpy/lib/format.py:594\u001b[0m, in \u001b[0;36m_read_array_header\u001b[0;34m(fp, version)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# The header is a pretty-printed string representation of a literal\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# Python dictionary with trailing newlines padded to a ARRAY_ALIGN byte\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# boundary. The keys are strings.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# Versions (2, 0) and (1, 0) could have been created by a Python 2\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# implementation before header filtering was implemented.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 594\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[43m_filter_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    596\u001b[0m     d \u001b[38;5;241m=\u001b[39m safe_eval(header)\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/numpy/lib/format.py:555\u001b[0m, in \u001b[0;36m_filter_header\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    553\u001b[0m tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    554\u001b[0m last_token_was_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokenize\u001b[38;5;241m.\u001b[39mgenerate_tokens(StringIO(s)\u001b[38;5;241m.\u001b[39mreadline):\n\u001b[1;32m    556\u001b[0m     token_type \u001b[38;5;241m=\u001b[39m token[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    557\u001b[0m     token_string \u001b[38;5;241m=\u001b[39m token[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/tokenize.py:525\u001b[0m, in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    522\u001b[0m     continued \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m pos \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mmax\u001b[39m:\n\u001b[0;32m--> 525\u001b[0m     pseudomatch \u001b[38;5;241m=\u001b[39m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPseudoToken\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pseudomatch:                                \u001b[38;5;66;03m# scan for tokens\u001b[39;00m\n\u001b[1;32m    527\u001b[0m         start, end \u001b[38;5;241m=\u001b[39m pseudomatch\u001b[38;5;241m.\u001b[39mspan(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import utils.geometry_util as geometry_util\n",
    "import robust_laplacian\n",
    "import scipy.sparse.linalg as sla\n",
    "import utils.geometry_util as geometry_util\n",
    "import my_code.sign_canonicalization.training as sign_training\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "# shapes_to_test = test_shapes\n",
    "# net.cache_dir = test_diff_folder\n",
    "\n",
    "net.cache_dir = dataset_single.lb_cache_dir\n",
    "           \n",
    "              \n",
    "iterator = tqdm(range(1000))\n",
    "incorrect_signs_list = torch.tensor([])\n",
    "curr_iter = 0\n",
    "\n",
    "for epoch in range(len(iterator) // len(dataset_single)):\n",
    "    \n",
    "    # train_shapes_shuffled = train_shapes.copy()\n",
    "    # np.random.shuffle(test_shapes_list)\n",
    "    \n",
    "    \n",
    "    for curr_idx in range(20):     \n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        # Select a shape\n",
    "        ##############################################\n",
    "        \n",
    "        test_shape = dataset_single[curr_idx]    \n",
    "        \n",
    "        verts = test_shape['verts'].unsqueeze(0).to(device)\n",
    "        faces = test_shape['faces'].unsqueeze(0).to(device)\n",
    "        evecs_orig = test_shape['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "\n",
    "        ##############################################\n",
    "        # Set the signs on shape 0\n",
    "        ##############################################\n",
    "\n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_0 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_0[sign_gt_0 == 0] = -1\n",
    "        sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_0, supp_vec_0, _ = sign_training.predict_sign_change(\n",
    "                net, verts, faces, evecs_flip_0, evecs_cond=None, input_type=input_type)\n",
    "        \n",
    "        ##############################################\n",
    "        # Set the signs on shape 1\n",
    "        ##############################################\n",
    "        \n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_1 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_1[sign_gt_1 == 0] = -1\n",
    "        sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "        \n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_1, supp_vec_1, _ = sign_training.predict_sign_change(\n",
    "                net, verts, faces, evecs_flip_1, evecs_cond=None, input_type=input_type)\n",
    "        \n",
    "        ##############################################\n",
    "        # Calculate the loss\n",
    "        ##############################################\n",
    "        \n",
    "        # calculate the ground truth sign difference\n",
    "        sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "        \n",
    "        # calculate the sign difference between predicted evecs\n",
    "        sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "        \n",
    "        sign_correct = sign_diff_pred.sign() * sign_diff_gt.sign() \n",
    "        \n",
    "        \n",
    "        # count the number of incorrect signs\n",
    "        count_incorrect_signs = (sign_correct < 0).int().sum()\n",
    "            \n",
    "        # incorrect_signs_list.append(count_incorrect_signs)\n",
    "        incorrect_signs_list = torch.cat([incorrect_signs_list, torch.tensor([count_incorrect_signs])])\n",
    "        \n",
    "        \n",
    "        iterator.set_description(f'Mean incorrect signs {incorrect_signs_list.float().mean():.2f} / {feature_dim}')\n",
    "        iterator.update(1)\n",
    "        # if count_incorrect_signs > 7:\n",
    "        #     raise ValueError('Too many incorrect signs')\n",
    "    \n",
    "iterator.close()\n",
    "    \n",
    "print(f'Results for {len(incorrect_signs_list)} test shapes')\n",
    "print(f'Incorrect signs per shape: {incorrect_signs_list.float().mean():.2f} / {feature_dim}')\n",
    "\n",
    "print('Max incorrect signs', incorrect_signs_list.max())\n",
    "\n",
    "print()\n",
    "# print('Shape idx', curr_idx)\n",
    "print('GT', sign_diff_gt)\n",
    "print('PRED', sign_diff_pred)\n",
    "print('Correct', sign_correct)\n",
    "print(f'Incorrect signs {torch.sum(sign_correct != 1)} / {feature_dim}')\n",
    "print(incorrect_signs_list)\n",
    "\n",
    "\n",
    "# plt.plot(support_vector_norm.squeeze().detach().cpu().numpy(), '.', alpha=0.1)\n",
    "# plt.ylim(-0.1, 0.1)\n",
    "# # plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $TMPDIR/FAUST_r/diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read /home/s94zalek_hpc/shape_matching/notebooks/31.07.2024/diffusionnet_runtime_profile.csv\n",
    "df = pd.read_csv('/home/s94zalek_hpc/shape_matching/notebooks/31.07.2024/diffusionnet_runtime_profile.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df by 'cumtime'\n",
    "df = df.sort_values(by='cumtime', ascending=False)\n",
    "# print(df.head(10))\n",
    "df.head(20)[['func','ncalls','ccalls','tottime','cumtime']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which shapes have the most incorrect signs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print indices where incorrect_signs_list > 10\n",
    "print('incorrect > 10, % 20:', torch.where(incorrect_signs_list > 3)[0] % 20)\n",
    "print('incorrect > 10:', torch.where(incorrect_signs_list > 3)[0])\n",
    "\n",
    "# for each index % 0 - 19, print the mean number of incorrect signs\n",
    "\n",
    "unique_shape_idx = torch.zeros(20)\n",
    "for i in range(len(incorrect_signs_list)):\n",
    "    unique_shape_idx[i % 20] += incorrect_signs_list[i]\n",
    "    \n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].plot(unique_shape_idx)\n",
    "axs[0].set_title('Incorrect signs per unique test shape')\n",
    "\n",
    "incorrect_signs_1 = []\n",
    "incorrect_signs_11 = []\n",
    "for i in range(len(incorrect_signs_list)):\n",
    "    if i % 20 == 11:\n",
    "        incorrect_signs_11.append(incorrect_signs_list[i])\n",
    "    if i % 20 == 1:\n",
    "        incorrect_signs_1.append(incorrect_signs_list[i])\n",
    "        \n",
    "axs[1].plot(incorrect_signs_1, '.', label='shape 1')\n",
    "axs[1].plot(incorrect_signs_11, '.', label='shape 11')\n",
    "\n",
    "axs[1].set_title('Incorrect signs for shape 1 and 11')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "# mesh_orig = trimesh.Trimesh(vertices=test_shapes[173]['verts'], faces=test_shapes[11]['faces'])\n",
    "# scene.add_geometry(mesh_orig)\n",
    "\n",
    "# mesh_orig = trimesh.Trimesh(vertices=test_shapes[224]['verts'] + torch.tensor([1, 0, 0])\n",
    "#                             , faces=test_shapes[101]['faces'])\n",
    "# scene.add_geometry(mesh_orig)\n",
    "\n",
    "for i, shape_idx in enumerate(torch.where(incorrect_signs_list > 10)[0]):\n",
    "    mesh_orig = trimesh.Trimesh(vertices=test_shapes[shape_idx]['verts'] + torch.tensor([i, 0, 0])\n",
    "                                , faces=test_shapes[shape_idx]['faces'])\n",
    "    scene.add_geometry(mesh_orig)\n",
    "\n",
    "\n",
    "axis = trimesh.creation.axis(axis_length=0.5)\n",
    "scene.add_geometry(axis)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the evecs on failed shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.geometry_util import get_operators\n",
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "import robust_laplacian\n",
    "import scipy.sparse.linalg as sla\n",
    "import utils.geometry_util as geometry_util\n",
    "import potpourri3d as pp3d\n",
    "\n",
    "evec_n = 60\n",
    "\n",
    "feature_dim = 64\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "verts_0 = test_shapes[0]['verts']\n",
    "faces_0 = test_shapes[0]['faces']\n",
    "# evecs_0 = test_shapes[11]['evecs'][:, start_dim:start_dim+feature_dim]\n",
    "# evecs_0 = torch.nn.functional.normalize(evecs_0, p=2, dim=0)\n",
    "\n",
    "# verts_0 = verts_0 * 2.5\n",
    "\n",
    "# L_0 = pp3d.cotan_laplacian(verts_0.numpy(), faces_0.numpy(), denom_eps=1e-10)\n",
    "# M_0 = pp3d.vertex_areas(verts_0.numpy(), faces_0.numpy())\n",
    "# M_0 += 1e-8 * np.mean(M_0)\n",
    "# M_0 = np.diag(M_0).astype(np.float32)\n",
    "\n",
    "# print(L_0.dtype, M_0.dtype)\n",
    "\n",
    "L_0, M_0 = robust_laplacian.mesh_laplacian(verts_0.numpy(), faces_0.numpy())\n",
    "# L_0, M_0 = robust_laplacian.point_cloud_laplacian(verts_0.numpy())\n",
    "evals_0, evecs_0 = sla.eigsh(L_0, feature_dim, M_0, sigma=1e-8)\n",
    "evecs_0 = torch.tensor(evecs_0)\n",
    "\n",
    "\n",
    "verts_1 = test_shapes[1]['verts']\n",
    "faces_1 = test_shapes[1]['faces']\n",
    "# evecs_1 = test_shapes[91]['evecs'][:, start_dim:start_dim+feature_dim]\n",
    "# evecs_1 = torch.nn.functional.normalize(evecs_1, p=2, dim=0)\n",
    "\n",
    "# L_1 = pp3d.cotan_laplacian(verts_1.numpy(), faces_1.numpy(), denom_eps=1e-10)\n",
    "# M_1 = pp3d.vertex_areas(verts_1.numpy(), faces_1.numpy())\n",
    "# M_1 += 1e-8 * np.mean(M_1)\n",
    "# M_1 = np.diag(M_1).astype(np.float32)\n",
    "\n",
    "L_1, M_1 = robust_laplacian.mesh_laplacian(verts_1.numpy(), faces_1.numpy())\n",
    "# L_1, M_1 = robust_laplacian.point_cloud_laplacian(verts_1.numpy())\n",
    "evals_1, evecs_1 = sla.eigsh(L_1, feature_dim, M_1, sigma=1e-8)\n",
    "evecs_1 = torch.tensor(evecs_1)\n",
    "\n",
    "\n",
    "cmap_0 = trimesh.visual.color.interpolate(\n",
    "    torch.nn.functional.normalize(evecs_0[:, evec_n], p=2, dim=0),\n",
    "    'bwr')\n",
    "\n",
    "cmap_1 = trimesh.visual.color.interpolate(\n",
    "    torch.nn.functional.normalize(evecs_1[:, evec_n], p=2, dim=0)\n",
    "    , 'bwr')\n",
    "\n",
    "\n",
    "# chng_by_evec = (evecs_0.abs() - evecs_1.abs()).abs().sum(dim=0)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(evecs_0[:, evec_n].abs().cpu().numpy(), label='11')\n",
    "axs[0].plot(evecs_1[:, evec_n].abs().cpu().numpy(), label='101')\n",
    "axs[0].legend()\n",
    "\n",
    "C_orig_rot = torch.linalg.lstsq(evecs_0, evecs_1).solution\n",
    "plotting_utils.plot_Cxy(fig, axs[1], C_orig_rot,\n",
    "                        'C_orig_rot', 0, 64, show_grid=False, show_colorbar=False)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mesh_0 = trimesh.Trimesh(vertices=verts_0, faces=faces_0, vertex_colors=cmap_0[:len(verts_0)])\n",
    "mesh_1 = trimesh.Trimesh(vertices=verts_1 + np.array([1, 0, 0]), faces=faces_1,\n",
    "                           vertex_colors=cmap_1[:len(verts_1)])\n",
    "\n",
    "scene.add_geometry(mesh_0)\n",
    "scene.add_geometry(mesh_1)\n",
    "\n",
    "axis = trimesh.creation.axis(axis_length=1)\n",
    "scene.add_geometry(axis)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_0[l:h].mean(), evals_1[l:h].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 48\n",
    "h = 64\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(evals_0[l:h], '.-', label='evals_0')\n",
    "axs[0].plot(evals_1[l:h], '.-', label='evals_1')\n",
    "\n",
    "axs[1].plot(evals_0[l:h] - evals_0[l:h].mean(), '.-', label='evals_0')\n",
    "axs[1].plot(evals_1[l:h] - evals_1[l:h].mean(), '.-', label='evals_1')\n",
    "\n",
    "\n",
    "# plt.plot(train_dataset[78]['second']['evals'][0][l:h], '.-', label='evals_78')\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plt.imshow((supp_vec_0.transpose(1, 2) @ evecs_flip_0)[0].cpu(), cmap='bwr')\n",
    "plt.colorbar(plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marker color = blue if incorrect, red if correct\n",
    "color = np.where(sign_correct.squeeze().detach().cpu().numpy() == 1, 'red', 'blue')\n",
    "\n",
    "plt.scatter(np.arange(feature_dim), sign_diff_pred.squeeze().detach().cpu().numpy(), c=color)\n",
    "\n",
    "# plt.ylim(-0.3, 0.3)\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "# plt.plot(sign_correct.squeeze().detach().cpu().numpy(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(3, 1, figsize=(5, 10))\n",
    "\n",
    "# for i, idx in enumerate(range(1, 4)):\n",
    "#     axs[i].plot(supp_vec_0[0, :, -idx].cpu(), '-')\n",
    "plt.plot(supp_vec_0[0, :, -4].cpu(), '-')\n",
    "plt.plot(supp_vec_1[0, :, -4].cpu(), '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "verts = test_shape['verts'].cpu().numpy()\n",
    "faces = test_shape['faces'].cpu().numpy()\n",
    "\n",
    "cmap = np.ones((verts.shape[0], 4))\n",
    "\n",
    "# set cmap to 1 where supp_vec_0[0, :, -4] > 0.02\n",
    "cmap[supp_vec_0[0, :, -2].cpu().abs() > 0.015, :2] = 0\n",
    "# cmap *= 255\n",
    "\n",
    "mesh = trimesh.Trimesh(vertices=verts, faces=faces, vertex_colors=cmap)\n",
    "scene.add_geometry(mesh)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "train_shape = train_dataset[58]['second']\n",
    "verts_orig = train_shape['verts']\n",
    "faces = train_shape['faces']\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for i in range(10):\n",
    "    _, _, _, _, evecs_orig, _, _ = get_operators(verts_orig, faces,\n",
    "                                                    k=feature_dim,\n",
    "                                                    cache_dir=None)\n",
    "time_get_operators = time.time() - time_start\n",
    "\n",
    "for i in range(10):\n",
    "    L_orig, M_orig = robust_laplacian.mesh_laplacian(verts_orig.numpy(), faces.numpy())\n",
    "    # L_orig, M_orig = robust_laplacian.point_cloud_laplacian(verts_orig.numpy())\n",
    "    evals_orig, evecs_orig = sla.eigsh(L_orig, feature_dim, M_orig, sigma=1e-8)\n",
    "    evecs_orig = torch.tensor(evecs_orig)\n",
    "\n",
    "time_robust_laplacian = time.time() - time_start - time_get_operators\n",
    "\n",
    "print(f'time_get_operators: {time_get_operators}')\n",
    "print(f'time_robust_laplacian: {time_robust_laplacian}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

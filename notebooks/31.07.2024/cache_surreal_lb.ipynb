{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_code.datasets.surreal_dataset_3dc import TemplateSurrealDataset3DC\n",
    "\n",
    "# create the dataset\n",
    "dataset = TemplateSurrealDataset3DC(\n",
    "    # shape_path=f'/home/s94zalek_hpc/3D-CODED/data/datas_surreal_train.pth',\n",
    "    shape_path='/lustre/mlnvme/data/s94zalek_hpc-shape_matching/mmap_datas_surreal_train.pth',\n",
    "    num_evecs=128,\n",
    "    use_cuda=False,\n",
    "    cache_lb_dir=None,\n",
    "    return_evecs=False\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.geometry_util as geometry_util\n",
    "import scipy.sparse\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def zip_write_operators(verts, faces, k, cache_zip, search_path, normals=None):\n",
    "\n",
    "    assert verts.dim() == 2, 'Please call get_all_operators() for a batch of vertices'\n",
    "    \n",
    "    # assert that cache_zip doesn't contain search_path   \n",
    "    # with zipfile.Path(root=cache_zip, at=search_path) as path:\n",
    "    #     if path.exists():\n",
    "    #         raise ValueError(f'{search_path} already exists in the cache zip file.')\n",
    " \n",
    "    verts_np = geometry_util.torch2np(verts)\n",
    "    faces_np = geometry_util.torch2np(faces) if faces is not None else None\n",
    "\n",
    "    if np.isnan(verts_np).any():\n",
    "        raise ValueError('detect NaN vertices.')\n",
    "\n",
    "    # recompute\n",
    "    frames, mass, L, evals, evecs, gradX, gradY = geometry_util.compute_operators(verts, faces, k, normals)\n",
    "\n",
    "    dtype_np = np.float32\n",
    "\n",
    "    # save\n",
    "    frames_np = geometry_util.torch2np(frames).astype(dtype_np)\n",
    "    mass_np = geometry_util.torch2np(mass).astype(dtype_np)\n",
    "    evals_np = geometry_util.torch2np(evals).astype(dtype_np)\n",
    "    evecs_np = geometry_util.torch2np(evecs).astype(dtype_np)\n",
    "    L_np = geometry_util.sparse_torch_to_np(L).astype(dtype_np)\n",
    "    gradX_np = geometry_util.sparse_torch_to_np(gradX).astype(dtype_np)\n",
    "    gradY_np = geometry_util.sparse_torch_to_np(gradY).astype(dtype_np)\n",
    "\n",
    "    # save to zip\n",
    "    with cache_zip.open(search_path, 'w') as f:\n",
    "        np.savez(\n",
    "            f,\n",
    "            verts=verts_np,\n",
    "            faces=faces_np,\n",
    "            k_eig=k,\n",
    "            frames=frames_np,\n",
    "            mass=mass_np,\n",
    "            evals=evals_np,\n",
    "            evecs=evecs_np,\n",
    "            L_data=L_np.data,\n",
    "            L_indices=L_np.indices,\n",
    "            L_indptr=L_np.indptr,\n",
    "            L_shape=L_np.shape,\n",
    "            gradX_data=gradX_np.data,\n",
    "            gradX_indices=gradX_np.indices,\n",
    "            gradX_indptr=gradX_np.indptr,\n",
    "            gradX_shape=gradX_np.shape,\n",
    "            gradY_data=gradY_np.data,\n",
    "            gradY_indices=gradY_np.indices,\n",
    "            gradY_indptr=gradY_np.indptr,\n",
    "            gradY_shape=gradY_np.shape,\n",
    "        )\n",
    "    return\n",
    "    # return frames, mass, L, evals, evecs, gradX, gradY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "idx_start = 0\n",
    "idx_end = 10000\n",
    "\n",
    "base_folder = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/SURREAL'\n",
    "os.makedirs(base_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                  | 6/10000 [00:07<3:27:05,  1.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m         faces \u001b[38;5;241m=\u001b[39m data_i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecond\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaces\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# print(f'Processing {i:06d}')\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m         \u001b[43mzip_write_operators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcache_zip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzip_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m06d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# print(zip_file.namelist())\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# zip_file.close()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mzip_write_operators\u001b[0;34m(verts, faces, k, cache_zip, search_path, normals)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetect NaN vertices.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# recompute\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m frames, mass, L, evals, evecs, gradX, gradY \u001b[38;5;241m=\u001b[39m \u001b[43mgeometry_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_operators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m dtype_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# save\u001b[39;00m\n",
      "File \u001b[0;32m~/shape_matching/utils/geometry_util.py:612\u001b[0m, in \u001b[0;36mcompute_operators\u001b[0;34m(verts, faces, k, normals)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 612\u001b[0m         evals_np, evecs_np \u001b[38;5;241m=\u001b[39m \u001b[43msla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigsh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL_eigsh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meigs_sigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;66;03m# Clip off any eigenvalues that end up slightly negative due to numerical error\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         evals_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(evals_np, a_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, a_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1697\u001b[0m, in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _ARPACK_LOCK:\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params\u001b[38;5;241m.\u001b[39mconverged:\n\u001b[0;32m-> 1697\u001b[0m         \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m params\u001b[38;5;241m.\u001b[39mextract(return_eigenvectors)\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:537\u001b[0m, in \u001b[0;36m_SymmetricArpackParams.iterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mido, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miparam, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 537\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arpack_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mido\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhich\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miparam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mipntr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m     xslice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn)\n\u001b[1;32m    542\u001b[0m     yslice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with zipfile.ZipFile(f'{base_folder}/{idx_start:06d}_{idx_end:06d}.zip',\n",
    "                           'w', compression=zipfile.ZIP_STORED) as zip_file:\n",
    "    for i in tqdm(range(idx_start, idx_end)):\n",
    "        \n",
    "        data_i = dataset[i]\n",
    "        verts = data_i['second']['verts']\n",
    "        faces = data_i['second']['faces']\n",
    "        \n",
    "        # print(f'Processing {i:06d}')\n",
    "        zip_write_operators(verts=verts, faces=faces, k=128,\n",
    "                            cache_zip=zip_file, search_path=f'{i:06d}.npz')\n",
    "        \n",
    "        # print(zip_file.namelist())\n",
    "    \n",
    "# zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.geometry_util as geometry_util\n",
    "import scipy.sparse\n",
    "import torch\n",
    "\n",
    "def read_sp_mat(npzfile, prefix):\n",
    "    data = npzfile[prefix + '_data']\n",
    "    indices = npzfile[prefix + '_indices']\n",
    "    indptr = npzfile[prefix + '_indptr']\n",
    "    shape = npzfile[prefix + '_shape']\n",
    "    mat = scipy.sparse.csc_matrix((data, indices, indptr), shape=shape)\n",
    "    return mat\n",
    "\n",
    "def zip_read_operators(cache_zip, search_path, k):\n",
    "\n",
    "    with cache_zip.open(search_path) as f:\n",
    "        with np.load(f, allow_pickle=True) as npzfile:\n",
    "\n",
    "            cache_verts = npzfile['verts']\n",
    "            cache_faces = npzfile['faces']\n",
    "            cache_k = npzfile['k_eig'].item()\n",
    "            \n",
    "            if cache_k < k:\n",
    "                raise ValueError(f'cache_k={cache_k} is less than k={k}.')\n",
    "\n",
    "            # this entry matches. return it.\n",
    "            frames = npzfile['frames']\n",
    "            mass = npzfile['mass']\n",
    "            L = read_sp_mat(npzfile, 'L')\n",
    "            evals = npzfile['evals'][:k]\n",
    "            evecs = npzfile['evecs'][:, :k]\n",
    "            gradX = read_sp_mat(npzfile, 'gradX')\n",
    "            gradY = read_sp_mat(npzfile, 'gradY')\n",
    "\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.float32\n",
    "\n",
    "    cache_verts = torch.from_numpy(cache_verts).to(device=device, dtype=dtype)\n",
    "    cache_faces = torch.from_numpy(cache_faces).to(device=device, dtype=torch.int64)\n",
    "    frames = torch.from_numpy(frames).to(device=device, dtype=dtype)\n",
    "    mass = torch.from_numpy(mass).to(device=device, dtype=dtype)\n",
    "    L = geometry_util.sparse_np_to_torch(L).to(device=device, dtype=dtype)\n",
    "    evals = torch.from_numpy(evals).to(device=device, dtype=dtype)\n",
    "    evecs = torch.from_numpy(evecs).to(device=device, dtype=dtype)\n",
    "    gradX = geometry_util.sparse_np_to_torch(gradX).to(device=device, dtype=dtype)\n",
    "    gradY = geometry_util.sparse_np_to_torch(gradY).to(device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "    return frames, cache_verts, cache_faces, mass, L, evals, evecs, gradX, gradY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile(f'{base_folder}/{idx_start:06d}_{idx_end:06d}.zip', 'r') as zip_file:\n",
    "# /lustre/mlnvme/data/s94zalek_hpc-shape_matching/SURREAL/010000_020000.zip\n",
    "\n",
    "with zipfile.ZipFile(\n",
    "    f'/lustre/mlnvme/data/s94zalek_hpc-shape_matching/SURREAL/010000_020000.zip',\n",
    "    'r') as zip_file:\n",
    "    for name in zip_file.namelist()[:5]:\n",
    "        print(name)\n",
    "        frames, verts, faces, mass, L, evals, evecs, gradX, gradY = zip_read_operators(zip_file, name, 64)\n",
    "        print(frames.shape, verts.shape, faces.shape, mass.shape, L.shape, evals.shape, evecs.shape, gradX.shape, gradY.shape)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh \n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "# with zipfile.ZipFile(f'{base_folder}/{idx_start:06d}_{idx_end:06d}.zip', 'r') as zip_file:\n",
    "\n",
    "with zipfile.ZipFile(\n",
    "    f'/lustre/mlnvme/data/s94zalek_hpc-shape_matching/SURREAL/010000_020000.zip',\n",
    "    'r') as zip_file:\n",
    "    \n",
    "    zip_namelist = zip_file.namelist()\n",
    "    for i, name in enumerate(tqdm(zip_namelist[:10])):\n",
    "        \n",
    "        rand_name = np.random.choice(zip_namelist)\n",
    "        frames, verts, faces, mass, L, evals, evecs, gradX, gradY = zip_read_operators(\n",
    "            zip_file, rand_name, 128)\n",
    "        mesh = trimesh.Trimesh(vertices=verts + torch.tensor([i, 0, 0]), faces=faces)\n",
    "\n",
    "        scene.add_geometry(mesh)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZipCollection:\n",
    "    '''\n",
    "    Context manager for opening and closing multiple zip files\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, zip_files_path_list):\n",
    "        self.zip_files_path_list = zip_files_path_list\n",
    "        self.zip_files = []\n",
    "        \n",
    "    def __enter__(self):\n",
    "        print(f'Opening {len(self.zip_files_path_list)} zip files...')\n",
    "        \n",
    "        for zip_file_path in self.zip_files_path_list:\n",
    "            self.zip_files.append(zipfile.ZipFile(zip_file_path, 'r'))\n",
    "        return self.zip_files\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, exc_traceback):\n",
    "        print(f'Closing {len(self.zip_files)} zip files...')\n",
    "        \n",
    "        for zip_file in self.zip_files:\n",
    "            zip_file.close()\n",
    "        return\n",
    "\n",
    "\n",
    "class ZipFileDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, zip_files, k):\n",
    "\n",
    "        self.k = k        \n",
    "        self.zip_files = zip_files\n",
    "\n",
    "        # get all the namelists and their lengths\n",
    "        self.zip_namelists = []\n",
    "        self.zip_namelists_len = []\n",
    "        for zip_file in self.zip_files:\n",
    "            zip_file_namelist = zip_file.namelist()\n",
    "            self.zip_namelists.append(zip_file_namelist)\n",
    "            self.zip_namelists_len.append(len(zip_file_namelist))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return sum(self.zip_namelists_len)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # find the source zip file\n",
    "        zip_file_idx = 0\n",
    "        while idx >= self.zip_namelists_len[zip_file_idx]:\n",
    "            idx -= self.zip_namelists_len[zip_file_idx]\n",
    "            zip_file_idx += 1\n",
    "            \n",
    "        # get the filename\n",
    "        file_name = self.zip_namelists[zip_file_idx][idx]\n",
    "        \n",
    "        # read the operators\n",
    "        frames, verts, faces, mass, L, evals, evecs, gradX, gradY = zip_read_operators(\n",
    "            self.zip_files[zip_file_idx], file_name, self.k)\n",
    "        \n",
    "        # construct the output payload\n",
    "        item = {\n",
    "            'verts': verts,\n",
    "            'faces': faces,\n",
    "            'evals': evals[:self.k].unsqueeze(0),\n",
    "            'evecs': evecs[:, :self.k],\n",
    "            'evecs_trans': evecs[:, :self.k].T * mass[None],\n",
    "            'mass': mass,\n",
    "            'L': L,\n",
    "            'gradX': gradX,\n",
    "            'gradY': gradY\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/lustre/mlnvme/data/s94zalek_hpc-shape_matching/SURREAL/000000_010000.zip', '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/SURREAL/010000_020000.zip']\n"
     ]
    }
   ],
   "source": [
    "# get all zip files in \n",
    "import os\n",
    "\n",
    "base_dir = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/SURREAL'\n",
    "\n",
    "zip_files_path_list = []\n",
    "for file in os.listdir(base_dir):\n",
    "    if file.endswith('.zip'):\n",
    "        zip_files_path_list.append(os.path.join(base_dir, file))\n",
    "        \n",
    "zip_files_path_list.sort()\n",
    "\n",
    "print(zip_files_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening 2 zip files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:52<00:00, 19.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing 2 zip files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with ZipCollection(zip_files_path_list) as zip_files:\n",
    "    dataset = ZipFileDataset(zip_files, 128)\n",
    "    \n",
    "    idxs = range(0, len(dataset), len(dataset) // 1000)\n",
    "    \n",
    "    for idx in tqdm(idxs):\n",
    "        data = dataset[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

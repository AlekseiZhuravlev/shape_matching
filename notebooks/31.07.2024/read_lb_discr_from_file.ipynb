{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import my_code.datasets.shape_dataset as shape_dataset\n",
    "import my_code.datasets.template_dataset as template_dataset\n",
    "\n",
    "\n",
    "dataset_single = shape_dataset.SingleFaustDataset(\n",
    "    phase='train',\n",
    "    data_root = 'data_with_smpl_corr/FAUST_r',\n",
    "    centering = 'bbox',\n",
    "    num_evecs=128,\n",
    "    lb_cache_dir=f'/home/s94zalek_hpc/shape_matching/data_with_smpl_corr/FAUST_r/diffusion',\n",
    "    # lb_cache_dir=f'{tmp_dir}/FAUST_r/diffusion'\n",
    "    return_evecs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache to local ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a zip file in /home/s94zalek_hpc/shape_matching/notebooks/31.07.2024 and open it\n",
    "import zipfile\n",
    "\n",
    "zip_file = zipfile.ZipFile('/home/s94zalek_hpc/shape_matching/notebooks/31.07.2024/FAUST_r.zip',\n",
    "                           'w', compression=zipfile.ZIP_STORED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.geometry_util as geometry_util\n",
    "import scipy.sparse\n",
    "\n",
    "def get_operators(verts, faces, k=120, normals=None,\n",
    "                  cache_zip=None, overwrite_cache=False):\n",
    "    \"\"\"\n",
    "    See documentation for compute_operators().\n",
    "    This essentailly just wraps a call to compute_operators, using a cache if possible.\n",
    "    All arrays are always computed using double precision for stability,\n",
    "    then truncated to single precision floats to store on disk,\n",
    "    and finally returned as a tensor with dtype/device matching the `verts` input.\n",
    "    \"\"\"\n",
    "    assert verts.dim() == 2, 'Please call get_all_operators() for a batch of vertices'\n",
    "    device = verts.device\n",
    "    dtype = verts.dtype\n",
    "    verts_np = geometry_util.torch2np(verts)\n",
    "    faces_np = geometry_util.torch2np(faces) if faces is not None else None\n",
    "\n",
    "    if np.isnan(verts_np).any():\n",
    "        raise ValueError('detect NaN vertices.')\n",
    "\n",
    "    found = False\n",
    "    if cache_zip:\n",
    "        # assert osp.isdir(cache_dir), f'Invalid cache directory: {cache_zip}'\n",
    "        hash_key_str = str(geometry_util.hash_arrays((verts_np, faces_np)))\n",
    "\n",
    "        # Search through buckets with matching hashes.\n",
    "        # When the loop exits,\n",
    "        # this is the bucket index of the file we should write to.\n",
    "        i_cache = 0\n",
    "        while True:\n",
    "            # From the name of the file to check\n",
    "            search_path = (hash_key_str+'_'+str(i_cache)+'.npz')\n",
    "            \n",
    "\n",
    "            try:\n",
    "                # npzfile = np.load(search_path, allow_pickle=True)\n",
    "                \n",
    "                # get the file from the zip\n",
    "                npzfile = np.load(cache_zip.open(search_path), allow_pickle=True)\n",
    "                \n",
    "                cache_verts = npzfile['verts']\n",
    "                cache_faces = npzfile['faces']\n",
    "                cache_k = npzfile['k_eig'].item()\n",
    "\n",
    "                # If the cache doesn't match, keep searching\n",
    "                if (not np.array_equal(verts, cache_verts)) or (not np.array_equal(faces, cache_faces)):\n",
    "                    i_cache += 1\n",
    "                    print('collision detected')\n",
    "                    continue\n",
    "\n",
    "                # Delete previous file and overwrite it\n",
    "                if overwrite_cache or cache_k < k:\n",
    "                    # os.remove(search_path)\n",
    "                    # remove the file from zip\n",
    "                    cache_zip.remove(search_path)\n",
    "                    break\n",
    "\n",
    "                def read_sp_mat(prefix):\n",
    "                    data = npzfile[prefix + '_data']\n",
    "                    indices = npzfile[prefix + '_indices']\n",
    "                    indptr = npzfile[prefix + '_indptr']\n",
    "                    shape = npzfile[prefix + '_shape']\n",
    "                    mat = scipy.sparse.csc_matrix((data, indices, indptr), shape=shape)\n",
    "                    return mat\n",
    "\n",
    "                # this entry matches. return it.\n",
    "                frames = npzfile['frames']\n",
    "                mass = npzfile['mass']\n",
    "                L = read_sp_mat('L')\n",
    "                evals = npzfile['evals'][:k]\n",
    "                evecs = npzfile['evecs'][:, :k]\n",
    "                gradX = read_sp_mat('gradX')\n",
    "                gradY = read_sp_mat('gradY')\n",
    "\n",
    "                frames = torch.from_numpy(frames).to(device=device, dtype=dtype)\n",
    "                mass = torch.from_numpy(mass).to(device=device, dtype=dtype)\n",
    "                L = geometry_util.sparse_np_to_torch(L).to(device=device, dtype=dtype)\n",
    "                evals = torch.from_numpy(evals).to(device=device, dtype=dtype)\n",
    "                evecs = torch.from_numpy(evecs).to(device=device, dtype=dtype)\n",
    "                gradX = geometry_util.sparse_np_to_torch(gradX).to(device=device, dtype=dtype)\n",
    "                gradY = geometry_util.sparse_np_to_torch(gradY).to(device=device, dtype=dtype)\n",
    "\n",
    "                found = True\n",
    "                break\n",
    "            except KeyError:\n",
    "                # not found, create a new file\n",
    "                break\n",
    "\n",
    "    if not found:\n",
    "        # recompute\n",
    "        frames, mass, L, evals, evecs, gradX, gradY = geometry_util.compute_operators(verts, faces, k, normals)\n",
    "\n",
    "        dtype_np = np.float32\n",
    "\n",
    "        # save\n",
    "        if cache_zip:\n",
    "            frames_np = geometry_util.torch2np(frames).astype(dtype_np)\n",
    "            mass_np = geometry_util.torch2np(mass).astype(dtype_np)\n",
    "            evals_np = geometry_util.torch2np(evals).astype(dtype_np)\n",
    "            evecs_np = geometry_util.torch2np(evecs).astype(dtype_np)\n",
    "            L_np = geometry_util.sparse_torch_to_np(L).astype(dtype_np)\n",
    "            gradX_np = geometry_util.sparse_torch_to_np(gradX).astype(dtype_np)\n",
    "            gradY_np = geometry_util.sparse_torch_to_np(gradY).astype(dtype_np)\n",
    "\n",
    "            # save to zip\n",
    "            np.savez(\n",
    "                cache_zip.open(search_path, 'w'),\n",
    "                verts=verts_np,\n",
    "                faces=faces_np,\n",
    "                k_eig=k,\n",
    "                frames=frames_np,\n",
    "                mass=mass_np,\n",
    "                evals=evals_np,\n",
    "                evecs=evecs_np,\n",
    "                L_data=L_np.data,\n",
    "                L_indices=L_np.indices,\n",
    "                L_indptr=L_np.indptr,\n",
    "                L_shape=L_np.shape,\n",
    "                gradX_data=gradX_np.data,\n",
    "                gradX_indices=gradX_np.indices,\n",
    "                gradX_indptr=gradX_np.indptr,\n",
    "                gradX_shape=gradX_np.shape,\n",
    "                gradY_data=gradY_np.data,\n",
    "                gradY_indices=gradY_np.indices,\n",
    "                gradY_indptr=gradY_np.indptr,\n",
    "                gradY_shape=gradY_np.shape,\n",
    "            )\n",
    "\n",
    "    return frames, mass, L, evals, evecs, gradX, gradY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [01:04<00:00,  1.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:07<00:00, 11.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 11.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for _ in range(3):\n",
    "    iterator = tqdm(range(len(dataset_single)))\n",
    "    for i in iterator:\n",
    "        data_i = dataset_single[i]\n",
    "        verts = data_i['verts']\n",
    "        faces = data_i['faces']\n",
    "        frames, mass, L, evals, evecs, gradX, gradY = get_operators(verts, faces, k=128, cache_zip=zip_file)\n",
    "        \n",
    "    iterator.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with reading from the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import my_code.datasets.shape_dataset as shape_dataset\n",
    "import my_code.datasets.template_dataset as template_dataset\n",
    "\n",
    "\n",
    "dataset_single_evecs = shape_dataset.SingleFaustDataset(\n",
    "    phase='train',\n",
    "    data_root = 'data_with_smpl_corr/FAUST_r',\n",
    "    centering = 'bbox',\n",
    "    num_evecs=128,\n",
    "    lb_cache_dir=f'/home/s94zalek_hpc/shape_matching/data_with_smpl_corr/FAUST_r/diffusion',\n",
    "    # lb_cache_dir=f'{tmp_dir}/FAUST_r/diffusion'\n",
    "    return_evecs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:11<00:00,  7.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:07<00:00, 10.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 13.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for _ in range(3):\n",
    "    iterator = tqdm(range(len(dataset_single_evecs)))\n",
    "    for i in iterator:\n",
    "        data_i = dataset_single_evecs[i]\n",
    "        verts = data_i['verts']\n",
    "        faces = data_i['faces']\n",
    "        # frames, mass, L, evals, evecs, gradX, gradY = get_operators(verts, faces, k=128, cache_zip=zip_file)\n",
    "        \n",
    "    iterator.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache to ZIP on Lustre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a zip file in /home/s94zalek_hpc/shape_matching/notebooks/31.07.2024 and open it\n",
    "import zipfile\n",
    "\n",
    "zip_file_lustre = zipfile.ZipFile('/lustre/mlnvme/data/s94zalek_hpc-shape_matching/FAUST_r.zip',\n",
    "                           'w', compression=zipfile.ZIP_STORED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [01:14<00:00,  1.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 11.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:06<00:00, 11.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for _ in range(3):\n",
    "    iterator = tqdm(range(len(dataset_single)))\n",
    "    for i in iterator:\n",
    "        data_i = dataset_single[i]\n",
    "        verts = data_i['verts']\n",
    "        faces = data_i['faces']\n",
    "        frames, mass, L, evals, evecs, gradX, gradY = get_operators(\n",
    "            verts, faces, k=128, cache_zip=zip_file_lustre)\n",
    "        \n",
    "    iterator.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip file size: 302.5829086303711 MB\n"
     ]
    }
   ],
   "source": [
    "# get size of /home/s94zalek_hpc/shape_matching/notebooks/31.07.2024/FAUST_r.zip\n",
    "import os\n",
    "\n",
    "zip_file_path = '/home/s94zalek_hpc/shape_matching/notebooks/31.07.2024/FAUST_r.zip'\n",
    "zip_file_size = os.path.getsize(zip_file_path)\n",
    "\n",
    "print(f'zip file size: {zip_file_size / 1024 / 1024} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 199552.078125 GB\n",
      "used: 8851.46875 GB\n",
      "free: 190700.609375 GB\n"
     ]
    }
   ],
   "source": [
    "# get directory size /home/s94zalek_hpc/shape_matching/data_with_smpl_corr/FAUST_r/diffusion\n",
    "\n",
    "import shutil\n",
    "\n",
    "dir_path = '/home/s94zalek_hpc/shape_matching/data_with_smpl_corr/FAUST_r/diffusion'\n",
    "# dir_size = shutil.disk_usage(dir_path)\n",
    "total, used, free = shutil.disk_usage(dir_path)\n",
    "\n",
    "print(f'total: {total / 1024 / 1024 / 1024} GB')\n",
    "print(f'used: {used / 1024 / 1024 / 1024} GB')\n",
    "print(f'free: {free / 1024 / 1024 / 1024} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subdivide directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a zip file in /home/s94zalek_hpc/shape_matching/notebooks/31.07.2024 and open it\n",
    "import zipfile\n",
    "\n",
    "zip_test = zipfile.ZipFile('/home/s94zalek_hpc/shape_matching/notebooks/31.07.2024/test.zip',\n",
    "                           'w', compression=zipfile.ZIP_STORED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_1 = 'A13KSJDNN2'\n",
    "str_2 = 'A22KJSCJCW'\n",
    "str_3 = 'B1ASCKJSCI'\n",
    "\n",
    "for str_i in [str_1, str_2, str_3]:\n",
    "    dir_1 = str_i[0]\n",
    "    dir_2 = str_i[1]\n",
    "    dir_3 = str_i[2]\n",
    "    \n",
    "    zip_test.writestr(f'{dir_1}/{dir_2}/{dir_3}/{str_i}.txt', str_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the zip file\n",
    "zip_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'A13KSJDNN2'\n"
     ]
    }
   ],
   "source": [
    "# print the content of the zip file\n",
    "with zipfile.ZipFile('/home/s94zalek_hpc/shape_matching/notebooks/31.07.2024/test.zip', 'r') as zip_test:\n",
    "    # print(zip_test.iterdir())\n",
    "    \n",
    "    # zip_path = zipfile.Path(zip_test)\n",
    "    # print(list(zip_path.iterdir()))\n",
    "\n",
    "    # read the file str_1\n",
    "    print(zip_test.read('A/1/3/A13KSJDNN2.txt'))\n",
    "\n",
    "    # for file_name in zip_test.namelist():\n",
    "    #     with zip_test.open(file_name) as file:\n",
    "    #         print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge 2 zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_single_2 = shape_dataset.SingleFaustDataset(\n",
    "    phase='train',\n",
    "    data_root = 'data_with_smpl_corr/FAUST_original',\n",
    "    centering = 'bbox',\n",
    "    num_evecs=128,\n",
    "    lb_cache_dir=f'/home/s94zalek_hpc/shape_matching/data_with_smpl_corr/FAUST_r/diffusion',\n",
    "    # lb_cache_dir=f'{tmp_dir}/FAUST_r/diffusion'\n",
    "    return_evecs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a zip file in /home/s94zalek_hpc/shape_matching/notebooks/31.07.2024 and open it\n",
    "import zipfile\n",
    "\n",
    "zip_file_2 = zipfile.ZipFile('/home/s94zalek_hpc/shape_matching/notebooks/31.07.2024/FAUST_orig.zip',\n",
    "                           'w', compression=zipfile.ZIP_STORED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [01:30<00:00,  1.13s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:10<00:00,  7.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:10<00:00,  7.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for _ in range(3):\n",
    "    iterator = tqdm(range(len(dataset_single_2)))\n",
    "    for i in iterator:\n",
    "        data_i = dataset_single_2[i]\n",
    "        verts = data_i['verts']\n",
    "        faces = data_i['faces']\n",
    "        frames, mass, L, evals, evecs, gradX, gradY = get_operators(\n",
    "            verts, faces, k=128, cache_zip=zip_file_2)\n",
    "        \n",
    "    iterator.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open this file /home/s94zalek_hpc/3D-CODED/data/datas_surreal_train.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "surreal_shapes = torch.load(\n",
    "    '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/mmap_datas_surreal_train.pth',\n",
    "    # '/home/s94zalek_hpc/3D-CODED/data/datas_surreal_train.pth',\n",
    "    mmap=True)\n",
    "# print('saving')\n",
    "# torch.save(surreal_shapes, '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/mmap_datas_surreal_train.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_FAUST  datas_surreal_train.pth  FAUST_r.zip  mmap_datas_surreal_train.pth\n"
     ]
    }
   ],
   "source": [
    "# !ls /lustre/mlnvme/data/s94zalek_hpc-shape_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_code.datasets.surreal_dataset_3dc import TemplateSurrealDataset3DC\n",
    "\n",
    "# create the dataset\n",
    "dataset = TemplateSurrealDataset3DC(\n",
    "    shape_path=f'/home/s94zalek_hpc/3D-CODED/data/datas_surreal_train.pth',\n",
    "    num_evecs=128,\n",
    "    use_cuda=False,\n",
    "    cache_lb_dir=None,\n",
    "    return_evecs=True\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': {'id': tensor(-1),\n",
       "  'verts': tensor([[ 0.0643,  0.5906,  0.1324],\n",
       "          [ 0.0606,  0.5795,  0.1361],\n",
       "          [ 0.0685,  0.5792,  0.1295],\n",
       "          ...,\n",
       "          [-0.0187,  0.5694,  0.0521],\n",
       "          [-0.0190,  0.5701,  0.0534],\n",
       "          [-0.0200,  0.5678,  0.0546]]),\n",
       "  'faces': tensor([[   3,    0,    2],\n",
       "          [   2,    0,    1],\n",
       "          [   5,    4,    1],\n",
       "          ...,\n",
       "          [4805, 3511, 6309],\n",
       "          [3511, 1330, 6309],\n",
       "          [6309, 1330, 4687]]),\n",
       "  'corr': tensor([   0,    1,    2,  ..., 6887, 6888, 6889]),\n",
       "  'evecs': tensor([[-1.0000, -0.9561,  0.0091,  ...,  0.6545, -0.0469,  0.0680],\n",
       "          [-1.0000, -0.9537,  0.0091,  ...,  0.0461, -0.0636,  0.0184],\n",
       "          [-1.0000, -0.9533,  0.0091,  ...,  0.0358, -0.1624,  0.0464],\n",
       "          ...,\n",
       "          [-1.0000, -0.9409,  0.0086,  ...,  1.5209,  1.3726,  0.5910],\n",
       "          [-1.0000, -0.9412,  0.0086,  ...,  1.5111,  1.3603,  0.5940],\n",
       "          [-1.0000, -0.9410,  0.0086,  ...,  1.4704,  1.3521,  0.5836]]),\n",
       "  'evecs_trans': tensor([[-1.5434e-04, -1.0727e-04, -9.0350e-05,  ..., -3.9224e-06,\n",
       "           -2.8042e-06, -4.3044e-06],\n",
       "          [-1.4757e-04, -1.0231e-04, -8.6135e-05,  ..., -3.6905e-06,\n",
       "           -2.6392e-06, -4.0504e-06],\n",
       "          [ 1.4024e-06,  9.7149e-07,  8.1969e-07,  ...,  3.3652e-08,\n",
       "            2.4076e-08,  3.6942e-08],\n",
       "          ...,\n",
       "          [ 1.0102e-04,  4.9423e-06,  3.2359e-06,  ...,  5.9657e-06,\n",
       "            4.2373e-06,  6.3291e-06],\n",
       "          [-7.2349e-06, -6.8217e-06, -1.4669e-05,  ...,  5.3840e-06,\n",
       "            3.8146e-06,  5.8202e-06],\n",
       "          [ 1.0498e-05,  1.9719e-06,  4.1916e-06,  ...,  2.3181e-06,\n",
       "            1.6658e-06,  2.5123e-06]]),\n",
       "  'evals': tensor([[6.8900e-05, 4.3187e+00, 5.6048e+00, 8.2374e+00, 1.2351e+01, 1.7638e+01,\n",
       "           3.5420e+01, 3.5706e+01, 5.0753e+01, 5.4037e+01, 7.7823e+01, 8.9991e+01,\n",
       "           1.0517e+02, 1.1617e+02, 1.1989e+02, 1.5230e+02, 1.6368e+02, 1.7247e+02,\n",
       "           1.9253e+02, 2.0837e+02, 2.2277e+02, 2.4133e+02, 2.6611e+02, 2.7624e+02,\n",
       "           2.7926e+02, 3.0523e+02, 3.2403e+02, 3.3306e+02, 3.3908e+02, 3.5785e+02,\n",
       "           3.6220e+02, 3.6470e+02, 3.7772e+02, 3.9762e+02, 4.0389e+02, 4.1813e+02,\n",
       "           4.2281e+02, 4.4822e+02, 4.6867e+02, 4.7464e+02, 4.8810e+02, 4.9376e+02,\n",
       "           5.1450e+02, 5.2154e+02, 5.5276e+02, 5.6434e+02, 5.7213e+02, 5.9773e+02,\n",
       "           6.0718e+02, 6.2503e+02, 6.3150e+02, 6.4413e+02, 6.4890e+02, 6.5127e+02,\n",
       "           6.6596e+02, 6.7906e+02, 6.8241e+02, 6.8989e+02, 7.0980e+02, 7.2056e+02,\n",
       "           7.3680e+02, 7.5754e+02, 7.5855e+02, 7.7012e+02, 7.7156e+02, 7.8767e+02,\n",
       "           8.0041e+02, 8.1315e+02, 8.1913e+02, 8.2324e+02, 8.2940e+02, 8.4289e+02,\n",
       "           8.5908e+02, 8.8407e+02, 8.9073e+02, 9.0510e+02, 9.1390e+02, 9.2097e+02,\n",
       "           9.3014e+02, 9.3488e+02, 9.4356e+02, 9.5895e+02, 9.7561e+02, 9.7998e+02,\n",
       "           9.8867e+02, 9.9194e+02, 1.0036e+03, 1.0128e+03, 1.0179e+03, 1.0365e+03,\n",
       "           1.0466e+03, 1.0530e+03, 1.0609e+03, 1.0732e+03, 1.0907e+03, 1.1028e+03,\n",
       "           1.1159e+03, 1.1254e+03, 1.1271e+03, 1.1466e+03, 1.1530e+03, 1.1691e+03,\n",
       "           1.1710e+03, 1.2008e+03, 1.2070e+03, 1.2107e+03, 1.2197e+03, 1.2370e+03,\n",
       "           1.2399e+03, 1.2489e+03, 1.2524e+03, 1.2667e+03, 1.2715e+03, 1.2876e+03,\n",
       "           1.3052e+03, 1.3072e+03, 1.3142e+03, 1.3425e+03, 1.3467e+03, 1.3578e+03,\n",
       "           1.3674e+03, 1.3846e+03, 1.3938e+03, 1.4067e+03, 1.4170e+03, 1.4189e+03,\n",
       "           1.4569e+03, 1.4654e+03]]),\n",
       "  'mass': tensor([1.5434e-04, 1.0727e-04, 9.0351e-05,  ..., 3.9224e-06, 2.8042e-06,\n",
       "          4.3045e-06]),\n",
       "  'L': tensor(indices=tensor([[   0,    0,    0,  ..., 6889, 6889, 6889],\n",
       "                         [   0,    1,    2,  ..., 6887, 6888, 6889]]),\n",
       "         values=tensor([ 3.6814e+00, -5.8169e-01, -4.2091e-01,  ...,\n",
       "                        -3.1761e-03, -4.7206e-01,  4.4629e+00]),\n",
       "         size=(6890, 6890), nnz=48218, layout=torch.sparse_coo),\n",
       "  'gradX': tensor(indices=tensor([[   0,    0,    0,  ..., 6889, 6889, 6889],\n",
       "                         [   0,    1,    2,  ..., 6887, 6888, 6889]]),\n",
       "         values=tensor([ -7.8738, -12.8947,  11.9536,  ...,  32.0920,\n",
       "                         70.7318,  32.1881]),\n",
       "         size=(6890, 6890), nnz=48218, layout=torch.sparse_coo),\n",
       "  'gradY': tensor(indices=tensor([[   0,    0,    0,  ..., 6889, 6889, 6889],\n",
       "                         [   0,    1,    2,  ..., 6887, 6888, 6889]]),\n",
       "         values=tensor([  -9.9100,  -16.4887,  -14.5384,  ...,  100.5555,\n",
       "                          38.0305, -130.0275]),\n",
       "         size=(6890, 6890), nnz=48218, layout=torch.sparse_coo)},\n",
       " 'second': {'id': tensor(12),\n",
       "  'verts': tensor([[-0.0126,  0.4946,  0.0930],\n",
       "          [-0.0139,  0.4832,  0.0978],\n",
       "          [-0.0051,  0.4838,  0.0926],\n",
       "          ...,\n",
       "          [-0.0744,  0.4395,  0.0125],\n",
       "          [-0.0751,  0.4404,  0.0139],\n",
       "          [-0.0768,  0.4378,  0.0156]]),\n",
       "  'faces': tensor([[   3,    0,    2],\n",
       "          [   2,    0,    1],\n",
       "          [   5,    4,    1],\n",
       "          ...,\n",
       "          [4805, 3511, 6309],\n",
       "          [3511, 1330, 6309],\n",
       "          [6309, 1330, 4687]]),\n",
       "  'evecs': tensor([[ 1.0000, -0.9754,  0.0848,  ...,  0.2017,  0.0790, -0.1937],\n",
       "          [ 1.0000, -0.9727,  0.0846,  ...,  0.0270, -0.4666, -0.4566],\n",
       "          [ 1.0000, -0.9718,  0.0842,  ...,  0.0677, -0.3222, -0.6146],\n",
       "          ...,\n",
       "          [ 1.0000, -0.9478,  0.0863,  ...,  0.8000,  1.6553, -1.5372],\n",
       "          [ 1.0000, -0.9483,  0.0863,  ...,  0.7649,  1.6087, -1.5227],\n",
       "          [ 1.0000, -0.9483,  0.0863,  ...,  0.7407,  1.5567, -1.5064]]),\n",
       "  'evecs_trans': tensor([[ 1.5080e-04,  1.0549e-04,  9.4786e-05,  ...,  5.1302e-06,\n",
       "            4.5743e-06,  5.6699e-06],\n",
       "          [-1.4709e-04, -1.0262e-04, -9.2117e-05,  ..., -4.8624e-06,\n",
       "           -4.3379e-06, -5.3768e-06],\n",
       "          [ 1.2792e-05,  8.9247e-06,  7.9819e-06,  ...,  4.4275e-07,\n",
       "            3.9481e-07,  4.8942e-07],\n",
       "          ...,\n",
       "          [ 3.0422e-05,  2.8530e-06,  6.4178e-06,  ...,  4.1042e-06,\n",
       "            3.4991e-06,  4.1999e-06],\n",
       "          [ 1.1915e-05, -4.9227e-05, -3.0537e-05,  ...,  8.4919e-06,\n",
       "            7.3589e-06,  8.8265e-06],\n",
       "          [-2.9214e-05, -4.8171e-05, -5.8255e-05,  ..., -7.8861e-06,\n",
       "           -6.9653e-06, -8.5411e-06]]),\n",
       "  'evals': tensor([[6.8900e-05, 6.5637e+00, 8.4015e+00, 1.0585e+01, 1.6461e+01, 2.3953e+01,\n",
       "           4.4663e+01, 4.6914e+01, 5.8394e+01, 6.6271e+01, 8.4804e+01, 9.3250e+01,\n",
       "           1.0079e+02, 1.3207e+02, 1.3771e+02, 1.5442e+02, 1.6604e+02, 1.9881e+02,\n",
       "           2.1922e+02, 2.3242e+02, 2.3736e+02, 2.5023e+02, 2.6308e+02, 2.7018e+02,\n",
       "           2.9077e+02, 2.9684e+02, 3.1142e+02, 3.1623e+02, 3.2695e+02, 3.4602e+02,\n",
       "           3.5047e+02, 3.7888e+02, 3.8990e+02, 3.9641e+02, 4.0905e+02, 4.1999e+02,\n",
       "           4.3220e+02, 4.4647e+02, 4.6935e+02, 4.8297e+02, 5.0393e+02, 5.1911e+02,\n",
       "           5.2322e+02, 5.3064e+02, 5.3851e+02, 5.5012e+02, 5.6562e+02, 5.8305e+02,\n",
       "           5.9185e+02, 6.1140e+02, 6.1559e+02, 6.3542e+02, 6.4214e+02, 6.5199e+02,\n",
       "           6.6520e+02, 6.7269e+02, 6.8774e+02, 6.9151e+02, 7.0757e+02, 7.1704e+02,\n",
       "           7.2938e+02, 7.3259e+02, 7.4998e+02, 7.7588e+02, 7.8190e+02, 7.9244e+02,\n",
       "           8.0507e+02, 8.1854e+02, 8.2817e+02, 8.4367e+02, 8.4860e+02, 8.5422e+02,\n",
       "           8.6851e+02, 8.7624e+02, 8.8638e+02, 9.0028e+02, 9.1358e+02, 9.2114e+02,\n",
       "           9.3405e+02, 9.4102e+02, 9.5220e+02, 9.6986e+02, 9.7770e+02, 9.8639e+02,\n",
       "           1.0027e+03, 1.0125e+03, 1.0159e+03, 1.0249e+03, 1.0345e+03, 1.0425e+03,\n",
       "           1.0596e+03, 1.0710e+03, 1.0793e+03, 1.0895e+03, 1.0928e+03, 1.1066e+03,\n",
       "           1.1150e+03, 1.1185e+03, 1.1230e+03, 1.1386e+03, 1.1592e+03, 1.1744e+03,\n",
       "           1.1797e+03, 1.1988e+03, 1.2068e+03, 1.2162e+03, 1.2290e+03, 1.2431e+03,\n",
       "           1.2477e+03, 1.2587e+03, 1.2603e+03, 1.2657e+03, 1.2831e+03, 1.2985e+03,\n",
       "           1.3007e+03, 1.3248e+03, 1.3366e+03, 1.3372e+03, 1.3399e+03, 1.3596e+03,\n",
       "           1.3683e+03, 1.3861e+03, 1.3996e+03, 1.4048e+03, 1.4202e+03, 1.4269e+03,\n",
       "           1.4324e+03, 1.4435e+03]]),\n",
       "  'mass': tensor([1.5080e-04, 1.0549e-04, 9.4787e-05,  ..., 5.1302e-06, 4.5743e-06,\n",
       "          5.6699e-06]),\n",
       "  'L': tensor(indices=tensor([[   0,    0,    0,  ..., 6889, 6889, 6889],\n",
       "                         [   0,    1,    2,  ..., 6886, 6888, 6889]]),\n",
       "         values=tensor([ 3.5840, -0.5961, -0.3988,  ..., -1.3843, -0.3469,\n",
       "                         4.2233]),\n",
       "         size=(6890, 6890), nnz=48218, layout=torch.sparse_coo),\n",
       "  'gradX': tensor(indices=tensor([[   0,    0,    0,  ..., 6889, 6889, 6889],\n",
       "                         [   0,    1,    2,  ..., 6886, 6888, 6889]]),\n",
       "         values=tensor([ -2.1501,  -7.5945,  14.7040,  ..., -46.0806,\n",
       "                         50.8731, -38.1225]),\n",
       "         size=(6890, 6890), nnz=48218, layout=torch.sparse_coo),\n",
       "  'gradY': tensor(indices=tensor([[   0,    0,    0,  ..., 6889, 6889, 6889],\n",
       "                         [   0,    1,    2,  ..., 6886, 6888, 6889]]),\n",
       "         values=tensor([ -6.3960, -22.0267, -13.1308,  ...,  84.8404,\n",
       "                         80.8061, -56.7171]),\n",
       "         size=(6890, 6890), nnz=48218, layout=torch.sparse_coo),\n",
       "  'corr': tensor([   0,    1,    2,  ..., 6887, 6888, 6889]),\n",
       "  'C_gt_xy': tensor([[[-9.9999e-01,  1.2955e-03, -7.5546e-03,  ...,  1.5132e-02,\n",
       "            -3.2439e-03, -3.3831e-02],\n",
       "           [-2.2708e-06,  9.5737e-01, -1.1237e-01,  ...,  3.1202e-03,\n",
       "            -5.0380e-03,  6.8534e-02],\n",
       "           [ 4.2752e-07, -9.8664e-02, -9.5005e-01,  ...,  3.3325e-02,\n",
       "            -6.2778e-02,  7.3568e-04],\n",
       "           ...,\n",
       "           [ 5.9158e-08,  9.1380e-05,  1.7603e-03,  ...,  1.3446e-01,\n",
       "            -1.7509e-01,  7.6096e-03],\n",
       "           [ 1.0984e-07,  5.6857e-05,  2.0043e-04,  ...,  1.7109e-01,\n",
       "             1.9486e-01,  4.3957e-02],\n",
       "           [ 6.4363e-08,  9.1187e-04,  1.4044e-03,  ..., -7.4637e-02,\n",
       "            -1.3913e-02,  3.4338e-01]]]),\n",
       "  'C_gt_yx': tensor([[[-9.9999e-01,  3.5022e-03,  7.5244e-03,  ...,  1.3961e-02,\n",
       "             2.7893e-03,  1.1194e-03],\n",
       "           [-2.3066e-06,  1.0255e+00, -1.1577e-01,  ...,  7.0761e-03,\n",
       "            -2.8997e-03, -2.2068e-02],\n",
       "           [-6.8427e-08, -1.1218e-01, -1.0329e+00,  ...,  6.6181e-03,\n",
       "             7.0921e-04,  9.1106e-03],\n",
       "           ...,\n",
       "           [-1.5389e-07,  2.9021e-04,  5.9294e-04,  ...,  1.1173e-01,\n",
       "             1.9287e-01, -7.9721e-02],\n",
       "           [ 1.1803e-10,  6.9502e-04,  6.3797e-04,  ..., -6.9786e-02,\n",
       "             1.4628e-01, -1.9725e-03],\n",
       "           [ 6.8393e-09,  9.8688e-04, -2.5693e-04,  ..., -7.6456e-02,\n",
       "            -6.1292e-03,  2.5199e-01]]])}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset[12]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

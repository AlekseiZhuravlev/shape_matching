{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D-CODED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import metrics.geodist_metric as geodist_metric\n",
    "from utils.shape_util import compute_geodesic_distmat\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_geo_err_3dcoded(dataset_name):\n",
    "\n",
    "    single_dataset, pair_dataset = data_loading.get_val_dataset(\n",
    "        dataset_name, 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    "    )\n",
    "\n",
    "    dist_mat_list = []\n",
    "\n",
    "    for i in tqdm(range(len(single_dataset))):\n",
    "\n",
    "        data_i = single_dataset[i]\n",
    "\n",
    "        dist_mat = torch.tensor(\n",
    "            compute_geodesic_distmat(data_i['verts'].numpy(), data_i['faces'].numpy())    \n",
    "        )\n",
    "        \n",
    "        dist_mat_list.append(dist_mat)\n",
    "\n",
    "    path_3dc = f'/lustre/mlnvme/data/s94zalek_hpc-shape_matching/results_baselines/3D_CODED/{dataset_name}'\n",
    "\n",
    "    geo_err_list = []\n",
    "\n",
    "    for i in tqdm(range(len(pair_dataset))):\n",
    "        \n",
    "        data_i = pair_dataset[i]\n",
    "        \n",
    "        first_idx = data_i['first']['id']\n",
    "        second_idx = data_i['second']['id']\n",
    "        \n",
    "        p2p_3dc = torch.tensor(\n",
    "            np.loadtxt(f'{path_3dc}/{first_idx}-{second_idx}.txt')\n",
    "        ).int()\n",
    "        \n",
    "        dist_x = dist_mat_list[first_idx]\n",
    "        dist_y = dist_mat_list[second_idx]\n",
    "        \n",
    "        corr_first = data_i['first']['corr']\n",
    "        corr_second = data_i['second']['corr']\n",
    "        \n",
    "        # geo_err = geodist_metric.calculate_geodesic_error(\n",
    "        #     dist_x, corr_first.cpu(), corr_second.cpu(), p2p_3dc, return_mean=True\n",
    "        # ) * 100\n",
    "        \n",
    "        geo_err = geodist_metric.calculate_geodesic_error(\n",
    "            dist_y, corr_second.cpu(), corr_first.cpu(), p2p_3dc, return_mean=True\n",
    "        ) * 100\n",
    "        \n",
    "        geo_err_list.append(geo_err)\n",
    "        \n",
    "    geo_err_list = torch.tensor(geo_err_list)\n",
    "    print(f'{dataset_name}, mean geo err: {geo_err_list.mean()}, median: {geo_err_list.median()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'FAUST_r_pair'\n",
    "\n",
    "single_dataset, pair_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    ")\n",
    "\n",
    "dist_mat_list = []\n",
    "\n",
    "for i in tqdm(range(len(single_dataset))):\n",
    "\n",
    "    data_i = single_dataset[i]\n",
    "\n",
    "    dist_mat = torch.tensor(\n",
    "        compute_geodesic_distmat(data_i['verts'].numpy(), data_i['faces'].numpy())    \n",
    "    )\n",
    "    \n",
    "    dist_mat_list.append(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_err_transmatch(dataset_name):\n",
    "    single_dataset, pair_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    "    )\n",
    "\n",
    "    dist_mat_list = []\n",
    "\n",
    "    for i in tqdm(range(len(single_dataset))):\n",
    "\n",
    "        data_i = single_dataset[i]\n",
    "\n",
    "        dist_mat = torch.tensor(\n",
    "            compute_geodesic_distmat(data_i['verts'].numpy(), data_i['faces'].numpy())    \n",
    "        )\n",
    "        \n",
    "        dist_mat_list.append(dist_mat)\n",
    "\n",
    "\n",
    "\n",
    "    path = f'/home/s94zalek_hpc/baselines/transmatching/evaluation/predictions/{dataset_name}/our(ckp=s2s_weighted_bary,refine=True,area_norm=True,refine_steps=100)'\n",
    "\n",
    "    geo_err_list = []\n",
    "\n",
    "    for i in tqdm(range(len(pair_dataset))):\n",
    "        \n",
    "        data_i = pair_dataset[i]\n",
    "        \n",
    "        first_idx = data_i['first']['id']\n",
    "        second_idx = data_i['second']['id']\n",
    "        \n",
    "        p2p = torch.tensor(\n",
    "            np.loadtxt(f'{path}/{i:03d}/pred_matching_A_to_B.txt')\n",
    "        ).to(torch.int64)\n",
    "        \n",
    "        # print(f'{path}/{i:03d}/pred_matching_A_to_B.txt')\n",
    "        \n",
    "        dist_x = dist_mat_list[first_idx]\n",
    "        dist_y = dist_mat_list[second_idx]\n",
    "        \n",
    "        corr_first = data_i['first']['corr']\n",
    "        corr_second = data_i['second']['corr']\n",
    "        \n",
    "        # geo_err = geodist_metric.calculate_geodesic_error(\n",
    "        #     dist_x, corr_first.cpu(), corr_second.cpu(), p2p, return_mean=True\n",
    "        # ) * 100\n",
    "        \n",
    "        geo_err = geodist_metric.calculate_geodesic_error(\n",
    "            dist_y, corr_second.cpu(), corr_first.cpu(), p2p, return_mean=True\n",
    "        ) * 100\n",
    "        \n",
    "        geo_err_list.append(geo_err)\n",
    "        \n",
    "        # break\n",
    "        \n",
    "    geo_err_list = torch.tensor(geo_err_list)\n",
    "    print(f'{dataset_name}, mean geo err: {geo_err_list.mean()}, median: {geo_err_list.median()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\n",
    "        'FAUST_r_pair',\n",
    "        'FAUST_a_pair', \n",
    "        'SCAPE_r_pair',\n",
    "        'SCAPE_a_pair',\n",
    "        'SHREC19_r_pair'\n",
    "        ]:\n",
    "    get_geo_err_transmatch(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConsistentFmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = f'/home/s94zalek_hpc/baselines/Spatially-and-Spectrally-Consistent-Deep-Functional-Maps/data/results/{dataset_name[:-5]}/p2p_21'\n",
    "\n",
    "geo_err_list = []\n",
    "\n",
    "for i in tqdm(range(len(pair_dataset))):\n",
    "    \n",
    "    data_i = pair_dataset[i]\n",
    "    \n",
    "    first_idx = data_i['first']['id']\n",
    "    second_idx = data_i['second']['id']\n",
    "    \n",
    "    p2p = torch.tensor(\n",
    "        np.loadtxt(f'{path}/{first_idx}_{second_idx}.txt')\n",
    "    ).int()\n",
    "    \n",
    "    dist_x = dist_mat_list[first_idx]\n",
    "    dist_y = dist_mat_list[second_idx]\n",
    "    \n",
    "    corr_first = data_i['first']['corr']\n",
    "    corr_second = data_i['second']['corr']\n",
    "    \n",
    "    geo_err = geodist_metric.calculate_geodesic_error(\n",
    "        dist_x, corr_first.cpu(), corr_second.cpu(), p2p, return_mean=True\n",
    "    ) * 100\n",
    "    \n",
    "    # geo_err = geodist_metric.calculate_geodesic_error(\n",
    "    #     dist_y, corr_second.cpu(), corr_first.cpu(), p2p, return_mean=True\n",
    "    # ) * 100\n",
    "    \n",
    "    geo_err_list.append(geo_err)\n",
    "    \n",
    "    # print(geo_err)\n",
    "    # break\n",
    "    \n",
    "geo_err_list = torch.tensor(geo_err_list)\n",
    "print(f'{dataset_name}, mean geo err: {geo_err_list.mean()}, median: {geo_err_list.median()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "path = f'/home/s94zalek_hpc/baselines/SimplifiedFmapsLearning/res_cache/train_faust/test_shrec19/maps'\n",
    "# path = f'/home/s94zalek_hpc/baselines/SimplifiedFmapsLearning/res_cache/train_faust/test_faust_24-11-04_17-06-01/maps'\n",
    "# path = f'/home/s94zalek_hpc/baselines/SimplifiedFmapsLearning/res_cache/train_faust/test_scape_24-11-04_17-25-39/maps'\n",
    "\n",
    "geo_err_list = []\n",
    "\n",
    "for i in tqdm(range(len(pair_dataset))):\n",
    "    \n",
    "    # i = 4\n",
    "    \n",
    "    data_i = pair_dataset[i]\n",
    "    \n",
    "    first_idx = data_i['first']['id']\n",
    "    second_idx = data_i['second']['id']\n",
    "    \n",
    "    off_file_first = single_dataset.off_files[first_idx]\n",
    "    off_file_second = single_dataset.off_files[second_idx]\n",
    "\n",
    "    # from data/FAUST_r/off/tr_reg_080.off get tr_reg_080\n",
    "    first_off_name = off_file_first.split('/')[-1].split('.')[0]\n",
    "    second_off_name = off_file_second.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    pickled_file = f'{path}/{second_off_name}-{first_off_name}.p'   \n",
    "    with open(pickled_file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    p2p = data['pmap10_ref'].cpu()\n",
    "        \n",
    "    # print(data)\n",
    "    # break\n",
    "    \n",
    "    # p2p = torch.tensor(\n",
    "    #     np.loadtxt(f'{path}/{first_idx}_{second_idx}.txt')\n",
    "    # ).int()\n",
    "    \n",
    "    dist_x = dist_mat_list[first_idx]\n",
    "    dist_y = dist_mat_list[second_idx]\n",
    "    \n",
    "    corr_first = data_i['first']['corr']\n",
    "    corr_second = data_i['second']['corr']\n",
    "    \n",
    "    # geo_err = geodist_metric.calculate_geodesic_error(\n",
    "    #     dist_x, corr_first.cpu(), corr_second.cpu(), p2p, return_mean=True\n",
    "    # ) * 100\n",
    "    \n",
    "    geo_err = geodist_metric.calculate_geodesic_error(\n",
    "        dist_y, corr_second.cpu(), corr_first.cpu(), p2p, return_mean=True\n",
    "    ) * 100\n",
    "    \n",
    "    geo_err_list.append(geo_err)\n",
    "    \n",
    "    # print(geo_err)\n",
    "    # break\n",
    "    \n",
    "geo_err_list = torch.tensor(geo_err_list)\n",
    "print(f'{dataset_name}, mean geo err: {geo_err_list.mean()}, median: {geo_err_list.median()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAUST_a_pair, mean geo err: 12.689779487620378, median: 5.11637879633151"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHREC19_r_pair, mean geo err: 6.349553541101691, median: 4.081554091554718\n",
    "\n",
    "SCAPE_a_pair, mean geo err: 8.630594943047253, median: 2.7107606137821887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_err_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "# i = 1\n",
    "# data_i = pair_dataset[i]\n",
    "\n",
    "# first_idx = data_i['first']['id']\n",
    "# second_idx = data_i['second']['id']\n",
    "\n",
    "# p2p = torch.tensor(\n",
    "#     # np.loadtxt(f'{path}/{i:03d}/pred_matching_A_to_B.txt')\n",
    "#     np.loadtxt('/home/s94zalek_hpc/baselines/transmatching/evaluation/predictions/FAUST_r_pair/our(ckp=s2s_weighted_bary,refine=True,area_norm=True,refine_steps=100)/001/pred_matching_A_to_B.txt')\n",
    "# ).to(torch.int64)\n",
    "    \n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    \n",
    "    \n",
    "    data_i['second']['verts'], data_i['second']['faces'],\n",
    "    data_i['first']['verts'], data_i['first']['faces'],\n",
    "    \n",
    "    p2p,\n",
    "    axes_color_gradient=[0, 1],\n",
    "    base_cmap='hsv'\n",
    ")\n",
    "\n",
    "scene.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

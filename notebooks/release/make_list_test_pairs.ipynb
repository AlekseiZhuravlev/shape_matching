{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_name_list = [\n",
    "    # 'SHREC19_r_pair',\n",
    "    'FAUST_r_pair',\n",
    "    'FAUST_a_pair',\n",
    "    'SCAPE_r_pair',\n",
    "    'SCAPE_a_pair',\n",
    "]\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "\n",
    "    single_dataset, pair_dataset = data_loading.get_val_dataset(\n",
    "        dataset_name, 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    "    )\n",
    "\n",
    "    off_pair_list = []\n",
    "\n",
    "    for i in tqdm(range(len(pair_dataset))):\n",
    "        \n",
    "        data_i = pair_dataset[i]\n",
    "        \n",
    "        first_index = data_i['first']['id']\n",
    "        second_index = data_i['second']['id']\n",
    "        \n",
    "        off_first = single_dataset.off_files[first_index]\n",
    "        off_second = single_dataset.off_files[second_index]\n",
    "        \n",
    "        # print(first_index)\n",
    "        # print(second_index)\n",
    "        \n",
    "        # print(off_first)\n",
    "        # print(off_second)\n",
    "        \n",
    "        off_pair_list.append({\n",
    "            'first': first_index.item(),\n",
    "            'second': second_index.item(),\n",
    "            'off_first': f'/home/s94zalek_hpc/shape_matching/{off_first}',\n",
    "            'off_second': f'/home/s94zalek_hpc/shape_matching/{off_second}'\n",
    "        })\n",
    "\n",
    "    with open(f'/home/s94zalek_hpc/shape_matching/notebooks/release/evaluation_pairs/{dataset_name}.yaml', 'w') as f:\n",
    "        yaml.dump(off_pair_list, f, sort_keys=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "mesh_1 = trimesh.load('/home/s94zalek_hpc/shape_matching/data/SCAPE_a/off/mesh054.off')\n",
    "\n",
    "mesh_2 = trimesh.load(\n",
    "    '/home/s94zalek_hpc/shape_matching/data/FAUST_a/off/tr_reg_080.off'\n",
    ")\n",
    "\n",
    "verts_1 = mesh_1.vertices.copy()\n",
    "\n",
    "# full_data['verts'][:, 0] = verts_first_raw[:, 0]\n",
    "# full_data['verts'][:, 1] = verts_first_raw[:, 2]\n",
    "# full_data['verts'][:, 2] = -verts_first_raw[:, 1]\n",
    "\n",
    "# mesh_1.vertices[:, 0] = verts_1[:, 1]\n",
    "# mesh_1.vertices[:, 1] = verts_1[:, 0]\n",
    "# mesh_1.vertices[:, 2] = verts_1[:, 2]\n",
    "\n",
    "verts_1_fixed = verts_1.copy()\n",
    "verts_1_fixed[:, 0] = -verts_1[:, 1]\n",
    "verts_1_fixed[:, 1] = verts_1[:, 0]\n",
    "verts_1_fixed[:, 2] = verts_1[:, 2]\n",
    "\n",
    "mesh_1 = trimesh.Trimesh(vertices=verts_1_fixed, faces=mesh_1.faces)\n",
    "\n",
    "\n",
    "mesh_3 = trimesh.load(\n",
    "    '/home/s94zalek_hpc/shape_matching/data/SHREC19_r/off/1.off'\n",
    ")\n",
    "\n",
    "scene.add_geometry(mesh_1)\n",
    "scene.add_geometry(mesh_2)\n",
    "scene.add_geometry(mesh_3)\n",
    "\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mesh_1.area_faces.sum())\n",
    "print(mesh_2.area_faces.sum())\n",
    "print(mesh_3.area_faces.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each mesh in /home/s94zalek_hpc/shape_matching/data/FAUST_a/off\n",
    "\n",
    "import os\n",
    "\n",
    "for off_file in os.listdir('/home/s94zalek_hpc/shape_matching/data/SCAPE_a/off'):\n",
    "    mesh = trimesh.load(f'/home/s94zalek_hpc/shape_matching/data/SCAPE_a/off/{off_file}', process=False)\n",
    "    \n",
    "    # verts_1_fixed = verts_1.copy()\n",
    "    # verts_1_fixed[:, 0] = -verts_1[:, 1]\n",
    "    # verts_1_fixed[:, 1] = verts_1[:, 0]\n",
    "    # verts_1_fixed[:, 2] = verts_1[:, 2]\n",
    "    \n",
    "    verts_fixed = mesh.vertices.copy()\n",
    "    verts_fixed[:, 0] = -mesh.vertices[:, 1]\n",
    "    verts_fixed[:, 1] = mesh.vertices[:, 0]\n",
    "    verts_fixed[:, 2] = mesh.vertices[:, 2]\n",
    "    \n",
    "    mesh = trimesh.Trimesh(vertices=verts_fixed, faces=mesh.faces, process=False)\n",
    "    # save the mesh\n",
    "    mesh.export(f'/home/s94zalek_hpc/shape_matching/data/SCAPE_a/off/{off_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "mesh_new = trimesh.load('/home/s94zalek_hpc/shape_matching/data/SCAPE_a/off/mesh055.off')\n",
    "mesh_old = trimesh.load('/home/s94zalek_hpc/shape_matching/data/SCAPE_a/off_old/mesh055.off')\n",
    "mesh_old.vertices += [1, 0, 0]\n",
    "\n",
    "\n",
    "scene.add_geometry(mesh_new)\n",
    "\n",
    "scene.add_geometry(mesh_old)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each mesh in /home/s94zalek_hpc/shape_matching/data/SCAPE_a/off\n",
    "\n",
    "import os\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "dataset = 'SCAPE_a'\n",
    "\n",
    "for i, off_file in enumerate(os.listdir(f'/home/s94zalek_hpc/shape_matching/data/{dataset}/off')[:20]):\n",
    "    \n",
    "    mesh = trimesh.load(f'/home/s94zalek_hpc/shape_matching/data/{dataset}/off/{off_file}', process=False)\n",
    "    \n",
    "    mesh.vertices += [i, 0, 0]\n",
    "    \n",
    "    scene.add_geometry(mesh)\n",
    "    \n",
    "scene.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.load('/home/s94zalek_hpc/shape_matching/data/SHREC19_r/off/12.off')\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_str = 'mesh/dsds.off'\n",
    "bad_str.replace('/', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "dataset_name_list = [\n",
    "    'SHREC19_r_pair',\n",
    "    # 'FAUST_r_pair',\n",
    "    'FAUST_a_pair',\n",
    "    'SCAPE_r_pair',\n",
    "    'SCAPE_a_pair',\n",
    "]\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    \n",
    "    path_transmatch = f'/home/s94zalek_hpc/baselines/transmatching/evaluation/datasets/{dataset_name}/data'\n",
    "    \n",
    "    if os.path.exists(path_transmatch):\n",
    "        os.system(f'rm -r {path_transmatch}')\n",
    "    \n",
    "    os.makedirs(path_transmatch, exist_ok=True)\n",
    "    \n",
    "\n",
    "    single_dataset, pair_dataset = data_loading.get_val_dataset(\n",
    "        dataset_name, 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    "    )\n",
    "\n",
    "    for i in tqdm(range(len(pair_dataset))):\n",
    "        \n",
    "        data_i = pair_dataset[i]\n",
    "        \n",
    "        first_index = data_i['first']['id']\n",
    "        second_index = data_i['second']['id']\n",
    "        \n",
    "        off_first = single_dataset.off_files[first_index]\n",
    "        off_second = single_dataset.off_files[second_index]\n",
    "        \n",
    "        \n",
    "        path_i = f'{path_transmatch}/{i:03d}'\n",
    "        os.makedirs(path_i, exist_ok=True)\n",
    "        \n",
    "        \n",
    "        mesh_first = trimesh.load(off_first, process=False, validate=False)\n",
    "        mesh_second = trimesh.load(off_second, process=False, validate=False)\n",
    "        \n",
    "        # mesh_first.vertices = mesh_first.vertices / mesh_first.area_faces.sum() ** 0.5\n",
    "        \n",
    "        assert 0.99 < mesh_first.area_faces.sum() < 1.01, f'mesh_first.area_faces.sum() = {mesh_first.area_faces.sum()}'\n",
    "        assert 0.99 < mesh_second.area_faces.sum() < 1.01, f'mesh_second.area_faces.sum() = {mesh_second.area_faces.sum()}'\n",
    "        \n",
    "        mesh_first.export(f'{path_i}/A.off')\n",
    "        mesh_second.export(f'{path_i}/B.off')\n",
    "\n",
    "        meta_dict = {\n",
    "            'id': {\n",
    "                'A': first_index.item(),\n",
    "                'B': second_index.item()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(f'{path_i}/meta.json', 'w') as f:\n",
    "            json.dump(meta_dict, f)\n",
    "            \n",
    "        # break\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(first_index)\n",
    "        # print(second_index)\n",
    "        \n",
    "        # print(off_first)\n",
    "        # print(off_second)\n",
    "        \n",
    "        # off_pair_list.append({\n",
    "        #     'first': first_index.item(),\n",
    "        #     'second': second_index.item(),\n",
    "        #     'off_first': f'/home/s94zalek_hpc/shape_matching/{off_first}',\n",
    "        #     'off_second': f'/home/s94zalek_hpc/shape_matching/{off_second}'\n",
    "        # })\n",
    "\n",
    "    # with open(f'/home/s94zalek_hpc/shape_matching/notebooks/release/evaluation_pairs/{dataset_name}.yaml', 'w') as f:\n",
    "    #     yaml.dump(off_pair_list, f, sort_keys=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_first.scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

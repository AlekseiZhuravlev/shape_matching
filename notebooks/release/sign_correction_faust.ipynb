{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "\n",
    "train_dataset_template = data_loading.get_val_dataset(\n",
    "    'FAUST_orig', 'train', 128, preload=False, return_evecs=True, centering='bbox'\n",
    "    )[1]\n",
    "test_dataset_single = data_loading.get_val_dataset(\n",
    "    'FAUST_orig', 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    ")[0]\n",
    "test_dataset_template = data_loading.get_val_dataset(\n",
    "    'FAUST_orig', 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    ")[1]\n",
    "\n",
    "test_dataset_single = [test_dataset_single[i] for i in range(len(test_dataset_single))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networks.diffusion_network as diffusion_network\n",
    "import yaml\n",
    "\n",
    "\n",
    "# exp_name = 'signNet_64_remeshed_mass_6b_1-2ev_10_0.2_0.8'\n",
    "# exp_name = 'signNet_64_FAUST_orig_1k'\n",
    "exp_name = 'signNet_32_FAUST_orig'\n",
    "\n",
    "exp_dir = f'/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_net/{exp_name}'\n",
    "\n",
    "with open(f'{exp_dir}/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "start_dim = config['start_dim']\n",
    "feature_dim = config['feature_dim']\n",
    "evecs_per_support = config['evecs_per_support']\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = diffusion_network.DiffusionNet(\n",
    "    **config['net_params']\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.sign_canonicalization.test_sign_correction as test_sign_correction\n",
    "\n",
    "err_per_iter = []\n",
    "# # for n_iter in range(0, 4000 + 1, 400):\n",
    "# for n_iter in [0, 100, 200, 300, 400, 500, 600, 700, 800, 900]:\n",
    "for n_iter in [0, 4000]:\n",
    "\n",
    "    net.load_state_dict(torch.load(f'{exp_dir}/{n_iter}.pth'))\n",
    "    \n",
    "    mean_incorrect_signs, _ = test_sign_correction.test_on_dataset(\n",
    "        net, test_dataset_single,\n",
    "        config=config, n_epochs=100)\n",
    "    \n",
    "    print(f'{n_iter}.pth: {mean_incorrect_signs:.2f}')\n",
    "    err_per_iter.append((n_iter, mean_incorrect_signs, _))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n_iter, mean_incorrect_signs, _) in err_per_iter:\n",
    "    print(f'{n_iter}.pth: {mean_incorrect_signs / 32 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the summary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.sign_canonicalization.training as sign_training\n",
    "\n",
    "# net.load_state_dict(torch.load(f'{exp_dir}/2000.pth'))\n",
    "net.load_state_dict(torch.load(f'{exp_dir}/4000.pth'))\n",
    "# net.load_state_dict(torch.load(f'{exp_dir}/50000.pth'))\n",
    "\n",
    "# for curr_idx in range(len(test_dataset_single)):\n",
    "for curr_idx in [11]:\n",
    "\n",
    "    ##############################################\n",
    "    # Select a shape\n",
    "    ##############################################\n",
    "\n",
    "    train_shape = test_dataset_single[curr_idx]           \n",
    "    \n",
    "    ##############################################\n",
    "    # Set the variables\n",
    "    ##############################################\n",
    "\n",
    "    # train_shape = double_shape['second']\n",
    "    verts = train_shape['verts'].unsqueeze(0).to(device)\n",
    "    faces = train_shape['faces'].unsqueeze(0).to(device)    \n",
    "\n",
    "    evecs_orig = train_shape['evecs'].unsqueeze(0)[:, :, config['start_dim']:config['start_dim']+config['feature_dim']].to(device)\n",
    "    \n",
    "    if 'with_mass' in config and config['with_mass']:\n",
    "        mass_mat = torch.diag_embed(\n",
    "            train_shape['mass'].unsqueeze(0)\n",
    "            ).to(device)\n",
    "    else:\n",
    "        mass_mat = None\n",
    "\n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_0, supp_vec_0, prod_0 = sign_training.predict_sign_change(\n",
    "            net, verts, faces, evecs_orig, \n",
    "            mass_mat=mass_mat, input_type=net.input_type,\n",
    "            evecs_per_support=config['evecs_per_support'],\n",
    "            mass=train_shape['mass'].unsqueeze(0), L=train_shape['L'].unsqueeze(0),\n",
    "            evals=train_shape['evals'].unsqueeze(0), evecs=train_shape['evecs'].unsqueeze(0),\n",
    "            gradX=train_shape['gradX'].unsqueeze(0), gradY=train_shape['gradY'].unsqueeze(0)\n",
    "            )\n",
    "        \n",
    "    if 'with_mass' in config and config[\"with_mass\"]:\n",
    "\n",
    "        print('Using mass')\n",
    "\n",
    "        supp_vec_norm = torch.nn.functional.normalize(\n",
    "            supp_vec_0[0].transpose(0, 1) \\\n",
    "                @ mass_mat[0],\n",
    "            p=2, dim=1)\n",
    "        \n",
    "        evecs_cond = supp_vec_norm @ evecs_orig[0]\n",
    "        supp_vec_norm = supp_vec_norm.transpose(0, 1).unsqueeze(0)\n",
    "\n",
    "    else:\n",
    "        print('Not using mass')\n",
    "        \n",
    "        supp_vec_norm = torch.nn.functional.normalize(\n",
    "            supp_vec_0[0].transpose(0, 1),\n",
    "            p=2, dim=1)\n",
    "        evecs_cond = supp_vec_norm @ evecs_orig[0]\n",
    "        supp_vec_norm = supp_vec_norm.transpose(0, 1).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "# material=trimesh.visual.material.SimpleMaterial(\n",
    "#         image=None,\n",
    "#         diffuse=[240] * 4,\n",
    "#         # glossiness=0.5,\n",
    "#     )\n",
    "# mesh1.visual.material = material\n",
    "\n",
    "\n",
    "evec_id = 15\n",
    "\n",
    "# supp_vec = supp_vec_0[0, :, evec_id].cpu()\n",
    "supp_vec = supp_vec_norm[0, :, evec_id].cpu()\n",
    "\n",
    "# supp_vec is a vector in [-1, 1]\n",
    "# make that the minimum negative value and maximum positive value have the same absolute value\n",
    "# but the zero value is still zero\n",
    "max_abs = torch.max(torch.abs(supp_vec))\n",
    "\n",
    "idx_min = torch.argmin(supp_vec)\n",
    "idx_max = torch.argmax(supp_vec)\n",
    "\n",
    "supp_vec[idx_min] = -max_abs\n",
    "supp_vec[idx_max] = max_abs\n",
    "\n",
    "\n",
    "mesh1 = trimesh.Trimesh(verts[0].cpu().numpy(), faces[0].cpu().numpy())\n",
    "cmap1 = trimesh.visual.color.interpolate(supp_vec, 'bwr')\n",
    "\n",
    "# smooth the colors\n",
    "# cmap1 = (cmap1.astype(np.int32) + np.roll(cmap1.astype(np.int32), 1) + np.roll(cmap1.astype(np.int32), -1)) / 3\n",
    "# cmap1 = cmap1.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "cmap1_faces = trimesh.visual.color.vertex_to_face_color(cmap1, mesh1.faces)\n",
    "mesh1.visual.face_colors = cmap1_faces.clip(0, 255).astype(np.uint8)\n",
    "# mesh1.visual.vertex_colors = cmap1[:len(mesh1.vertices)].clip(0, 255).astype(np.uint8)\n",
    "\n",
    "mesh2 = trimesh.Trimesh(verts[0].cpu().numpy() + np.array([1, 0, 0]), faces[0].cpu().numpy())\n",
    "cmap2 = trimesh.visual.color.interpolate(evecs_orig[0, :, evec_id].cpu().numpy(), 'bwr')\n",
    "# mesh2.visual.vertex_colors = cmap2[:len(mesh2.vertices)].clip(0, 255).astype(np.uint8)\n",
    "\n",
    "cmap2_faces = trimesh.visual.color.vertex_to_face_color(cmap2, mesh2.faces)\n",
    "mesh2.visual.face_colors = cmap2_faces.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "scene.add_geometry(mesh1)\n",
    "scene.add_geometry(mesh2)\n",
    "\n",
    "scene.set_camera(angles=(-0.5, 0, 0), distance=(1.7), center=(0.5, 0, 0), resolution=None, fov=None)\n",
    "\n",
    "light = trimesh.scene.lighting.DirectionalLight(color=[255, 255, 255, 255])\n",
    "scene.lights = [light]\n",
    "\n",
    "print(f'evec n {evec_id + 1}')\n",
    "print(f'projection {prod_0[0][evec_id, evec_id].item():.2f}')\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "l = 0\n",
    "h = 64\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs, prod_0[0].cpu(), 'Projection', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].plot(supp_vec_norm[0, :, 16].cpu().numpy())\n",
    "ax[1].plot(supp_vec)\n",
    "\n",
    "# plt.plot(supp_vec_0[0, :, 16].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "C_xy_pred_list = torch.tensor([])\n",
    "C_xy_orig_list = torch.tensor([])\n",
    "prod_with_support_list = torch.tensor([])\n",
    "supp_vec_list = torch.tensor([])\n",
    "\n",
    "data_0 = train_dataset_template[0]\n",
    "verts_first = data_0['first']['verts'].unsqueeze(0).to(device)\n",
    "faces_first = data_0['first']['faces'].unsqueeze(0).to(device)\n",
    "evecs_first = data_0['first']['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "corr_first = data_0['first']['corr']\n",
    "mass_mat_first = torch.diag_embed(data_0['first']['mass'].unsqueeze(0)).to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    sign_pred_first = sign_training.predict_sign_change(\n",
    "        net, verts_first, faces_first, evecs_first, \n",
    "        mass_mat=mass_mat_first, input_type=net.input_type,\n",
    "        evecs_per_support=config['evecs_per_support'],\n",
    "        mass=data_0['first']['mass'].unsqueeze(0), L=data_0['first']['L'].unsqueeze(0),\n",
    "        evals=data_0['first']['evals'].unsqueeze(0), evecs=data_0['first']['evecs'].unsqueeze(0),\n",
    "        gradX=data_0['first']['gradX'].unsqueeze(0), gradY=data_0['first']['gradY'].unsqueeze(0)\n",
    "        )[0]\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(train_dataset_template))):\n",
    "    # data_0 = test_dataset[12]\n",
    "    data_0 = train_dataset_template[i]\n",
    "\n",
    "    verts_second = data_0['second']['verts'].unsqueeze(0).to(device)\n",
    "    faces_second = data_0['second']['faces'].unsqueeze(0).to(device)\n",
    "    evecs_second = data_0['second']['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "    corr_second = data_0['second']['corr']\n",
    "    \n",
    "    mass_mat_second = torch.diag_embed(data_0['second']['mass'].unsqueeze(0)).to(device)\n",
    "\n",
    "    C_gt_xy = data_0['second']['C_gt_xy'][0]\n",
    "\n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_second, supp_vec_second, prod_with_support = sign_training.predict_sign_change(\n",
    "            net, verts_second, faces_second, evecs_second, \n",
    "            mass_mat=mass_mat_second, input_type=net.input_type,\n",
    "            evecs_per_support=config['evecs_per_support'],\n",
    "            mass=data_0['second']['mass'].unsqueeze(0), L=data_0['second']['L'].unsqueeze(0),\n",
    "            evals=data_0['second']['evals'].unsqueeze(0), evecs=data_0['second']['evecs'].unsqueeze(0),\n",
    "            gradX=data_0['second']['gradX'].unsqueeze(0), gradY=data_0['second']['gradY'].unsqueeze(0)\n",
    "            )\n",
    "\n",
    "    C_xy_pred = torch.linalg.lstsq(\n",
    "        evecs_second.cpu()[0, corr_second] * torch.sign(sign_pred_second).cpu(),\n",
    "        evecs_first.cpu()[0, corr_first] * torch.sign(sign_pred_first).cpu()\n",
    "        ).solution\n",
    "    \n",
    "    C_xy_pred_list = torch.cat([C_xy_pred_list, C_xy_pred.unsqueeze(0)])\n",
    "    C_xy_orig_list = torch.cat([C_xy_orig_list, C_gt_xy.unsqueeze(0)])\n",
    "    prod_with_support_list = torch.cat([prod_with_support_list, prod_with_support.cpu()])\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(test_dataset_template))):\n",
    "    # data_0 = test_dataset[12]\n",
    "    data_0 = test_dataset_template[i]\n",
    "\n",
    "    verts_second = data_0['second']['verts'].unsqueeze(0).to(device)\n",
    "    faces_second = data_0['second']['faces'].unsqueeze(0).to(device)\n",
    "    evecs_second = data_0['second']['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "    corr_second = data_0['second']['corr']\n",
    "    \n",
    "    mass_mat_second = torch.diag_embed(data_0['second']['mass'].unsqueeze(0)).to(device)\n",
    "\n",
    "    C_gt_xy = data_0['second']['C_gt_xy'][0]\n",
    "\n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_second, supp_vec_second, prod_with_support = sign_training.predict_sign_change(\n",
    "            net, verts_second, faces_second, evecs_second, \n",
    "            mass_mat=mass_mat_second, input_type=net.input_type,\n",
    "            evecs_per_support=config['evecs_per_support'],\n",
    "            mass=data_0['second']['mass'].unsqueeze(0), L=data_0['second']['L'].unsqueeze(0),\n",
    "            evals=data_0['second']['evals'].unsqueeze(0), evecs=data_0['second']['evecs'].unsqueeze(0),\n",
    "            gradX=data_0['second']['gradX'].unsqueeze(0), gradY=data_0['second']['gradY'].unsqueeze(0)\n",
    "            )\n",
    "\n",
    "    C_xy_pred = torch.linalg.lstsq(\n",
    "        evecs_second.cpu()[0, corr_second] * torch.sign(sign_pred_second).cpu(),\n",
    "        evecs_first.cpu()[0, corr_first] * torch.sign(sign_pred_first).cpu()\n",
    "        ).solution\n",
    "    \n",
    "    C_xy_pred_list = torch.cat([C_xy_pred_list, C_xy_pred.unsqueeze(0)])\n",
    "    C_xy_orig_list = torch.cat([C_xy_orig_list, C_gt_xy.unsqueeze(0)])\n",
    "    prod_with_support_list = torch.cat([prod_with_support_list, prod_with_support.cpu()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "h = 32\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0, 0], C_xy_orig_list[81], 'C_xy_orig', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[0, 1], C_xy_pred_list[81], 'C_xy_pred', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[1, 0], C_xy_orig_list[82], 'C_xy_pred', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1, 1], C_xy_pred_list[82], 'C_xy_pred', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "C_xy_pred_list_scaled = scaler.fit_transform(C_xy_pred_list.reshape(C_xy_pred_list.shape[0], -1))\n",
    "C_xy_pred_list_pca = pca.fit_transform(C_xy_pred_list_scaled)\n",
    "\n",
    "pca_df_pred = pd.DataFrame(C_xy_pred_list_pca[:, :2], columns=[f'PCA_{i}' for i in range(2)])\n",
    "pca_df_pred['body_type'] = [i // 10 for i in range(C_xy_pred_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "C_xy_orig_list_scaled = scaler.fit_transform(C_xy_orig_list.reshape(C_xy_orig_list.shape[0], -1))\n",
    "C_xy_orig_list_pca = pca.fit_transform(C_xy_orig_list_scaled)\n",
    "pca_df_orig = pd.DataFrame(C_xy_orig_list_pca[:, :2], columns=[f'PCA_{i}' for i in range(2)])\n",
    "pca_df_orig['body_type'] = [i // 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "\n",
    "sns_plot_orig = sns.scatterplot(data=pca_df_orig, x='PCA_0', y='PCA_1', hue='body_type', palette='tab10',\n",
    "                s=50, ax=axs[0], legend=False\n",
    ")\n",
    "sns_plot_pred = sns.scatterplot(data=pca_df_pred, x='PCA_0', y='PCA_1', hue='body_type', palette='tab10',\n",
    "                s=50, ax=axs[1]\n",
    ")\n",
    "\n",
    "axs[0].set_title('PCA on original')\n",
    "axs[1].set_title('PCA on predicted')\n",
    "\n",
    "axs[0].set_xlim(-20, 20)\n",
    "axs[0].set_ylim(-20, 20)\n",
    "\n",
    "axs[1].set_xlim(-20, 25)\n",
    "axs[1].set_ylim(-20, 20)\n",
    "\n",
    "sns.move_legend(sns_plot_pred, 'upper right', bbox_to_anchor=(1.3, 1), ncol=1)\n",
    "\n",
    "print('PCA on predicted')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "C_xy_orig_list_scaled = scaler.fit_transform(C_xy_orig_list.reshape(C_xy_orig_list.shape[0], -1))\n",
    "C_xy_orig_list_pca = pca.fit_transform(C_xy_orig_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(C_xy_orig_list_pca[:, :2], columns=[f'PCA_{i}' for i in range(2)])\n",
    "\n",
    "# remove the outliers based on standard deviation\n",
    "# pca_df = pca_df[(np.abs(pca_df) < 50).all(axis=1)]\n",
    "\n",
    "\n",
    "# pca_df['name'] = names_y\n",
    "pca_df['body_type'] = [i // 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "\n",
    "pca_df = pca_df[(np.abs(pca_df) < np.std(pca_df) * 6\n",
    "                 ).all(axis=1)]\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde', hue='body_type', palette='tab10')\n",
    "\n",
    "print('PCA on original')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "prod_with_support_list_scaled = scaler.fit_transform(prod_with_support_list.reshape(prod_with_support_list.shape[0], -1))\n",
    "prod_with_support_list_pca = pca.fit_transform(prod_with_support_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(prod_with_support_list_pca[:, :3], columns=[f'PCA_{i}' for i in range(3)])\n",
    "# pca_df['name'] = names_y\n",
    "pca_df['body_type'] = [i // 10 for i in range(prod_with_support_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde', hue='body_type', palette='tab10')\n",
    "\n",
    "print('PCA on product with support')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_vec_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "# supp_vec_list_scaled = scaler.fit_transform(supp_vec_list.reshape(supp_vec_list.shape[0], -1))\n",
    "# supp_vec_list_pca = pca.fit_transform(supp_vec_list_scaled)\n",
    "\n",
    "supp_vec_list_scaled = scaler.fit_transform(\n",
    "    (supp_vec_list.transpose(1, 2) @ supp_vec_list).reshape(supp_vec_list.shape[0], -1)\n",
    "    )\n",
    "supp_vec_list_pca = pca.fit_transform(supp_vec_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(supp_vec_list_pca[:, :3], columns=[f'PCA_{i}' for i in range(3)])\n",
    "# pca_df['name'] = names_y\n",
    "pca_df['body_type'] = [i // 10 for i in range(supp_vec_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde', hue='body_type', palette='tab10')\n",
    "\n",
    "print('PCA on product with support')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supp_vec_list_product = supp_vec_list.transpose(1, 2) @ supp_vec_list\n",
    "supp_vec_list_product = supp_vec_list_scaled.reshape(supp_vec_list.shape[0], feature_dim, feature_dim)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axs_0 = axs[0].imshow(supp_vec_list_product[5], cmap='bwr')\n",
    "plt.colorbar(axs_0, ax=axs[0])\n",
    "\n",
    "axs_1 = axs[1].imshow(supp_vec_list_product[6], cmap='bwr')\n",
    "plt.colorbar(axs_1, ax=axs[1])\n",
    "\n",
    "axs_2 = axs[2].imshow(supp_vec_list_product[7], cmap='bwr')\n",
    "plt.colorbar(axs_2, ax=axs[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "# supp_vec_list_scaled = scaler.fit_transform(supp_vec_list.reshape(supp_vec_list.shape[0], -1))\n",
    "# supp_vec_list_pca = pca.fit_transform(supp_vec_list_scaled)\n",
    "\n",
    "supp_vec_list_scaled = scaler.fit_transform(\n",
    "    (supp_vec_list.transpose(1, 2) @ supp_vec_list).reshape(supp_vec_list.shape[0], -1)\n",
    "    )\n",
    "supp_vec_list_pca = pca.fit_transform(supp_vec_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(supp_vec_list_pca[:, :3], columns=[f'PCA_{i}' for i in range(3)])\n",
    "# pca_df['name'] = names_y\n",
    "pca_df['body_type'] = [i // 10 for i in range(supp_vec_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde', hue='body_type', palette='tab10')\n",
    "\n",
    "print('PCA on product with support')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

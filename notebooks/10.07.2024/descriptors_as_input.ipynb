{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networks.diffusion_network as diffusion_network\n",
    "import os\n",
    "import utils.geometry_util as geometry_util\n",
    "import utils.shape_util as shape_util\n",
    "from tqdm import tqdm\n",
    "\n",
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "start_dim = 0\n",
    "\n",
    "feature_dim = 64\n",
    "evecs_per_support = 4\n",
    "n_block = 6\n",
    "\n",
    "input_type = 'learned'\n",
    "lapl_type = 'mesh'\n",
    "\n",
    "train_folder = 'FAUST_rot_xyz_180_scaling_0.9_1.1'\n",
    "test_folder = 'FAUST_rot_xyz_180_scaling_0.9_1.1'\n",
    "\n",
    "chkpt_name = f'sign_double_start_{start_dim}_feat_{feature_dim}_{n_block}block_factor{evecs_per_support}_dataset_{train_folder}_{input_type}'\n",
    "\n",
    "\n",
    "\n",
    "experiment_dir = f'/home/s94zalek_hpc/shape_matching/my_code/experiments/{chkpt_name}'\n",
    "os.makedirs(experiment_dir)\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = diffusion_network.DiffusionNet(\n",
    "    in_channels=256,\n",
    "    out_channels=feature_dim // evecs_per_support,\n",
    "    cache_dir=None,\n",
    "    input_type='wks',\n",
    "    k_eig=128,\n",
    "    n_block=n_block,\n",
    "    ).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    opt, start_factor=1, end_factor=0.1, \n",
    "    total_iters=50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.sign_canonicalization.training as sign_training\n",
    "\n",
    "train_shapes, train_diff_folder = sign_training.load_cached_shapes(\n",
    "    f'/home/s94zalek_hpc/shape_matching/data_sign_training/train/{train_folder}',\n",
    "    lapl_type='mesh'\n",
    ")\n",
    "\n",
    "test_shapes, test_diff_folder = sign_training.load_cached_shapes(\n",
    "    f'/home/s94zalek_hpc/shape_matching/data_sign_training/test/{test_folder}',\n",
    "    lapl_type='mesh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 4 random training shapes to trimesh scene\n",
    "\n",
    "# np.random.shuffle(train_shapes)\n",
    "scene.geometry.clear()\n",
    "\n",
    "rand_idx_train = np.random.randint(0, len(train_shapes), 5)\n",
    "rand_idx_test = np.random.randint(0, len(test_shapes), 5)\n",
    "\n",
    "for i, idx in enumerate(rand_idx_train):\n",
    "    scene.add_geometry(trimesh.Trimesh(\n",
    "        vertices=train_shapes[idx]['verts'] + torch.tensor([i, 0, 0]),\n",
    "        faces=train_shapes[idx]['faces']))\n",
    "    \n",
    "for i, idx in enumerate(rand_idx_test):\n",
    "    scene.add_geometry(trimesh.Trimesh(\n",
    "        vertices=test_shapes[idx]['verts'] + torch.tensor([i, -1, 0]),\n",
    "        faces=test_shapes[idx]['faces']))\n",
    "    \n",
    "axis = trimesh.creation.axis(axis_length=1)\n",
    "scene.add_geometry(axis)\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_sign_change(net, verts, faces, evecs_flip, evecs_cond, input_type, cond_net=None):\n",
    "    \n",
    "    # normalize the evecs\n",
    "    evecs_flip = torch.nn.functional.normalize(evecs_flip, p=2, dim=1)\n",
    "    \n",
    "    if evecs_cond is not None:\n",
    "        evecs_cond = torch.nn.functional.normalize(evecs_cond, p=2, dim=1)\n",
    "        evecs_input = torch.cat([evecs_flip, evecs_cond], dim=-1)\n",
    "        \n",
    "    elif input_type == 'wks':\n",
    "        evecs_input = None\n",
    "    \n",
    "    elif input_type == 'learned':\n",
    "        evecs_input = cond_net(verts=verts, faces=faces)\n",
    "        evecs_input = torch.nn.functional.normalize(evecs_input, dim=-1, p=2)\n",
    "    \n",
    "    else:\n",
    "        evecs_input = evecs_flip\n",
    "        \n",
    "    # process the flipped evecs\n",
    "    support_vector_flip = net(\n",
    "        verts=verts,\n",
    "        faces=faces,\n",
    "        feats=evecs_input,\n",
    "    ) # [1 x 6890 x 1]\n",
    "\n",
    "    # normalize the support vector\n",
    "    support_vector_norm = torch.nn.functional.normalize(support_vector_flip, p=2, dim=1)\n",
    "    \n",
    "    if support_vector_norm.shape[-1] != evecs_flip.shape[-1]:\n",
    "        # copy each element to match the number of evecs\n",
    "        assert evecs_flip.shape[-1] % support_vector_norm.shape[-1] == 0\n",
    "        \n",
    "        repeat_factor = evecs_flip.shape[-1] // support_vector_norm.shape[-1]\n",
    "        \n",
    "        support_vector_norm_repeated = torch.repeat_interleave(\n",
    "            support_vector_norm, repeat_factor, dim=-1)\n",
    "    else:\n",
    "        support_vector_norm_repeated = support_vector_norm\n",
    "        \n",
    "    \n",
    "    # multiply the support vector by the flipped evecs [1 x 6890 x 4].T @ [1 x 6890 x 4]\n",
    "    product_with_support = support_vector_norm_repeated.transpose(1, 2) @ evecs_flip\n",
    "\n",
    "    if product_with_support.shape[1] == product_with_support.shape[2]:\n",
    "        # take only diagonal elements\n",
    "        sign_flip_predicted = torch.diagonal(product_with_support, dim1=1, dim2=2)\n",
    "        \n",
    "    # get the sign of the support vector\n",
    "    # sign_flip_predicted = product_with_support\n",
    " \n",
    "    return sign_flip_predicted, support_vector_norm, product_with_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_net = diffusion_network.DiffusionNet(\n",
    "    in_channels=128,\n",
    "    out_channels=256,\n",
    "    cache_dir=None,\n",
    "    input_type='wks'\n",
    "    ).to(device)\n",
    "\n",
    "cond_ckpt = torch.load('/home/s94zalek_hpc/shape_matching/checkpoints/faust.pth')\n",
    "cond_net.load_state_dict(cond_ckpt['networks']['feature_extractor'])\n",
    "\n",
    "# set the cond_net to be untrainable\n",
    "for param in cond_net.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm._instances.clear()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "losses = torch.tensor([])\n",
    "train_iterator = tqdm(range(40001))\n",
    "    \n",
    "net.cache_dir = train_diff_folder    \n",
    "cond_net.cache_dir = train_diff_folder  \n",
    "        \n",
    "curr_iter = 0\n",
    "for epoch in range(len(train_iterator) // len(train_shapes)):\n",
    "    \n",
    "    # train_shapes_shuffled = train_shapes.copy()\n",
    "    np.random.shuffle(train_shapes)\n",
    "    \n",
    "    \n",
    "    for curr_idx in range(len(train_shapes)):     \n",
    "\n",
    "        ##############################################\n",
    "        # Select a shape\n",
    "        ##############################################\n",
    "        # curr_idx = np.random.randint(0, len(train_shapes))\n",
    "    \n",
    "        train_shape = train_shapes[curr_idx]\n",
    "\n",
    "        verts = train_shape['verts'].unsqueeze(0).to(device)\n",
    "        \n",
    "        if lapl_type == 'pcl':\n",
    "            faces = None\n",
    "        else:\n",
    "            faces = train_shape['faces'].unsqueeze(0).to(device)    \n",
    "\n",
    "        evecs_orig = train_shape['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        # Set the signs on shape 0\n",
    "        ##############################################\n",
    "\n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_0 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_0[sign_gt_0 == 0] = -1\n",
    "        sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "        \n",
    "        # predict the sign change\n",
    "        sign_pred_0 = predict_sign_change(net, verts, faces, evecs_flip_0, \n",
    "                                                evecs_cond=None, input_type=input_type,\n",
    "                                                cond_net=cond_net)[0]\n",
    "        \n",
    "        ##############################################\n",
    "        # Set the signs on shape 1\n",
    "        ##############################################\n",
    "        \n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_1 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_1[sign_gt_1 == 0] = -1\n",
    "        sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "        \n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "        \n",
    "        # predict the sign change\n",
    "        sign_pred_1 = predict_sign_change(net, verts, faces, evecs_flip_1, \n",
    "                                                evecs_cond=None, input_type=input_type,\n",
    "                                                cond_net=cond_net)[0]\n",
    "        \n",
    "        ##############################################\n",
    "        # Calculate the loss\n",
    "        ##############################################\n",
    "        \n",
    "        # calculate the ground truth sign difference\n",
    "        sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "        \n",
    "        # calculate the sign difference between predicted evecs\n",
    "        sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = loss_fn(\n",
    "            sign_diff_pred.reshape(sign_diff_pred.shape[0], -1),\n",
    "            sign_diff_gt.reshape(sign_diff_gt.shape[0], -1)\n",
    "            )\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        losses = torch.cat([losses, torch.tensor([loss.item()])])\n",
    "        \n",
    "        # print mean of last 10 losses\n",
    "        train_iterator.set_description(f'loss={torch.mean(losses[-10:]):.3f}')\n",
    "        \n",
    "        # plot the losses every 1000 iterations\n",
    "        if curr_iter > 0 and curr_iter % (len(train_iterator) // 10) == 0:\n",
    "            pd.Series(losses.numpy()).rolling(10).mean().plot()\n",
    "            plt.yscale('log')\n",
    "            # plt.show()\n",
    "            \n",
    "            plt.savefig(f'{experiment_dir}/losses_{curr_iter}.png')\n",
    "            plt.close()\n",
    "            \n",
    "        curr_iter += 1\n",
    "        train_iterator.update(1)\n",
    "        \n",
    "        \n",
    "# save model checkpoint\n",
    "torch.save(\n",
    "    net.state_dict(),\n",
    "    f'{experiment_dir}/{curr_iter}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import utils.geometry_util as geometry_util\n",
    "import robust_laplacian\n",
    "import scipy.sparse.linalg as sla\n",
    "import utils.geometry_util as geometry_util\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "shapes_to_test = test_shapes\n",
    "net.cache_dir = test_diff_folder\n",
    "cond_net.cache_dir = test_diff_folder\n",
    "\n",
    "# shapes_to_test = train_shapes\n",
    "# net.cache_dir = train_diff_folder\n",
    "         \n",
    "             \n",
    "              \n",
    "iterator = tqdm(range(1000))\n",
    "incorrect_signs_list = torch.tensor([])\n",
    "curr_iter = 0\n",
    "\n",
    "for epoch in range(len(iterator) // len(shapes_to_test)):\n",
    "    \n",
    "    # train_shapes_shuffled = train_shapes.copy()\n",
    "    # np.random.shuffle(test_shapes_list)\n",
    "    \n",
    "    \n",
    "    for curr_idx in range(len(shapes_to_test)):     \n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        # Select a shape\n",
    "        ##############################################\n",
    "        \n",
    "        test_shape = shapes_to_test[curr_idx]    \n",
    "        \n",
    "        verts = test_shape['verts'].unsqueeze(0).to(device)\n",
    "        faces = test_shape['faces'].unsqueeze(0).to(device)\n",
    "        evecs_orig = test_shape['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "\n",
    "        ##############################################\n",
    "        # Set the signs on shape 0\n",
    "        ##############################################\n",
    "\n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_0 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_0[sign_gt_0 == 0] = -1\n",
    "        sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_0, supp_vec_0, _ = predict_sign_change(\n",
    "                net, verts, faces, evecs_flip_0, evecs_cond=None, input_type=input_type,\n",
    "                cond_net=cond_net)\n",
    "        \n",
    "        ##############################################\n",
    "        # Set the signs on shape 1\n",
    "        ##############################################\n",
    "        \n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_1 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_1[sign_gt_1 == 0] = -1\n",
    "        sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "        \n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_1, supp_vec_1, _ = predict_sign_change(\n",
    "                net, verts, faces, evecs_flip_1, evecs_cond=None, input_type=input_type, cond_net=cond_net)\n",
    "        \n",
    "        ##############################################\n",
    "        # Calculate the loss\n",
    "        ##############################################\n",
    "        \n",
    "        # calculate the ground truth sign difference\n",
    "        sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "        \n",
    "        # calculate the sign difference between predicted evecs\n",
    "        sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "        \n",
    "        sign_correct = sign_diff_pred.sign() * sign_diff_gt.sign() \n",
    "        \n",
    "        \n",
    "        # count the number of incorrect signs\n",
    "        count_incorrect_signs = (sign_correct < 0).int().sum()\n",
    "            \n",
    "        # incorrect_signs_list.append(count_incorrect_signs)\n",
    "        incorrect_signs_list = torch.cat([incorrect_signs_list, torch.tensor([count_incorrect_signs])])\n",
    "        \n",
    "        \n",
    "        iterator.set_description(f'Mean incorrect signs {incorrect_signs_list.float().mean():.2f} / {feature_dim}')\n",
    "        iterator.update(1)\n",
    "        # if count_incorrect_signs > 7:\n",
    "        #     raise ValueError('Too many incorrect signs')\n",
    "    \n",
    "    \n",
    "print(f'Results for {len(incorrect_signs_list)} test shapes')\n",
    "print(f'Incorrect signs per shape: {incorrect_signs_list.float().mean():.2f} / {feature_dim}')\n",
    "\n",
    "print('Max incorrect signs', incorrect_signs_list.max())\n",
    "\n",
    "print()\n",
    "# print('Shape idx', curr_idx)\n",
    "print('GT', sign_diff_gt)\n",
    "print('PRED', sign_diff_pred)\n",
    "print('Correct', sign_correct)\n",
    "print(f'Incorrect signs {torch.sum(sign_correct != 1)} / {feature_dim}')\n",
    "print(incorrect_signs_list)\n",
    "\n",
    "\n",
    "# plt.plot(support_vector_norm.squeeze().detach().cpu().numpy(), '.', alpha=0.1)\n",
    "# plt.ylim(-0.1, 0.1)\n",
    "# # plt.yscale('log')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

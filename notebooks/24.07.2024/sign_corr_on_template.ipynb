{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_code.datasets.surreal_dataset_3dc import TemplateSurrealDataset3DC\n",
    "\n",
    "num_evecs = 32\n",
    "# create the dataset\n",
    "dataset = TemplateSurrealDataset3DC(\n",
    "    shape_path=f'/home/s94zalek_hpc/3D-CODED/data/datas_surreal_train.pth',\n",
    "    num_evecs=32,\n",
    "    use_cuda=False,\n",
    "    cache_lb_dir=None,\n",
    "    return_evecs=True\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_code.sign_canonicalization.training import predict_sign_change\n",
    "import networks.diffusion_network as diffusion_network\n",
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "import matplotlib.pyplot as plt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net_path = '/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_estimator_no_aug/40000.pth'\n",
    "num_evecs = 32\n",
    "evecs_per_support = 4\n",
    "input_type = 'wks'\n",
    "\n",
    "\n",
    "net = diffusion_network.DiffusionNet(\n",
    "    in_channels=num_evecs,\n",
    "    out_channels=num_evecs // evecs_per_support,\n",
    "    cache_dir=None,\n",
    "    input_type=input_type,\n",
    "    k_eig=128,\n",
    "    n_block=6\n",
    "    ).to(device)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.load_state_dict(torch.load(net_path, map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import utils.geometry_util as geometry_util\n",
    "import robust_laplacian\n",
    "import scipy.sparse.linalg as sla\n",
    "import utils.geometry_util as geometry_util\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "# shapes_to_test = test_shapes\n",
    "# net.cache_dir = test_diff_folder\n",
    "\n",
    "shapes_to_test = [dataset[0]['first']]\n",
    "net.cache_dir = '/home/s94zalek_hpc/shape_matching/notebooks/24.07.2024'\n",
    "         \n",
    "             \n",
    "              \n",
    "iterator = tqdm(range(1000))\n",
    "incorrect_signs_list = torch.tensor([])\n",
    "curr_iter = 0\n",
    "\n",
    "for epoch in range(len(iterator) // len(shapes_to_test)):\n",
    "    \n",
    "    # train_shapes_shuffled = train_shapes.copy()\n",
    "    # np.random.shuffle(test_shapes_list)\n",
    "    \n",
    "    \n",
    "    for curr_idx in range(len(shapes_to_test)):     \n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        # Select a shape\n",
    "        ##############################################\n",
    "        \n",
    "        test_shape = shapes_to_test[curr_idx]    \n",
    "        \n",
    "        verts = test_shape['verts'].unsqueeze(0).to(device)\n",
    "        faces = test_shape['faces'].unsqueeze(0).to(device)\n",
    "        evecs_orig = test_shape['evecs'][:, :num_evecs].unsqueeze(0).to(device)\n",
    "\n",
    "        ##############################################\n",
    "        # Set the signs on shape 0\n",
    "        ##############################################\n",
    "\n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_0 = torch.randint(0, 2, (num_evecs,)).float().to(device)\n",
    "        \n",
    "        sign_gt_0[sign_gt_0 == 0] = -1\n",
    "        sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_0, supp_vec_0, _ = predict_sign_change(\n",
    "                net, verts, faces, evecs_flip_0, evecs_cond=None, input_type=input_type)\n",
    "        \n",
    "        ##############################################\n",
    "        # Set the signs on shape 1\n",
    "        ##############################################\n",
    "        \n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_1 = torch.randint(0, 2, (num_evecs,)).float().to(device)\n",
    "        \n",
    "        sign_gt_1[sign_gt_1 == 0] = -1\n",
    "        sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "        \n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_1, supp_vec_1, _ = predict_sign_change(\n",
    "                net, verts, faces, evecs_flip_1, evecs_cond=None, input_type=input_type)\n",
    "        \n",
    "        ##############################################\n",
    "        # Calculate the loss\n",
    "        ##############################################\n",
    "        \n",
    "        # calculate the ground truth sign difference\n",
    "        sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "        \n",
    "        # calculate the sign difference between predicted evecs\n",
    "        sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "        \n",
    "        sign_correct = sign_diff_pred.sign() * sign_diff_gt.sign() \n",
    "        \n",
    "        \n",
    "        # count the number of incorrect signs\n",
    "        count_incorrect_signs = (sign_correct < 0).int().sum()\n",
    "            \n",
    "        # incorrect_signs_list.append(count_incorrect_signs)\n",
    "        incorrect_signs_list = torch.cat([incorrect_signs_list, torch.tensor([count_incorrect_signs])])\n",
    "        \n",
    "        \n",
    "        iterator.set_description(f'Mean incorrect signs {incorrect_signs_list.float().mean():.2f} / {num_evecs}, max {incorrect_signs_list.max()}')\n",
    "        iterator.update(1)\n",
    "        # if count_incorrect_signs > 7:\n",
    "        #     raise ValueError('Too many incorrect signs')\n",
    "    \n",
    "    \n",
    "print(f'Results for {len(incorrect_signs_list)} test shapes')\n",
    "print(f'Incorrect signs per shape: {incorrect_signs_list.float().mean():.2f} / {num_evecs}')\n",
    "\n",
    "print('Max incorrect signs', incorrect_signs_list.max())\n",
    "\n",
    "print()\n",
    "# print('Shape idx', curr_idx)\n",
    "print('GT', sign_diff_gt)\n",
    "print('PRED', sign_diff_pred)\n",
    "print('Correct', sign_correct)\n",
    "print(f'Incorrect signs {torch.sum(sign_correct != 1)} / {num_evecs}')\n",
    "print(incorrect_signs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# read /home/s94zalek_hpc/shape_matching/data/SURREAL_full/full_datasets/dataset_3dc_corrected_noAug_32/train/C_gt_xy.txt\n",
    "data_Cxy = np.loadtxt('/home/s94zalek_hpc/shape_matching/data/SURREAL_full/full_datasets/dataset_3dc_corrected_noAug_32/train/C_gt_xy_0_11500.txt')\n",
    "data_Cxy = torch.from_numpy(data_Cxy).reshape(data_Cxy.shape[0], 32, 32)\n",
    "\n",
    "data_evals = np.loadtxt('/home/s94zalek_hpc/shape_matching/data/SURREAL_full/full_datasets/dataset_3dc_corrected_noAug_32/train/evals_0_11500.txt')\n",
    "data_evals = torch.from_numpy(data_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Cxy_unproc = np.loadtxt('/home/s94zalek_hpc/shape_matching/data/SURREAL_full/full_datasets/dataset_3dc_faceNorm_32/train/C_gt_xy_0_11500.txt')\n",
    "data_Cxy_unproc = torch.from_numpy(data_Cxy_unproc).reshape(data_Cxy_unproc.shape[0], 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "h = 32\n",
    "\n",
    "# get 4 random indices\n",
    "idxs = np.random.randint(0, data_Cxy.shape[0], 4)\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(15, 8))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0, 0], data_Cxy[idxs[0]],\n",
    "                        f'Proc {idxs[0]}', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[0, 1], data_Cxy[idxs[1]],\n",
    "                        f'{idxs[1]}', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[0, 2], data_Cxy[idxs[2]],\n",
    "                        f'{idxs[2]}', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[0, 3], data_Cxy[idxs[3]],\n",
    "                        f'{idxs[3]}', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[1, 0], data_Cxy_unproc[idxs[0]],\n",
    "                        f'Unproc {idxs[0]}', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1, 1], data_Cxy_unproc[idxs[1]],\n",
    "                        f'{idxs[1]}', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1, 2], data_Cxy_unproc[idxs[2]],\n",
    "                        f'{idxs[2]}', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1, 3], data_Cxy_unproc[idxs[3]],\n",
    "                        f'{idxs[3]}', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "C_xy_pred_list_scaled = scaler.fit_transform(data_Cxy.reshape(data_Cxy.shape[0], -1))\n",
    "C_xy_pred_list_pca = pca.fit_transform(C_xy_pred_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(C_xy_pred_list_pca[::100, :2], columns=[f'PCA_{i}' for i in range(2)])\n",
    "# only keep 1000 elements, evenly distributed\n",
    "\n",
    "# pca_df = pd.DataFrame(C_xy_pred_list_pca, columns=[f'PCA_{i}' for i in range(32)])\n",
    "\n",
    "# pca_df['name'] = names_y\n",
    "# pca_df['body_type'] = [i // 10 for i in range(C_xy_pred_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_pred_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde') #, hue='body_type', palette='tab10')\n",
    "\n",
    "print('PCA on predicted')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "C_xy_pred_list_scaled = scaler.fit_transform(data_Cxy_unproc.reshape(data_Cxy_unproc.shape[0], -1))\n",
    "C_xy_pred_list_pca = pca.fit_transform(C_xy_pred_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(C_xy_pred_list_pca[::100, :2], columns=[f'PCA_{i}' for i in range(2)])\n",
    "# only keep 1000 elements, evenly distributed\n",
    "\n",
    "# pca_df = pd.DataFrame(C_xy_pred_list_pca, columns=[f'PCA_{i}' for i in range(32)])\n",
    "\n",
    "# pca_df['name'] = names_y\n",
    "# pca_df['body_type'] = [i // 10 for i in range(C_xy_pred_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_pred_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde') #, hue='body_type', palette='tab10')\n",
    "\n",
    "print('PCA on predicted')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = torch.tensor([1,2,3,4,5])\n",
    "tensor_2 = torch.tensor([2])\n",
    "\n",
    "# torch.cat([tensor_1.sum(), tensor_2])\n",
    "# tensor_1.sum()\n",
    "torch.cat([\n",
    "    torch.tensor([tensor_1.sum()]),\n",
    "    tensor_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

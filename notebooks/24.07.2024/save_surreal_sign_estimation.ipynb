{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import trimesh\n",
    "from tqdm import tqdm\n",
    "import utils.geometry_util as geometry_util\n",
    "import utils.shape_util as shape_util\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/s94zalek_hpc/3D-CODED/data/datas_surreal_train.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_code\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurreal_dataset_3dc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TemplateSurrealDataset3DC\n\u001b[1;32m      3\u001b[0m user_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms94zalek_hpc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTemplateSurrealDataset3DC\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/3D-CODED/data/datas_surreal_train.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_evecs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_lb_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_evecs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m    \n",
      "File \u001b[0;32m~/shape_matching/my_code/datasets/surreal_dataset_3dc.py:45\u001b[0m, in \u001b[0;36mTemplateSurrealDataset3DC.__init__\u001b[0;34m(self, shape_path, num_evecs, use_cuda, cache_lb_dir, return_evecs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_evecs \u001b[38;5;241m=\u001b[39m return_evecs\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# load the shapes from 3D-coded\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshapes \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# load template mesh\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_mesh \u001b[38;5;241m=\u001b[39m trimesh\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/shape_matching/data/SURREAL_full/template/template.ply\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/fmnet/lib/python3.8/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/s94zalek_hpc/3D-CODED/data/datas_surreal_train.pth'"
     ]
    }
   ],
   "source": [
    "from my_code.datasets.surreal_dataset_3dc import TemplateSurrealDataset3DC\n",
    "\n",
    "user_name = 's94zalek_hpc'\n",
    "dataset = TemplateSurrealDataset3DC(\n",
    "    shape_path=f'/home/{user_name}/3D-CODED/data/datas_surreal_train.pth',\n",
    "    num_evecs=4,\n",
    "    use_cuda=False,\n",
    "    cache_lb_dir=None,\n",
    "    return_evecs=False\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/home/s94zalek_hpc/shape_matching/data_sign_training/train/SURREAL'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:08<00:00,  7.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# base_folder = '/home/s94zalek_hpc/shape_matching/data_sign_training/train/SURREAL'\n",
    "\n",
    "\n",
    "base_folder = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/data_sign_training/train/SURREAL'\n",
    "\n",
    "mesh_folder = f'{base_folder}/off'\n",
    "corr_folder = f'{base_folder}/corres'\n",
    "\n",
    "os.makedirs(mesh_folder)\n",
    "os.makedirs(corr_folder)\n",
    "\n",
    "n_shapes = 1000\n",
    "rand_idxs = np.random.choice(len(dataset), n_shapes, replace=False)\n",
    "\n",
    "for curr_iter, i in tqdm(enumerate(rand_idxs), total=n_shapes):\n",
    "    data = dataset[i]['second']\n",
    "    \n",
    "\n",
    "    shape_util.write_off(\n",
    "        f'{mesh_folder}/{curr_iter:04}.off',\n",
    "        data['verts'].numpy(),\n",
    "        data['faces'].numpy()\n",
    "        )\n",
    "    \n",
    "    with open(f'{corr_folder}/{curr_iter:04}.vts', 'w') as f:\n",
    "        corr = np.array(list(range(len(data['verts'])))) + 1\n",
    "        np.savetxt(f, corr, fmt='%d')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s94zalek_hpc\n"
     ]
    }
   ],
   "source": [
    "!printenv HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "mesh_folder = '/home/s94zalek_hpc/shape_matching/data_sign_training/train/SURREAL_train_rot_180_180_180_normal_True_noise_0.0_-0.05_0.05_lapl_mesh_scale_0.9_1.1/off'\n",
    "# read 5 random shapes and show them\n",
    "rand_idxs = np.random.choice(1000, 5, replace=False)\n",
    "\n",
    "for curr_idx, i in enumerate(rand_idxs):\n",
    "    mesh = trimesh.load_mesh(f'{mesh_folder}/{i:04}.off')\n",
    "    mesh.vertices += np.array([curr_idx, 0, 0])\n",
    "    scene.add_geometry(mesh)\n",
    "    \n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.datasets.shape_dataset as shape_dataset\n",
    "\n",
    "diff_folder = f'{base_folder}/diffusion'\n",
    "dataset_single = shape_dataset.SingleShapeDataset(\n",
    "    data_root = base_folder,\n",
    "    centering = 'bbox',\n",
    "    num_evecs=128,\n",
    "    lb_cache_dir=diff_folder,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████▉                                                                           | 210/1000 [00:46<02:54,  4.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m data_train \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset_single))):\n\u001b[0;32m----> 3\u001b[0m     data_i \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_single\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m     data_train\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverts\u001b[39m\u001b[38;5;124m'\u001b[39m: data_i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverts\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaces\u001b[39m\u001b[38;5;124m'\u001b[39m: data_i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaces\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevecs\u001b[39m\u001b[38;5;124m'\u001b[39m: data_i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevecs\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m         })\n",
      "File \u001b[0;32m~/shape_matching/my_code/datasets/shape_dataset.py:127\u001b[0m, in \u001b[0;36mSingleShapeDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# get eigenfunctions/eigenvalues\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_evecs:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# cache_dir = os.path.join(self.data_root, 'diffusion')\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_spectral_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_evecs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_evecs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlb_cache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# get geodesic distance matrix\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_dist:\n",
      "File \u001b[0;32m~/shape_matching/my_code/datasets/preprocessing.py:78\u001b[0m, in \u001b[0;36mget_spectral_ops\u001b[0;34m(item, num_evecs, cache_dir)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(cache_dir):\n\u001b[1;32m     77\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(cache_dir)\n\u001b[0;32m---> 78\u001b[0m _, mass, L, evals, evecs, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_operators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mverts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfaces\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_evecs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m evals \u001b[38;5;241m=\u001b[39m evals\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     82\u001b[0m evecs_trans \u001b[38;5;241m=\u001b[39m evecs\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m mass[\u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "File \u001b[0;32m~/shape_matching/utils/geometry_util.py:718\u001b[0m, in \u001b[0;36mget_operators\u001b[0;34m(verts, faces, k, normals, cache_dir, overwrite_cache)\u001b[0m\n\u001b[1;32m    716\u001b[0m frames \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(frames)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    717\u001b[0m mass \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mass)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 718\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[43msparse_np_to_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    719\u001b[0m evals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(evals)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    720\u001b[0m evecs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(evecs)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/shape_matching/utils/geometry_util.py:43\u001b[0m, in \u001b[0;36msparse_np_to_torch\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m     41\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((Acoo\u001b[38;5;241m.\u001b[39mrow, Acoo\u001b[38;5;241m.\u001b[39mcol))\n\u001b[1;32m     42\u001b[0m shape \u001b[38;5;241m=\u001b[39m Acoo\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_coo_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoalesce\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "for i in tqdm(range(len(dataset_single))):\n",
    "    data_i = dataset_single[i]\n",
    "    data_train.append({\n",
    "        'verts': data_i['verts'],\n",
    "        'faces': data_i['faces'],\n",
    "        'evecs': data_i['evecs'],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.diffusion_training.data_loading as data_loading\n",
    "\n",
    "train_dataset = data_loading.get_val_dataset(\n",
    "    'FAUST_orig', 'train', 200, canonicalize_fmap=None\n",
    "    )[1]\n",
    "test_dataset = data_loading.get_val_dataset(\n",
    "    'FAUST_orig', 'test', 200, canonicalize_fmap=None\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.plotting_utils as plotting_utils\n",
    "\n",
    "l = 0\n",
    "h = 32\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0], train_dataset[78]['second']['C_gt_xy'][0],\n",
    "                        'C_gt_xy', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1], test_dataset[1]['second']['C_gt_xy'][0],\n",
    "                        'C_gt_xy', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sign_change(net, verts, faces, evecs_flip, evecs_cond):\n",
    "    \n",
    "    # normalize the evecs\n",
    "    evecs_flip = torch.nn.functional.normalize(evecs_flip, p=2, dim=1)\n",
    "    \n",
    "    if evecs_cond is not None:\n",
    "        evecs_cond = torch.nn.functional.normalize(evecs_cond, p=2, dim=1)\n",
    "        evecs_input = torch.cat([evecs_flip, evecs_cond], dim=-1)\n",
    "    else:\n",
    "        evecs_input = evecs_flip\n",
    "        \n",
    "    # process the flipped evecs\n",
    "    support_vector_flip = net(\n",
    "        verts=verts,\n",
    "        faces=faces,\n",
    "        feats=evecs_input,\n",
    "    ) # [1 x 6890 x 1]\n",
    "\n",
    "    # normalize the support vector\n",
    "    support_vector_norm = torch.nn.functional.normalize(support_vector_flip, p=2, dim=1)\n",
    "    \n",
    "    # multiply the support vector by the flipped evecs [1 x 6890 x 4].T @ [1 x 6890 x 4]\n",
    "    product_with_support = support_vector_norm.transpose(1, 2) @ evecs_flip\n",
    "\n",
    "    if product_with_support.shape[1] == product_with_support.shape[2]:\n",
    "        # take only diagonal elements\n",
    "        product_with_support = torch.diagonal(product_with_support, dim1=1, dim2=2)\n",
    "        \n",
    "    # get the sign of the support vector\n",
    "    sign_flip_predicted = product_with_support\n",
    " \n",
    "    return sign_flip_predicted, support_vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networks.diffusion_network as diffusion_network\n",
    "\n",
    "condition_dim = 0\n",
    "start_dim = 0\n",
    "feature_dim = 64\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = diffusion_network.DiffusionNet(\n",
    "    in_channels=feature_dim + condition_dim,\n",
    "    out_channels=feature_dim,\n",
    "    # hidden_channels=feature_dim // 2,\n",
    "    cache_dir=f'data_with_smpl_corr/FAUST_original/{200}',\n",
    "    input_type='wks',\n",
    "    ).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "losses = torch.tensor([])\n",
    "iterator = tqdm(range(30001))\n",
    "\n",
    "possible_shapes = [train_dataset[i]['second'] for i in range(len(train_dataset))]\n",
    "# possible_shapes = [train_dataset[i]['second'] for i in range(2)]\n",
    "                   \n",
    "for i in iterator:\n",
    "\n",
    "    ##############################################\n",
    "    # Select a shape\n",
    "    ##############################################\n",
    "    curr_idx = np.random.randint(0, len(possible_shapes))\n",
    "    \n",
    "    train_shape = possible_shapes[curr_idx]\n",
    "\n",
    "    verts = train_shape['verts'].unsqueeze(0).to(device)\n",
    "    faces = train_shape['faces'].unsqueeze(0).to(device)\n",
    "\n",
    "    evecs_orig = train_shape['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "\n",
    "    # evecs_cond = None\n",
    "    evecs_cond = train_shape['evecs'][:,\n",
    "        start_dim + feature_dim : start_dim + feature_dim + condition_dim].unsqueeze(0).to(device)\n",
    "\n",
    "    ##############################################\n",
    "    # Set the signs on shape 0\n",
    "    ##############################################\n",
    "\n",
    "    # create a random combilation of +1 and -1, length = feature_dim\n",
    "    sign_gt_0 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "    \n",
    "    sign_gt_0[sign_gt_0 == 0] = -1\n",
    "    sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "    # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "    evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "    \n",
    "    # predict the sign change\n",
    "    sign_pred_0 = predict_sign_change(net, verts, faces, evecs_flip_0, \n",
    "                                              evecs_cond=evecs_cond)[0]\n",
    "    \n",
    "    ##############################################\n",
    "    # Set the signs on shape 1\n",
    "    ##############################################\n",
    "    \n",
    "    # create a random combilation of +1 and -1, length = feature_dim\n",
    "    sign_gt_1 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "    \n",
    "    sign_gt_1[sign_gt_1 == 0] = -1\n",
    "    sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "    \n",
    "    # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "    evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "    \n",
    "    # predict the sign change\n",
    "    sign_pred_1 = predict_sign_change(net, verts, faces, evecs_flip_1, \n",
    "                                              evecs_cond=evecs_cond)[0]\n",
    "    \n",
    "    ##############################################\n",
    "    # Calculate the loss\n",
    "    ##############################################\n",
    "    \n",
    "    # calculate the ground truth sign difference\n",
    "    sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "    \n",
    "    # calculate the sign difference between predicted evecs\n",
    "    sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "    \n",
    "    # calculate the loss\n",
    "    loss = loss_fn(\n",
    "        sign_diff_pred.reshape(sign_diff_pred.shape[0], -1),\n",
    "        sign_diff_gt.reshape(sign_diff_gt.shape[0], -1)\n",
    "        )\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    losses = torch.cat([losses, torch.tensor([loss.item()])])\n",
    "    \n",
    "    # print mean of last 10 losses\n",
    "    iterator.set_description(f'loss={torch.mean(losses[-10:]):.3f}')\n",
    "    \n",
    "    # plot the losses every 1000 iterations\n",
    "    if i > 0 and i % (len(iterator) // 10) == 0:\n",
    "        pd.Series(losses.numpy()).rolling(10).mean().plot()\n",
    "        plt.yscale('log')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shapes_list = [test_dataset[i]['second'] for i in range(len(test_dataset))]\n",
    "                   \n",
    "iterator = tqdm(range(1001))\n",
    "\n",
    "incorrect_signs_list = torch.tensor([])\n",
    "for i in iterator:\n",
    "\n",
    "    ##############################################\n",
    "    # Select a shape\n",
    "    ##############################################\n",
    "    # test_shape = test_shapes_list[i]\n",
    "    \n",
    "    curr_idx = np.random.randint(0, len(test_shapes_list))   \n",
    "    test_shape = test_shapes_list[curr_idx]    \n",
    "\n",
    "    verts = test_shape['verts'].unsqueeze(0).to(device)\n",
    "    faces = test_shape['faces'].unsqueeze(0).to(device)\n",
    "\n",
    "    evecs_orig = test_shape['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "    evecs_cond = test_shape['evecs'][:,\n",
    "        start_dim + feature_dim : start_dim + feature_dim + condition_dim].unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "    ##############################################\n",
    "    # Set the signs on shape 0\n",
    "    ##############################################\n",
    "\n",
    "    # create a random combilation of +1 and -1, length = feature_dim\n",
    "    sign_gt_0 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "    \n",
    "    sign_gt_0[sign_gt_0 == 0] = -1\n",
    "    sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "    # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "    evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "    \n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_0 = predict_sign_change(net, verts, faces, evecs_flip_0, \n",
    "                                              evecs_cond=evecs_cond)[0]\n",
    "    \n",
    "    ##############################################\n",
    "    # Set the signs on shape 1\n",
    "    ##############################################\n",
    "    \n",
    "    # create a random combilation of +1 and -1, length = feature_dim\n",
    "    sign_gt_1 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "    \n",
    "    sign_gt_1[sign_gt_1 == 0] = -1\n",
    "    sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "    \n",
    "    # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "    evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "    \n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_1 = predict_sign_change(net, verts, faces, evecs_flip_1, \n",
    "                                              evecs_cond=evecs_cond)[0]\n",
    "    \n",
    "    ##############################################\n",
    "    # Calculate the loss\n",
    "    ##############################################\n",
    "    \n",
    "    # calculate the ground truth sign difference\n",
    "    sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "    \n",
    "    # calculate the sign difference between predicted evecs\n",
    "    sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "    \n",
    "    sign_correct = sign_diff_pred.sign() * sign_diff_gt.sign() \n",
    "    \n",
    "    \n",
    "    # count the number of incorrect signs\n",
    "    count_incorrect_signs = (sign_correct < 0).int().sum()\n",
    "    # incorrect_signs_list.append(count_incorrect_signs)\n",
    "    incorrect_signs_list = torch.cat([incorrect_signs_list, torch.tensor([count_incorrect_signs])])\n",
    "    \n",
    "    \n",
    "    iterator.set_description(f'Mean incorrect signs {incorrect_signs_list.float().mean():.2f} / {feature_dim}')\n",
    "    \n",
    "    \n",
    "print(f'Results for {len(incorrect_signs_list)} test shapes')\n",
    "print(f'Incorrect signs per shape: {incorrect_signs_list.float().mean():.2f} / {feature_dim}')\n",
    "\n",
    "# print('Shape idx', curr_idx)\n",
    "print('GT', sign_diff_gt)\n",
    "print('PRED', sign_diff_pred)\n",
    "print('Correct', sign_correct)\n",
    "print(f'Incorrect signs {torch.sum(sign_correct != 1)} / {feature_dim}')\n",
    "\n",
    "# plt.plot(support_vector_norm.squeeze().detach().cpu().numpy(), '.', alpha=0.1)\n",
    "# plt.ylim(-0.1, 0.1)\n",
    "# # plt.yscale('log')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_xy_pred_list = torch.tensor([])\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    # data_0 = test_dataset[12]\n",
    "    data_0 = train_dataset[i]\n",
    "\n",
    "    verts_first = data_0['first']['verts'].unsqueeze(0).to(device)\n",
    "    verts_second = data_0['second']['verts'].unsqueeze(0).to(device)\n",
    "\n",
    "    evecs_first = data_0['first']['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "    evecs_second = data_0['second']['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "\n",
    "    corr_first = data_0['first']['corr']\n",
    "    corr_second = data_0['second']['corr']\n",
    "\n",
    "    C_gt_xy = data_0['second']['C_gt_xy'][0]\n",
    "\n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_first = predict_sign_change(net, verts_first, faces, evecs_first, \n",
    "                                                evecs_cond=None)[0]\n",
    "        sign_pred_second = predict_sign_change(net, verts_second, faces, evecs_second, \n",
    "                                                evecs_cond=None)[0]\n",
    "\n",
    "    C_xy_pred = torch.linalg.lstsq(\n",
    "        evecs_second.cpu()[0, corr_second] * torch.sign(sign_pred_second).cpu(),\n",
    "        evecs_first.cpu()[0, corr_first] * torch.sign(sign_pred_first).cpu()\n",
    "        ).solution\n",
    "    \n",
    "    C_xy_pred_list = torch.cat([C_xy_pred_list, C_xy_pred.unsqueeze(0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "h = 32\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0], C_xy_pred_list[0], 'C_xy_pred_list[0]', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1], C_xy_pred_list[1], 'C_xy_pred_list[12]', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[2], C_xy_pred_list[2], 'C_xy_pred_list[26]', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "C_xy_pred_list_scaled = scaler.fit_transform(C_xy_pred_list.reshape(C_xy_pred_list.shape[0], -1))\n",
    "C_xy_pred_list_pca = pca.fit_transform(C_xy_pred_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(C_xy_pred_list_pca[:, :3], columns=[f'PCA_{i}' for i in range(3)])\n",
    "# pca_df['name'] = names_y\n",
    "pca_df['body_type'] = [i // 10 for i in range(C_xy_pred_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_pred_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde', hue='body_type', palette='tab10')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

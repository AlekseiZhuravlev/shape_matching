{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# models\n",
    "from my_code.models.diag_conditional import DiagConditionedUnet\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "import my_code.datasets.template_dataset as template_dataset\n",
    "\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "\n",
    "import networks.diffusion_network as diffusion_network\n",
    "import matplotlib.pyplot as plt\n",
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "import utils.fmap_util as fmap_util\n",
    "import metrics.geodist_metric as geodist_metric\n",
    "from my_code.sign_canonicalization.training import predict_sign_change\n",
    "import argparse\n",
    "from pyFM_fork.pyFM.refine.zoomout import zoomout_refine\n",
    "import my_code.utils.zoomout_custom as zoomout_custom\n",
    "from utils.shape_util import compute_geodesic_distmat\n",
    "from my_code.diffusion_training_sign_corr.test.test_diffusion_cond import select_p2p_map_dirichlet, log_to_database, parse_args\n",
    "import accelerate\n",
    "\n",
    "tqdm._instances.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_error(\n",
    "    p2p_first, p2p_second,\n",
    "    evecs_first, evecs_second,\n",
    "    corr_first, corr_second,\n",
    "    num_evecs, apply_zoomout,\n",
    "    dist_x,\n",
    "    regularized,\n",
    "    evecs_trans_first=None, evecs_trans_second=None,\n",
    "    evals_first=None, evals_second=None,\n",
    "    return_p2p=False, return_Cxy=False,\n",
    "    A2=None\n",
    "    ):\n",
    "        \n",
    "    if regularized:\n",
    "        Cxy = fmnet.compute_functional_map(\n",
    "            evecs_trans_second[:num_evecs, p2p_second].unsqueeze(0),\n",
    "            evecs_trans_first[:num_evecs, p2p_first].unsqueeze(0),\n",
    "            evals_second[:num_evecs].unsqueeze(0),\n",
    "            evals_first[:num_evecs].unsqueeze(0), \n",
    "        )[0].T\n",
    "        \n",
    "    else:\n",
    "        Cxy = torch.linalg.lstsq(\n",
    "            evecs_second[:, :num_evecs][p2p_second],\n",
    "            evecs_first[:, :num_evecs][p2p_first]\n",
    "            ).solution\n",
    "    \n",
    "    \n",
    "    if apply_zoomout:\n",
    "        Cxy = zoomout_custom.zoomout(\n",
    "            FM_12=Cxy, \n",
    "            evects1=evecs_first,\n",
    "            evects2=evecs_second,\n",
    "            nit=evecs_first.shape[1] - num_evecs, step=1,\n",
    "            A2=A2\n",
    "        )\n",
    "        num_evecs = evecs_first.shape[1]\n",
    "        \n",
    "    p2p = fmap_util.fmap2pointmap(\n",
    "        C12=Cxy,\n",
    "        evecs_x=evecs_first[:, :num_evecs],\n",
    "        evecs_y=evecs_second[:, :num_evecs],\n",
    "        ).cpu()\n",
    "    \n",
    "    geo_err = geodist_metric.calculate_geodesic_error(\n",
    "        dist_x, corr_first.cpu(), corr_second.cpu(), p2p, return_mean=True\n",
    "    )\n",
    "    \n",
    "    # if return_p2p:\n",
    "    #     return geo_err * 100, p2p\n",
    "    # else:\n",
    "    #     return geo_err * 100\n",
    "    \n",
    "    if not return_p2p and not return_Cxy:\n",
    "        return geo_err * 100\n",
    "    \n",
    "    payload = [geo_err * 100]\n",
    "    \n",
    "    if return_p2p:\n",
    "        payload.append(p2p)\n",
    "    if return_Cxy:\n",
    "        payload.append(Cxy)\n",
    "        \n",
    "    return payload\n",
    "\n",
    "\n",
    "def filter_p2p_by_confidence(\n",
    "    p2p_first, p2p_second,\n",
    "    confidence_scores_first, confidence_scores_second,\n",
    "    confidence_threshold, log_file_name\n",
    "    ):\n",
    "    \n",
    "    assert p2p_first.shape[0] == p2p_second.shape[0]\n",
    "    \n",
    "    # select points with both confidence scores above threshold\n",
    "    valid_points = (confidence_scores_first < confidence_threshold) & (confidence_scores_second < confidence_threshold)\n",
    "    \n",
    "    with open(log_file_name, 'a') as f:\n",
    "        \n",
    "        while valid_points.sum() < 0.05 * len(valid_points):\n",
    "            confidence_threshold += 0.05\n",
    "            valid_points = (confidence_scores_first < confidence_threshold) & (confidence_scores_second < confidence_threshold)\n",
    "            \n",
    "            print(f'Increasing confidence threshold: {confidence_threshold}\\n')\n",
    "        print(f'Valid points: {valid_points.sum()}')\n",
    "        assert valid_points.sum() > 0, \"No valid points found\"\n",
    "        \n",
    "    p2p_first = p2p_first[valid_points]\n",
    "    p2p_second = p2p_second[valid_points]\n",
    "    \n",
    "    return p2p_first, p2p_second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self):\n",
    "        self.experiment_name='single_64_2-2ev_64-128-128_remeshed_fixed'\n",
    "        self.checkpoint_name='epoch_99'\n",
    "        \n",
    "        self.dataset_name='SHREC19_r_pair'\n",
    "        self.split='test'\n",
    "        \n",
    "        self.num_iters_avg=100\n",
    "        self.num_samples_median=8\n",
    "        self.confidence_threshold=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "\n",
    "# configuration\n",
    "experiment_name = args.experiment_name\n",
    "checkpoint_name = args.checkpoint_name\n",
    "\n",
    "### config\n",
    "exp_base_folder = f'/home/s94zalek_hpc/shape_matching/my_code/experiments/ddpm/{experiment_name}'\n",
    "with open(f'{exp_base_folder}/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "### model\n",
    "model = DiagConditionedUnet(config[\"model_params\"]).to('cuda')\n",
    "\n",
    "if \"accelerate\" in config and config[\"accelerate\"]:\n",
    "    accelerate.load_checkpoint_in_model(model, f\"{exp_base_folder}/checkpoints/{checkpoint_name}/model.safetensors\")\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f\"{exp_base_folder}/checkpoints/{checkpoint_name}\"))\n",
    "\n",
    "\n",
    "model = model.to('cuda')\n",
    "\n",
    "### Sign correction network\n",
    "sign_corr_net = diffusion_network.DiffusionNet(\n",
    "    **config[\"sign_net\"][\"net_params\"]\n",
    "    ).to('cuda')\n",
    "    \n",
    "sign_corr_net.load_state_dict(torch.load(\n",
    "        f'{config[\"sign_net\"][\"net_path\"]}/{config[\"sign_net\"][\"n_iter\"]}.pth'\n",
    "        ))\n",
    "\n",
    "\n",
    "### sample the model\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='squaredcos_cap_v2',\n",
    "                                clip_sample=True) \n",
    "\n",
    "\n",
    "### test dataset\n",
    "dataset_name = args.dataset_name\n",
    "split = args.split\n",
    "\n",
    "single_dataset, test_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, split, 200, preload=False, return_evecs=True\n",
    "    )\n",
    "sign_corr_net.cache_dir = single_dataset.lb_cache_dir\n",
    "\n",
    "\n",
    "num_evecs = config[\"model_params\"][\"sample_size\"]\n",
    "\n",
    "\n",
    "##########################################\n",
    "# Template\n",
    "##########################################\n",
    "\n",
    "template_shape = template_dataset.get_template(\n",
    "    # template_path='data/SURREAL_full/template/template.ply',\n",
    "    num_evecs=single_dataset.num_evecs,\n",
    "    # template_corr=list(range(6890)),\n",
    "    centering='bbox',\n",
    "    \n",
    "    template_path=f'/home/s94zalek_hpc/shape_matching/data/SURREAL_full/template/{config[\"sign_net\"][\"template_type\"]}/template.off',\n",
    "    template_corr=np.loadtxt(\n",
    "        f'/home/s94zalek_hpc/shape_matching/data/SURREAL_full/template/{config[\"sign_net\"][\"template_type\"]}/corr.txt',\n",
    "        dtype=np.int32) - 1\n",
    "    )    \n",
    "\n",
    "##########################################\n",
    "# Logging\n",
    "##########################################\n",
    "\n",
    "# log_dir = f'{exp_base_folder}/eval/{checkpoint_name}/{dataset_name}-{split}-template'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# fig_dir = f'{log_dir}/figs'\n",
    "# os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "# log_file_name = f'{log_dir}/log.txt'\n",
    "\n",
    "log_dir = f'{exp_base_folder}/eval/{checkpoint_name}/{dataset_name}-{split}/no_smoothing'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "fig_dir = f'{log_dir}/figs'\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "log_file_name = f'{log_dir}/log.txt'\n",
    "\n",
    "\n",
    "##########################################\n",
    "# Template stage\n",
    "##########################################\n",
    "\n",
    "# data_range = tqdm(range(len(single_dataset)), desc='Calculating fmaps to template')\n",
    "\n",
    "# data_range = tqdm([0, 11, 43])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset.dataset = single_dataset\n",
    "    \n",
    "geo_errs_gt = []\n",
    "geo_errs_corr_gt = []\n",
    "geo_errs_pairzo = []\n",
    "geo_errs_dirichlet = []\n",
    "geo_errs_median = []\n",
    "geo_errs_median_filtered = []\n",
    "\n",
    "    \n",
    "# data_range_pair = tqdm(range(len(test_dataset)), desc='Calculating pair fmaps',\n",
    "#                        disable=True)\n",
    "\n",
    "data_range_pair = tqdm([124])\n",
    "# print('!!! WARNING: only 2 samples are processed !!!')\n",
    "\n",
    "\n",
    "for i in data_range_pair:\n",
    "    \n",
    "    data = test_dataset[i]        \n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # device = 'cpu'\n",
    "    \n",
    "    verts_first = data['first']['verts'].to(device)\n",
    "    verts_second = data['second']['verts'].to(device)\n",
    "    \n",
    "    faces_first = data['first']['faces'].to(device)\n",
    "    faces_second = data['second']['faces'].to(device)\n",
    "\n",
    "    evecs_first = data['first']['evecs'][:, :].to(device)\n",
    "    evecs_second = data['second']['evecs'][:, :].to(device)\n",
    "    \n",
    "    evals_first = data['first']['evals'][:num_evecs]\n",
    "    evals_second = data['second']['evals'][:num_evecs]\n",
    "\n",
    "    corr_first = data['first']['corr'].to(device)\n",
    "    corr_second = data['second']['corr'].to(device)\n",
    "    \n",
    "    ###############################################\n",
    "    # Functional maps\n",
    "    ###############################################\n",
    "    \n",
    "    # evecs_first_zo = data['first']['evecs_zo'].to(device)\n",
    "    # evecs_second_zo = data['second']['evecs_zo'].to(device)\n",
    "    \n",
    "    evecs_first_zo = data['first']['evecs'].to(device)\n",
    "    evecs_second_zo = data['second']['evecs'].to(device)\n",
    "    \n",
    "    # p2p_est_first = data['first']['p2p_est'].to(device)\n",
    "    # p2p_est_second = data['second']['p2p_est'].to(device)\n",
    "    \n",
    "    # p2p_dirichlet_first = data['first']['p2p_dirichlet'].to(device)\n",
    "    # p2p_dirichlet_second = data['second']['p2p_dirichlet'].to(device)\n",
    "    \n",
    "    # p2p_median_first = data['first']['p2p_median'].to(device)\n",
    "    # p2p_median_second = data['second']['p2p_median'].to(device)\n",
    "    \n",
    "    dist_x = torch.tensor(\n",
    "        compute_geodesic_distmat(data['first']['verts'].numpy(), data['first']['faces'].numpy())    \n",
    "    )\n",
    "    dist_y = torch.tensor(\n",
    "        compute_geodesic_distmat(data['second']['verts'].numpy(), data['second']['faces'].numpy())    \n",
    "    )\n",
    "    # dist_x = data['first']['geo_dist']\n",
    "    # dist_y = data['second']['geo_dist']\n",
    "    \n",
    "    # mass_second = data['second']['mass'].to(device)\n",
    "    mass_second=data['second']['mass'].to(device)\n",
    "    \n",
    "    ###############################################\n",
    "    # Geodesic errors\n",
    "    ###############################################\n",
    "    \n",
    "    # GT geo error\n",
    "    geo_err_gt = get_geo_error(\n",
    "        corr_first, corr_second,\n",
    "        evecs_first, evecs_second,\n",
    "        corr_first, corr_second,\n",
    "        num_evecs, False,\n",
    "        dist_x, regularized=False,\n",
    "        A2=mass_second\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "geo_err_k, p2p_k, Cxy_k = get_geo_error(\n",
    "    corr_first, corr_second,\n",
    "    # p2p_est_first[k], p2p_est_second[k],\n",
    "    evecs_first_zo, evecs_second_zo,\n",
    "    corr_first, corr_second,\n",
    "    num_evecs, False,\n",
    "    dist_x, regularized=True,\n",
    "    A2=mass_second,\n",
    "    return_p2p=True,\n",
    "    return_Cxy=True,\n",
    "    evecs_trans_first=torch.linalg.pinv(evecs_first_zo),\n",
    "    evecs_trans_second=torch.linalg.pinv(evecs_second_zo),\n",
    "    evals_first=data['first']['evals'].to('cuda'),\n",
    "    evals_second=data['second']['evals'].to('cuda'),\n",
    "    )\n",
    "print(geo_err_k)\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    data['first']['verts'], data['first']['faces'],\n",
    "    data['second']['verts'], data['second']['faces'],\n",
    "    p2p_k,\n",
    "    axes_color_gradient=[0],\n",
    "    base_cmap='hsv'\n",
    ")\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import potpourri3d as pp3d\n",
    "import scipy.sparse.linalg as sla\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "\n",
    "def get_evecs_cotan(verts, faces, k):\n",
    "\n",
    "    eps = 1e-8\n",
    "\n",
    "    L = pp3d.cotan_laplacian(verts, faces, denom_eps=1e-10)\n",
    "    massvec = pp3d.vertex_areas(verts, faces)\n",
    "    massvec += eps * np.mean(massvec)\n",
    "\n",
    "    # Compute the eigenbasis\n",
    "    # Prepare matrices\n",
    "    L_eigsh = (L + eps * scipy.sparse.identity(L.shape[0])).tocsc()\n",
    "    massvec_eigsh = massvec\n",
    "    Mmat = scipy.sparse.diags(massvec_eigsh)\n",
    "    eigs_sigma = eps\n",
    "\n",
    "    evals, evecs = sla.eigsh(L_eigsh, k=k, M=Mmat, sigma=eigs_sigma)\n",
    "    \n",
    "    return torch.tensor(evecs, dtype=torch.float32)\n",
    "\n",
    "evecs_first_cotan = get_evecs_cotan(\n",
    "    data['first']['verts'].numpy(),\n",
    "    data['first']['faces'].numpy(),\n",
    "    k=200\n",
    "    ).to('cuda')\n",
    "evecs_second_cotan = get_evecs_cotan(\n",
    "    data['second']['verts'].numpy(),\n",
    "    data['second']['faces'].numpy(),\n",
    "    k=200\n",
    "    ).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_err_k, p2p_k, Cxy_k = get_geo_error(\n",
    "    corr_first, corr_second,\n",
    "    # p2p_est_first[k], p2p_est_second[k],\n",
    "    evecs_first_cotan, evecs_second_cotan,\n",
    "    corr_first, corr_second,\n",
    "    num_evecs, False,\n",
    "    dist_x, regularized=False,\n",
    "    A2=mass_second,\n",
    "    return_p2p=True,\n",
    "    return_Cxy=True,\n",
    "    evecs_trans_first=torch.linalg.pinv(evecs_first_cotan),\n",
    "    evecs_trans_second=torch.linalg.pinv(evecs_second_cotan),\n",
    "    evals_first=data['first']['evals'].to('cuda'),\n",
    "    evals_second=data['second']['evals'].to('cuda'),\n",
    "    )\n",
    "print(geo_err_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/s94zalek_hpc/shape_matching/pyFM_fork')\n",
    "\n",
    "import pyFM\n",
    "from pyFM.mesh.trimesh import TriMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_1 = TriMesh(\n",
    "    data['first']['verts'].numpy(),\n",
    "    data['first']['faces'].numpy()\n",
    "    )\n",
    "mesh_2 = TriMesh(\n",
    "    data['second']['verts'].numpy(),\n",
    "    data['second']['faces'].numpy()\n",
    "    )\n",
    "mesh_1.process(intrinsic=True, robust=True)\n",
    "mesh_2.process(intrinsic=True, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs_first_pyfm = torch.tensor(mesh_1.eigenvectors, dtype=torch.float32, device='cuda')\n",
    "evecs_second_pyfm = torch.tensor(mesh_2.eigenvectors, dtype=torch.float32, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_err_k, p2p_k, Cxy_k = get_geo_error(\n",
    "    corr_first, corr_second,\n",
    "    # p2p_est_first[k], p2p_est_second[k],\n",
    "    evecs_first_pyfm, evecs_second_pyfm,\n",
    "    corr_first, corr_second,\n",
    "    200, False,\n",
    "    dist_x, regularized=True,\n",
    "    A2=mass_second,\n",
    "    return_p2p=True,\n",
    "    return_Cxy=True,\n",
    "    evecs_trans_first=torch.linalg.pinv(evecs_first_pyfm),\n",
    "    evecs_trans_second=torch.linalg.pinv(evecs_second_pyfm),\n",
    "    evals_first=data['first']['evals'].to('cuda'),\n",
    "    evals_second=data['second']['evals'].to('cuda'),\n",
    "    )\n",
    "print(geo_err_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(399 * 3 + 8 * 9) / 408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_code.utils.median_p2p_map import dirichlet_energy\n",
    "\n",
    "dirichlet_energy(p2p_k, verts_first.cpu(), data['second']['L']),\\\n",
    "    dirichlet_energy(corr_second.cpu(), verts_second.cpu(), data['first']['L']),\\\n",
    "        # dirichlet_energy(corr_second.cpu(), verts_first.cpu(), data['second']['L']),\\\n",
    "# dirichlet_energy(p2p_k, verts_second.cpu(), data['first']['L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_second, p2p_k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

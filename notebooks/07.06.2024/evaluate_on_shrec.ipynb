{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "curr_dir = os.getcwd()\n",
    "if 's94zalek_hpc' in curr_dir:\n",
    "    user_name = 's94zalek_hpc'\n",
    "else:\n",
    "    user_name = 's94zalek'\n",
    "sys.path.append(f'/home/{user_name}/shape_matching')\n",
    "\n",
    "# datasets\n",
    "import my_code.diffusion_training.sample_model as sample_model\n",
    "import my_code.diffusion_training.evaluate_samples as evaluate_samples\n",
    "\n",
    "\n",
    "# models\n",
    "from my_code.models.diag_conditional import DiagConditionedUnet\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import my_code.datasets.template_dataset as template_dataset\n",
    "import my_code.datasets.shape_dataset as shape_dataset\n",
    "\n",
    "import my_code.diffusion_training.data_loading as data_loading\n",
    "\n",
    "\n",
    "\n",
    "def get_subset(dataset, subset_fraction):\n",
    "    \n",
    "    # get n random samples\n",
    "    n_samples = int(len(dataset) * subset_fraction)\n",
    "    subset_indices = torch.randperm(len(dataset))[:n_samples]\n",
    "    \n",
    "    # return the subset\n",
    "    return torch.utils.data.Subset(dataset, subset_indices), subset_indices\n",
    "\n",
    "\n",
    "def plot_pck(metrics, title):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "    thresholds = np.linspace(0., 0.1, 40)\n",
    "    ax.plot(thresholds, torch.mean(metrics['pcks'], axis=0), 'r-',\n",
    "            label=f'auc: {torch.mean(metrics[\"auc\"]):.2f}')\n",
    "    ax.set_xlim(0., 0.1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xscale('linear')\n",
    "    ax.set_xticks([0.025, 0.05, 0.075, 0.1])\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def preprocess_metrics(metrics):\n",
    "    metrics_payload = {}\n",
    "    \n",
    "    metrics_payload['auc'] = round(metrics['auc'].mean(dim=0).item(), 2)\n",
    "    \n",
    "    metrics_payload['geo_err_mean'] = round(metrics['geo_err_est'].mean().item() * 100, 1)\n",
    "    metrics_payload['geo_err_ratio_mean'] = round(metrics['geo_err_ratio'].mean().item(), 2)\n",
    "    metrics_payload['geo_err_ratio_median'] = round(metrics['geo_err_ratio'].median().item(), 2)\n",
    "    metrics_payload['geo_err_ratio_max'] = round(metrics['geo_err_ratio'].max().item(), 2)\n",
    "    metrics_payload['geo_err_ratio_min'] = round(metrics['geo_err_ratio'].min().item(), 2)\n",
    "    \n",
    "    metrics_payload['mse_mean'] = round(metrics['mse_abs'].mean().item(), 2)\n",
    "    metrics_payload['mse_median'] = round(metrics['mse_abs'].median().item(), 2)\n",
    "    metrics_payload['mse_max'] = round(metrics['mse_abs'].max().item(), 2)\n",
    "    metrics_payload['mse_min'] = round(metrics['mse_abs'].min().item(), 2)\n",
    "    \n",
    "    return metrics_payload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'test_faceScaling_faustRA'\n",
    "checkpoint_name = 'checkpoint_60'\n",
    "subset_fraction = 100\n",
    "dataset_name = 'FAUST_orig'\n",
    "\n",
    "\n",
    "### config\n",
    "exp_base_folder = f'my_code/experiments/{experiment_name}'\n",
    "with open(f'{exp_base_folder}/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "### model\n",
    "model = DiagConditionedUnet(config[\"model_params\"]).to('cuda')\n",
    "model.load_state_dict(torch.load(f\"{exp_base_folder}/checkpoints/{checkpoint_name}.pt\"))\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, 'train', config[\"model_params\"][\"sample_size\"]\n",
    "    )[1]\n",
    "    \n",
    "\n",
    "### sample the model\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='squaredcos_cap_v2',\n",
    "                                clip_sample=True)\n",
    "x_sampled = sample_model.sample_dataset(model, test_dataset, noise_scheduler)    \n",
    "\n",
    "\n",
    "### assign gt signs and unnormalize the samples \n",
    "x_gt = torch.stack([test_dataset[i]['second']['C_gt_xy'] for i in range(len(test_dataset))])\n",
    "fmap_sampled = torch.sign(x_gt) * (x_sampled + 1) / 2\n",
    "\n",
    "\n",
    "### calculate metrics\n",
    "metrics = evaluate_samples.calculate_metrics(\n",
    "    fmap_sampled,\n",
    "    test_dataset\n",
    ")\n",
    "metrics_payload = preprocess_metrics(metrics)\n",
    "fig = plot_pck(metrics, title=f\"PCK on {dataset_name}_{subset_fraction}\")\n",
    "\n",
    "\n",
    "### print the metrics\n",
    "print(f\"AUC mean: {metrics_payload['auc']}\\n\")\n",
    "print(f'GeoErr mean: {metrics_payload[\"geo_err_mean\"]}\\n')\n",
    "print(f\"GeoErr ratio mean: {metrics_payload['geo_err_ratio_mean']}\")\n",
    "print(f\"GeoErr ratio median: {metrics_payload['geo_err_ratio_median']}\")\n",
    "print(f'GeoErr ratio max: {metrics_payload[\"geo_err_ratio_max\"]}', f'min: {metrics_payload[\"geo_err_ratio_min\"]}\\n')\n",
    "print(f\"MSE mean: {metrics_payload['mse_mean']}\")\n",
    "print(f\"MSE median: {metrics_payload['mse_median']}\")\n",
    "print(f\"MSE max: {metrics_payload['mse_max']}\", f\"min: {metrics_payload['mse_min']}\")\n",
    "\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

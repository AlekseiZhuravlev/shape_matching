{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "/home/s94zalek/shape_matching\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/s94zalek/shape_matching')\n",
    "\n",
    "# set logging level to info\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from datasets_code import build_dataloader, build_dataset\n",
    "from utils.options import parse_options\n",
    "from train import create_train_val_dataloader\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.chdir('/home/s94zalek/shape_matching')\n",
    "\n",
    "# print current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend DataParallel.\n",
      "Path already exists. Rename it to /home/s94zalek/shape_matching/results/faust_archived_20240502_123311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing DatasetFromListOfDicts: 100%|█████████████████████████████████████████████████████████████████████████████| 80/80 [00:04<00:00, 18.61it/s]\n",
      "Calculating functional maps: 100%|█████████████████████████████████████████████████████████████████████████████████| 6400/6400 [01:10<00:00, 90.83it/s]\n",
      "2024-05-02 12:34:26,178 INFO: Dataset [PairFaustDataset]-[FaustTrain] is built.\n",
      "Constructing DatasetFromListOfDicts: 100%|█████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 25.86it/s]\n",
      "Calculating functional maps: 100%|██████████████████████████████████████████████████████████████████████████████████| 400/400 [00:03<00:00, 102.82it/s]\n",
      "2024-05-02 12:34:30,854 INFO: Dataset [PairFaustDataset]-[FaustTest] is built.\n",
      "Constructing DatasetFromListOfDicts: 100%|█████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 30.87it/s]\n",
      "Calculating functional maps: 100%|██████████████████████████████████████████████████████████████████████████████████| 400/400 [00:03<00:00, 103.35it/s]\n",
      "2024-05-02 12:34:35,380 INFO: Dataset [PairFaustDataset]-[FaustTest] is built.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# root_path = osp.abspath(osp.join(__file__, osp.pardir))\n",
    "root_path = '/home/s94zalek/shape_matching'\n",
    "\n",
    "opt = parse_options(root_path, is_train=False, use_argparse=False,\n",
    "                    opt_path = 'options/train/faust.yaml')\n",
    "\n",
    "opt['root_path'] = root_path\n",
    "opt['dist'] = False\n",
    "\n",
    "opt['datasets']['train_dataset']['return_corr'] = True\n",
    "opt['datasets']['train_dataset']['return_dist'] = False\n",
    "opt['datasets']['test_dataset']['return_dist'] = False\n",
    "\n",
    "# create train and validation dataloaders\n",
    "result = create_train_val_dataloader(opt)\n",
    "train_loader, train_sampler, val_loader, total_epochs, total_iters = result\n",
    "\n",
    "test_set = build_dataset(opt['datasets']['test_dataset'])\n",
    "test_loader = build_dataloader(\n",
    "test_set, opt['datasets']['test_dataset'], phase='val', num_gpu=opt['num_gpu'], dist=opt['dist'], sampler=None, seed=opt['manual_seed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cxy_40 = []\n",
    "Dx_40 = []\n",
    "Dy_40 = []\n",
    "\n",
    "Vxy_computed_40 = []\n",
    "Rxy_computed_40 = []\n",
    "\n",
    "data_40 = []\n",
    "\n",
    "train_dataset = train_loader.dataset\n",
    "for i in range(len(train_dataset)):\n",
    "    data = train_dataset[i]\n",
    "    if data['first']['name'] == 'tr_reg_040':\n",
    "        \n",
    "        Cxy_40.append(data['Cxy'])\n",
    "        \n",
    "        Dx_40.append(data['first']['evals'])\n",
    "        Dy_40.append(data['second']['evals'])\n",
    "        \n",
    "        Vxy_computed_40.append(data['Vxy'])\n",
    "        Rxy_computed_40.append(data['Rxy'])\n",
    "        \n",
    "        data_40.append(data)\n",
    "        \n",
    "Cxy_40_full = torch.stack(Cxy_40)\n",
    "Cxy_40_truncated = torch.stack(Cxy_40)[:, :20, :20]\n",
    "\n",
    "Dx_40_full = torch.stack(Dx_40)\n",
    "Dy_40_full = torch.stack(Dy_40)\n",
    "\n",
    "Vxy_computed_40_full = torch.stack(Vxy_computed_40)\n",
    "Rxy_computed_40_full = torch.stack(Rxy_computed_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# Check if difference operators in dataset are correct\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cxy_T_Cxy_40_full = torch.bmm(Cxy_40_full.transpose(1, 2), Cxy_40_full)\n",
    "\n",
    "Rxy_40_left = torch.bmm(\n",
    "    torch.diag_embed(-1 / Dx_40_full),\n",
    "    Cxy_40_full.transpose(1, 2)\n",
    "    )\n",
    "Rxy_40_right = torch.bmm(\n",
    "    torch.diag_embed(-Dy_40_full),\n",
    "    Cxy_40_full\n",
    "    )\n",
    "\n",
    "Rxy_40_full = torch.bmm(Rxy_40_left, Rxy_40_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vxy in dataset - Vxy computed: tensor(0.0002)\n",
      "Rxy in dataset - Rxy computed: tensor(-6.4227e-05)\n"
     ]
    }
   ],
   "source": [
    "print('Vxy in dataset - Vxy computed:', (Vxy_computed_40_full - Cxy_T_Cxy_40_full).sum())\n",
    "print('Rxy in dataset - Rxy computed:', (Rxy_40_full - Rxy_computed_40_full).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#\n",
    "# Descriptor preservation by GT Fmap\n",
    "#\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 200]), torch.Size([200, 5001]), torch.Size([5001, 200]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_40[21]\n",
    "data_x = data['first']\n",
    "data_y = data['second']\n",
    "\n",
    "data['Cxy'].shape, data_x['evecs_trans'].shape, data_y['evecs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicator preserv. loss,  50 ef, sum: tensor(0.3631) mean: tensor(0.0001)\n",
      "Indicator preserv. loss, 100 ef, sum: tensor(1.6721) mean: tensor(0.0002)\n",
      "Indicator preserv. loss, 150 ef, sum: tensor(3.8614) mean: tensor(0.0002)\n",
      "Indicator preserv. loss, 200 ef, sum: tensor(5.6738) mean: tensor(0.0001)\n"
     ]
    }
   ],
   "source": [
    "# indicator functions as descriptors\n",
    "\n",
    "ind_pres_loss = (data['Cxy'] @ data_x['evecs_trans'] - data_y['evecs_trans']).abs()\n",
    "\n",
    "print('Indicator preserv. loss,  50 ef, sum:',\n",
    "      ind_pres_loss[:50, :50].sum(), 'mean:', ind_pres_loss[:50, :50].mean())\n",
    "print('Indicator preserv. loss, 100 ef, sum:', ind_pres_loss[:100, :100].sum(),\n",
    "      'mean:', ind_pres_loss[:100, :100].mean())\n",
    "print('Indicator preserv. loss, 150 ef, sum:', ind_pres_loss[:150, :150].sum(),\n",
    "      'mean:', ind_pres_loss[:150, :150].mean())\n",
    "print('Indicator preserv. loss, 200 ef, sum:', ind_pres_loss[:200, :200].sum(),\n",
    "      'mean:', ind_pres_loss[:200, :200].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I guess this counts as preservation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HKS preserv. loss,  50 ef, sum: tensor(17.4320) mean: tensor(0.0218)\n",
      "HKS preserv. loss, 100 ef, sum: tensor(21.4995) mean: tensor(0.0134)\n",
      "HKS preserv. loss, 150 ef, sum: tensor(24.1054) mean: tensor(0.0100)\n",
      "HKS preserv. loss, 200 ef, sum: tensor(25.4915) mean: tensor(0.0080)\n"
     ]
    }
   ],
   "source": [
    "import utils.geometry_util as geometry_util\n",
    "\n",
    "# hks as descriptors\n",
    "hks_x = geometry_util.compute_hks_autoscale(data_x['evals'].unsqueeze(0), data_x['evecs'].unsqueeze(0), 16)[0]\n",
    "hks_y = geometry_util.compute_hks_autoscale(data_y['evals'].unsqueeze(0), data_y['evecs'].unsqueeze(0), 16)[0]\n",
    "\n",
    "hks_pres_loss = (data['Cxy'] @ data_x['evecs_trans'] @ hks_x - data_y['evecs_trans'] @ hks_y).abs()\n",
    "\n",
    "print('HKS preserv. loss,  50 ef, sum:', hks_pres_loss[:50, :50].sum(), 'mean:', hks_pres_loss[:50, :50].mean())\n",
    "print('HKS preserv. loss, 100 ef, sum:', hks_pres_loss[:100, :100].sum(), 'mean:', hks_pres_loss[:100, :100].mean())\n",
    "print('HKS preserv. loss, 150 ef, sum:', hks_pres_loss[:150, :150].sum(), 'mean:', hks_pres_loss[:150, :150].mean())\n",
    "print('HKS preserv. loss, 200 ef, sum:', hks_pres_loss[:200, :200].sum(), 'mean:', hks_pres_loss[:200, :200].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WKS preserv. loss,  50 ef, sum: tensor(25.3663) mean: tensor(0.0101)\n",
      "WKS preserv. loss, 100 ef, sum: tensor(77.3188) mean: tensor(0.0077)\n",
      "WKS preserv. loss, 150 ef, sum: tensor(126.9926) mean: tensor(0.0066)\n",
      "WKS preserv. loss, 200 ef, sum: tensor(149.6696) mean: tensor(0.0058)\n"
     ]
    }
   ],
   "source": [
    "# wks as descriptors\n",
    "\n",
    "wks_x = geometry_util.compute_wks_autoscale(data_x['evals'].unsqueeze(0), data_x['evecs'].unsqueeze(0), data_x['mass'].unsqueeze(0))[0]\n",
    "wks_y = geometry_util.compute_wks_autoscale(data_y['evals'].unsqueeze(0), data_y['evecs'].unsqueeze(0), data_y['mass'].unsqueeze(0))[0]\n",
    "\n",
    "wks_pres_loss = (data['Cxy'] @ data_x['evecs_trans'] @ wks_x - data_y['evecs_trans'] @ wks_y).abs()\n",
    "\n",
    "print('WKS preserv. loss,  50 ef, sum:', wks_pres_loss[:50, :50].sum(), 'mean:', wks_pres_loss[:50, :50].mean())\n",
    "print('WKS preserv. loss, 100 ef, sum:', wks_pres_loss[:100, :100].sum(), 'mean:', wks_pres_loss[:100, :100].mean())\n",
    "print('WKS preserv. loss, 150 ef, sum:', wks_pres_loss[:150, :150].sum(), 'mean:', wks_pres_loss[:150, :150].mean())\n",
    "print('WKS preserv. loss, 200 ef, sum:', wks_pres_loss[:200, :200].sum(), 'mean:', wks_pres_loss[:200, :200].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#\n",
    "# Does this count as descriptor preservation?\n",
    "#\n",
    "########################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

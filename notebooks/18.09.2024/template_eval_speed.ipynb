{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# models\n",
    "from my_code.models.diag_conditional import DiagConditionedUnet\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "import my_code.datasets.template_dataset as template_dataset\n",
    "\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "\n",
    "import networks.diffusion_network as diffusion_network\n",
    "import matplotlib.pyplot as plt\n",
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "import utils.fmap_util as fmap_util\n",
    "import metrics.geodist_metric as geodist_metric\n",
    "from my_code.sign_canonicalization.training import predict_sign_change\n",
    "import argparse\n",
    "from pyFM_fork.pyFM.refine.zoomout import zoomout_refine\n",
    "import my_code.utils.zoomout_custom as zoomout_custom\n",
    "from utils.shape_util import compute_geodesic_distmat\n",
    "from my_code.diffusion_training_sign_corr.test.test_diffusion_cond import select_p2p_map_dirichlet, log_to_database, parse_args\n",
    "import accelerate\n",
    "\n",
    "tqdm._instances.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_geodesic_error(dist_x, corr_x, corr_y, p2p, return_mean=True):\n",
    "    \"\"\"\n",
    "    Calculate the geodesic error between predicted correspondence and gt correspondence\n",
    "\n",
    "    Args:\n",
    "        dist_x (np.ndarray): Geodesic distance matrix of shape x. shape [Vx, Vx]\n",
    "        corr_x (np.ndarray): Ground truth correspondences of shape x. shape [V]\n",
    "        corr_y (np.ndarray): Ground truth correspondences of shape y. shape [V]\n",
    "        p2p (np.ndarray): Point-to-point map (shape y -> shape x). shape [Vy]\n",
    "        return_mean (bool, optional): Average the geodesic error. Default True.\n",
    "    Returns:\n",
    "        avg_geodesic_error (np.ndarray): Average geodesic error.\n",
    "    \"\"\"\n",
    "        \n",
    "    ind21 = np.stack([corr_x, p2p[corr_y]], axis=-1)\n",
    "    \n",
    "    ind21 = np.ravel_multi_index(ind21.T, dims=[dist_x.shape[0], dist_x.shape[0]]) \n",
    "\n",
    "    geo_err = np.take(dist_x, ind21)\n",
    "\n",
    "    if return_mean:\n",
    "        return geo_err.mean()\n",
    "    else:\n",
    "        return geo_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_geodesic_error_torch(dist_x, corr_x, corr_y, p2p, return_mean=True):\n",
    "    \n",
    "    pred_x = p2p[corr_y]\n",
    "    \n",
    "    # index the distance matrix\n",
    "    geo_err = dist_x[corr_x, pred_x]\n",
    "    \n",
    "    if return_mean:\n",
    "        return geo_err.mean()\n",
    "    \n",
    "    return geo_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_error(\n",
    "    p2p_first, p2p_second,\n",
    "    evecs_first, evecs_second,\n",
    "    corr_first, corr_second,\n",
    "    num_evecs, apply_zoomout,\n",
    "    dist_x\n",
    "    ):\n",
    "    Cxy = torch.linalg.lstsq(\n",
    "        evecs_second[:, :num_evecs][p2p_second],\n",
    "        evecs_first[:, :num_evecs][p2p_first]\n",
    "        ).solution\n",
    "    \n",
    "    if apply_zoomout:\n",
    "        Cxy = zoomout_custom.zoomout(\n",
    "            FM_12=Cxy, \n",
    "            evects1=evecs_first,\n",
    "            evects2=evecs_second,\n",
    "            nit=evecs_first.shape[1] - num_evecs, step=1,\n",
    "        )\n",
    "        num_evecs = evecs_first.shape[1]\n",
    "        \n",
    "    p2p = fmap_util.fmap2pointmap(\n",
    "        C12=Cxy,\n",
    "        evecs_x=evecs_first[:, :num_evecs],\n",
    "        evecs_y=evecs_second[:, :num_evecs],\n",
    "        )\n",
    "    \n",
    "    # geo_err = calculate_geodesic_error(\n",
    "    #     dist_x.cpu().numpy(), corr_first.cpu().numpy(), corr_second.cpu().numpy(), p2p.cpu().numpy(), return_mean=True\n",
    "    # )\n",
    "    # geo_err = torch.tensor(geo_err)\n",
    "    \n",
    "    geo_err_torch = calculate_geodesic_error_torch(\n",
    "        dist_x, corr_first, corr_second, p2p, return_mean=True\n",
    "    ).cpu()\n",
    "    \n",
    "    # assert torch.allclose(geo_err, geo_err_torch), f\"{geo_err} != {geo_err_torch}\"\n",
    "    \n",
    "    # return geo_err * 100\n",
    "    \n",
    "    return geo_err_torch * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self):\n",
    "        self.experiment_name='single_48_remeshed_noAcc_yx_64_128_128'\n",
    "        self.num_iters_avg=25\n",
    "        self.checkpoint_name='checkpoint_90.pt'\n",
    "        \n",
    "        self.dataset_name='FAUST_a_pair'\n",
    "        self.split='test'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "\n",
    "# configuration\n",
    "experiment_name = args.experiment_name\n",
    "checkpoint_name = args.checkpoint_name\n",
    "\n",
    "### config\n",
    "exp_base_folder = f'/home/s94zalek_hpc/shape_matching/my_code/experiments/ddpm/{experiment_name}'\n",
    "with open(f'{exp_base_folder}/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "### model\n",
    "model = DiagConditionedUnet(config[\"model_params\"]).to('cuda')\n",
    "\n",
    "if \"accelerate\" in config and config[\"accelerate\"]:\n",
    "    accelerate.load_checkpoint_in_model(model, f\"{exp_base_folder}/checkpoints/{checkpoint_name}/model.safetensors\")\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f\"{exp_base_folder}/checkpoints/{checkpoint_name}\"))\n",
    "\n",
    "\n",
    "model = model.to('cuda')\n",
    "\n",
    "### Sign correction network\n",
    "sign_corr_net = diffusion_network.DiffusionNet(\n",
    "    **config[\"sign_net\"][\"net_params\"]\n",
    "    ).to('cuda')\n",
    "    \n",
    "sign_corr_net.load_state_dict(torch.load(\n",
    "        f'{config[\"sign_net\"][\"net_path\"]}/{config[\"sign_net\"][\"n_iter\"]}.pth'\n",
    "        ))\n",
    "\n",
    "\n",
    "### sample the model\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='squaredcos_cap_v2',\n",
    "                                clip_sample=True) \n",
    "\n",
    "\n",
    "### test dataset\n",
    "dataset_name = args.dataset_name\n",
    "split = args.split\n",
    "\n",
    "single_dataset, test_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, split, 200, preload=False, return_evecs=True\n",
    "    )\n",
    "sign_corr_net.cache_dir = single_dataset.lb_cache_dir\n",
    "\n",
    "\n",
    "num_evecs = config[\"model_params\"][\"sample_size\"]\n",
    "\n",
    "\n",
    "##########################################\n",
    "# Template\n",
    "##########################################\n",
    "\n",
    "template_shape = template_dataset.get_template(\n",
    "    # template_path='data/SURREAL_full/template/template.ply',\n",
    "    num_evecs=single_dataset.num_evecs,\n",
    "    # template_corr=list(range(6890)),\n",
    "    centering='bbox',\n",
    "    \n",
    "    template_path=f'/home/s94zalek_hpc/shape_matching/data/SURREAL_full/template/{config[\"sign_net\"][\"template_type\"]}/template.off',\n",
    "    template_corr=np.loadtxt(\n",
    "        f'/home/s94zalek_hpc/shape_matching/data/SURREAL_full/template/{config[\"sign_net\"][\"template_type\"]}/corr.txt',\n",
    "        dtype=np.int32) - 1\n",
    "    )    \n",
    "\n",
    "##########################################\n",
    "# Logging\n",
    "##########################################\n",
    "\n",
    "# log_dir = f'{exp_base_folder}/eval/{checkpoint_name}/{dataset_name}-{split}-template'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# fig_dir = f'{log_dir}/figs'\n",
    "# os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "# log_file_name = f'{log_dir}/log.txt'\n",
    "\n",
    "log_dir = f'{exp_base_folder}/eval/{checkpoint_name}/{dataset_name}-{split}/no_smoothing'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "fig_dir = f'{log_dir}/figs'\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "log_file_name = f'{log_dir}/log.txt'\n",
    "\n",
    "\n",
    "##########################################\n",
    "# Template stage\n",
    "##########################################\n",
    "\n",
    "data_range = tqdm(range(len(single_dataset)), desc='Calculating fmaps to template')\n",
    "\n",
    "# data_range = tqdm(range(2))\n",
    "# print('!!! WARNING: only 2 samples are processed !!!')\n",
    "\n",
    "for i in data_range:\n",
    "\n",
    "    data = single_dataset[i]\n",
    "    \n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # device = 'cpu'\n",
    "    \n",
    "    verts_first = template_shape['verts'].unsqueeze(0).to(device)\n",
    "    verts_second = data['verts'].unsqueeze(0).to(device)\n",
    "    \n",
    "    faces_first = template_shape['faces'].unsqueeze(0).to(device)\n",
    "    faces_second = data['faces'].unsqueeze(0).to(device)\n",
    "\n",
    "    evecs_first = template_shape['evecs'][:, :num_evecs].unsqueeze(0).to(device)\n",
    "    evecs_second = data['evecs'][:, :num_evecs].unsqueeze(0).to(device)\n",
    "    \n",
    "    evals_first = template_shape['evals'][:num_evecs]\n",
    "    evals_second = data['evals'][:num_evecs]\n",
    "\n",
    "    # corr_first = data['first']['corr']\n",
    "    # corr_second = data['corr']\n",
    "    \n",
    "    if config[\"sign_net\"][\"with_mass\"]:\n",
    "        mass_mat_first = torch.diag_embed(\n",
    "            template_shape['mass'].unsqueeze(0)\n",
    "            ).to(device)\n",
    "        mass_mat_second = torch.diag_embed(\n",
    "            data['mass'].unsqueeze(0)\n",
    "            ).to(device)\n",
    "    else:\n",
    "        mass_mat_first = None\n",
    "        mass_mat_second = None\n",
    "\n",
    "\n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_first, support_vector_norm_first, _ = predict_sign_change(\n",
    "            sign_corr_net, verts_first, faces_first, evecs_first, \n",
    "            mass_mat=mass_mat_first, input_type=sign_corr_net.input_type,\n",
    "            # mass=None, L=None, evals=None, evecs=None, gradX=None, gradY=None\n",
    "            mass=template_shape['mass'].unsqueeze(0), L=template_shape['L'].unsqueeze(0),\n",
    "            evals=template_shape['evals'][:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "            evecs=template_shape['evecs'][:,:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "            gradX=template_shape['gradX'].unsqueeze(0), gradY=template_shape['gradY'].unsqueeze(0)\n",
    "            )\n",
    "        sign_pred_second, support_vector_norm_second, _ = predict_sign_change(\n",
    "            sign_corr_net, verts_second, faces_second, evecs_second, \n",
    "            mass_mat=mass_mat_second, input_type=sign_corr_net.input_type,\n",
    "            # mass=None, L=None, evals=None, evecs=None, gradX=None, gradY=None\n",
    "            mass=data['mass'].unsqueeze(0), L=data['L'].unsqueeze(0),\n",
    "            evals=data['evals'][:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "            evecs=data['evecs'][:,:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "            gradX=data['gradX'].unsqueeze(0), gradY=data['gradY'].unsqueeze(0)\n",
    "            )\n",
    "\n",
    "    # correct the evecs\n",
    "    evecs_first_corrected = evecs_first.cpu()[0] * torch.sign(sign_pred_first).cpu()\n",
    "    evecs_first_corrected_norm = evecs_first_corrected / torch.norm(evecs_first_corrected, dim=0, keepdim=True)\n",
    "    \n",
    "    evecs_second_corrected = evecs_second.cpu()[0] * torch.sign(sign_pred_second).cpu()\n",
    "    evecs_second_corrected_norm = evecs_second_corrected / torch.norm(evecs_second_corrected, dim=0, keepdim=True)\n",
    "    \n",
    "    # product with support\n",
    "    # evecs_cond_first = evecs_first_corrected_norm.transpose(0, 1) @ support_vector_norm_first[0].cpu()\n",
    "    # evecs_cond_second = evecs_second_corrected_norm.transpose(0, 1) @ support_vector_norm_second[0].cpu()\n",
    "\n",
    "\n",
    "    # product with support\n",
    "    if config[\"sign_net\"][\"with_mass\"]:\n",
    "    # if config[\"sign_net\"]['cond_mass_normalize']:\n",
    "        \n",
    "        mass_mat_first = torch.diag_embed(\n",
    "            template_shape['mass'].unsqueeze(0)\n",
    "            ).to(device)\n",
    "        mass_mat_second = torch.diag_embed(\n",
    "            data['mass'].unsqueeze(0)\n",
    "            ).to(device)\n",
    "        \n",
    "        evecs_cond_first = torch.nn.functional.normalize(\n",
    "            support_vector_norm_first[0].cpu().transpose(0, 1) \\\n",
    "                @ mass_mat_first[0].cpu(),\n",
    "            p=2, dim=1) \\\n",
    "                @ evecs_first_corrected_norm\n",
    "        \n",
    "        evecs_cond_second = torch.nn.functional.normalize(\n",
    "            support_vector_norm_second[0].cpu().transpose(0, 1) \\\n",
    "                @ mass_mat_second[0].cpu(),\n",
    "            p=2, dim=1) \\\n",
    "                @ evecs_second_corrected_norm \n",
    "        \n",
    "    else:\n",
    "        evecs_cond_first = support_vector_norm_first[0].cpu().transpose(0, 1) @ evecs_first_corrected_norm\n",
    "        evecs_cond_second = support_vector_norm_second[0].cpu().transpose(0, 1) @ evecs_second_corrected_norm\n",
    "    \n",
    "    \n",
    "    ###############################################\n",
    "    # Conditioning\n",
    "    ###############################################\n",
    "\n",
    "    conditioning = torch.tensor([])\n",
    "    \n",
    "    if 'evals' in config[\"conditioning_types\"]:\n",
    "        eval = evals_second.unsqueeze(0)\n",
    "        eval = torch.diag_embed(eval)\n",
    "        conditioning = torch.cat((conditioning, eval), 0)\n",
    "    \n",
    "    if 'evals_inv' in config[\"conditioning_types\"]:\n",
    "        eval_inv = 1 / evals_second.unsqueeze(0)\n",
    "        # replace elements > 1 with 1\n",
    "        eval_inv[eval_inv > 1] = 1\n",
    "        eval_inv = torch.diag_embed(eval_inv)\n",
    "        conditioning = torch.cat((conditioning, eval_inv), 0)\n",
    "    \n",
    "    if 'evecs' in config[\"conditioning_types\"]:\n",
    "        evecs = torch.cat(\n",
    "            (evecs_cond_first.unsqueeze(0), evecs_cond_second.unsqueeze(0)),\n",
    "            0)\n",
    "        conditioning = torch.cat((conditioning, evecs), 0)\n",
    "    \n",
    "    \n",
    "    ###############################################\n",
    "    # Sample the model\n",
    "    ###############################################\n",
    "    \n",
    "    x_sampled = torch.rand(args.num_iters_avg, 1, model.model.sample_size, model.model.sample_size).to(device)\n",
    "    y = conditioning.unsqueeze(0).repeat(args.num_iters_avg, 1, 1, 1).to(device)    \n",
    "    \n",
    "    # print(x_sampled.shape, y.shape)\n",
    "        \n",
    "    # Sampling loop\n",
    "    for t in noise_scheduler.timesteps:\n",
    "\n",
    "        # Get model pred\n",
    "        with torch.no_grad():\n",
    "            residual = model(x_sampled, t,\n",
    "                                conditioning=y\n",
    "                                ).sample\n",
    "\n",
    "        # Update sample with step\n",
    "        x_sampled = noise_scheduler.step(residual, t, x_sampled).prev_sample\n",
    "    \n",
    "    \n",
    "    ###############################################\n",
    "    # Zoomout\n",
    "    ###############################################\n",
    "    \n",
    "    evecs_first_zo = torch.cat(\n",
    "        [evecs_first_corrected,\n",
    "            template_shape['evecs'][:, num_evecs:]], 1)\n",
    "    evecs_second_zo = torch.cat(\n",
    "        [evecs_second_corrected,\n",
    "            data['evecs'][:, num_evecs:]], 1)\n",
    "    \n",
    "    \n",
    "    # single_dataset.additional_data[i]['Cyx_est'] = []\n",
    "    # single_dataset.additional_data[i]['Cyx_est_zo'] = []\n",
    "    single_dataset.additional_data[i]['evecs_zo'] = evecs_second_zo\n",
    "\n",
    "    single_dataset.additional_data[i]['p2p_est'] = []\n",
    "    # single_dataset.additional_data[i]['p2p_est_zo'] = []\n",
    "    \n",
    "    for k in range(args.num_iters_avg):\n",
    "        Cyx_est_k = x_sampled[k][0].cpu()\n",
    "    \n",
    "        Cyx_est_zo_k = zoomout_custom.zoomout(\n",
    "            FM_12=Cyx_est_k.to(device), \n",
    "            evects1=evecs_second_zo.to(device), \n",
    "            evects2=evecs_first_zo.to(device),\n",
    "            nit=evecs_first_zo.shape[1] - num_evecs, step=1,\n",
    "        ).cpu()\n",
    "\n",
    "        p2p_est_k = fmap_util.fmap2pointmap(\n",
    "            C12=Cyx_est_k.to(device),\n",
    "            evecs_x=evecs_second_corrected.to(device),\n",
    "            evecs_y=evecs_first_corrected.to(device),\n",
    "            ).cpu()\n",
    "\n",
    "        p2p_est_zo_k = fmap_util.fmap2pointmap(\n",
    "            C12=Cyx_est_zo_k.to(device),\n",
    "            evecs_x=evecs_second_zo.to(device),\n",
    "            evecs_y=evecs_first_zo.to(device),\n",
    "            ).cpu()\n",
    "\n",
    "        # single_dataset.additional_data[i]['Cyx_est'].append(Cyx_est_k)\n",
    "        # single_dataset.additional_data[i]['Cyx_est_zo'].append(Cyx_est_zo_k)\n",
    "        # single_dataset.additional_data[i]['evecs_zo'] = evecs_second_zo\n",
    "\n",
    "        single_dataset.additional_data[i]['p2p_est'].append(p2p_est_k)\n",
    "        # single_dataset.additional_data[i]['p2p_est_zo'].append(p2p_est_zo_k)\n",
    "        \n",
    "        \n",
    "    single_dataset.additional_data[i]['p2p_est'] = torch.stack(single_dataset.additional_data[i]['p2p_est'])\n",
    "        \n",
    "    ##########################################################\n",
    "    # p2p map selection\n",
    "    ##########################################################\n",
    "    \n",
    "    dist_second = torch.tensor(\n",
    "        compute_geodesic_distmat(\n",
    "            verts_second[0].cpu().numpy(),\n",
    "            faces_second[0].cpu().numpy())    \n",
    "    )\n",
    "    \n",
    "    p2p_dirichlet, p2p_median, dirichlet_energy_list = select_p2p_map_dirichlet(\n",
    "        single_dataset.additional_data[i]['p2p_est'],\n",
    "        verts_second[0].cpu(),\n",
    "        template_shape['L'], \n",
    "        dist_second\n",
    "        )\n",
    "    \n",
    "    single_dataset.additional_data[i]['p2p_dirichlet'] = p2p_dirichlet\n",
    "    single_dataset.additional_data[i]['p2p_median'] = p2p_median\n",
    "    \n",
    "    single_dataset.additional_data[i]['geo_dist'] = dist_second\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##########################################\n",
    "# Pairwise stage\n",
    "##########################################\n",
    "    \n",
    "def pairwise_stage():\n",
    "    \n",
    "    test_dataset.dataset = single_dataset\n",
    "        \n",
    "    geo_errs_gt = []\n",
    "    geo_errs_corr_gt = []\n",
    "    geo_errs_pairzo = []\n",
    "    geo_errs_dirichlet = []\n",
    "    geo_errs_median = []\n",
    "\n",
    "        \n",
    "    # data_range_pair = tqdm(range(len(test_dataset)), desc='Calculating pair fmaps')\n",
    "\n",
    "    data_range_pair = tqdm(range(10), desc='Calculating pair fmaps')\n",
    "\n",
    "    # data_range_pair = tqdm(range(2))\n",
    "    # print('!!! WARNING: only 2 samples are processed !!!')\n",
    "\n",
    "    for i in data_range_pair:\n",
    "        \n",
    "        data = test_dataset[i]        \n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # device = 'cpu'\n",
    "        \n",
    "        verts_first = data['first']['verts'].to(device)\n",
    "        verts_second = data['second']['verts'].to(device)\n",
    "        \n",
    "        faces_first = data['first']['faces'].to(device)\n",
    "        faces_second = data['second']['faces'].to(device)\n",
    "\n",
    "        evecs_first = data['first']['evecs'][:, :].to(device)\n",
    "        evecs_second = data['second']['evecs'][:, :].to(device)\n",
    "        \n",
    "        evals_first = data['first']['evals'][:num_evecs]\n",
    "        evals_second = data['second']['evals'][:num_evecs]\n",
    "\n",
    "        corr_first = data['first']['corr'].to(device)\n",
    "        corr_second = data['second']['corr'].to(device)\n",
    "        \n",
    "        ###############################################\n",
    "        # Functional maps\n",
    "        ###############################################\n",
    "        \n",
    "        evecs_first_zo = data['first']['evecs_zo'].to(device)\n",
    "        evecs_second_zo = data['second']['evecs_zo'].to(device)\n",
    "        \n",
    "        p2p_est_first = data['first']['p2p_est'].to(device)\n",
    "        p2p_est_second = data['second']['p2p_est'].to(device)\n",
    "        \n",
    "        p2p_dirichlet_first = data['first']['p2p_dirichlet'].to(device)\n",
    "        p2p_dirichlet_second = data['second']['p2p_dirichlet'].to(device)\n",
    "        \n",
    "        p2p_median_first = data['first']['p2p_median'].to(device)\n",
    "        p2p_median_second = data['second']['p2p_median'].to(device)\n",
    "        \n",
    "        # dist_x = torch.tensor(\n",
    "        #     compute_geodesic_distmat(data['first']['verts'].numpy(), data['first']['faces'].numpy())    \n",
    "        # )\n",
    "        dist_x = data['first']['geo_dist'].to(device)\n",
    "        \n",
    "        ###############################################\n",
    "        # Geodesic errors\n",
    "        ###############################################\n",
    "        \n",
    "        # GT geo error\n",
    "        geo_err_gt = get_geo_error(\n",
    "            corr_first, corr_second,\n",
    "            evecs_first, evecs_second,\n",
    "            corr_first, corr_second,\n",
    "            num_evecs, False,\n",
    "            dist_x\n",
    "            )\n",
    "        geo_err_corr_gt = get_geo_error(\n",
    "            corr_first, corr_second,\n",
    "            evecs_first_zo, evecs_second_zo,\n",
    "            corr_first, corr_second,\n",
    "            num_evecs, False,\n",
    "            dist_x\n",
    "            )\n",
    "        \n",
    "        # mean pred geo error with zoomout\n",
    "        geo_err_est_pairzo = []\n",
    "        for k in range(args.num_iters_avg):\n",
    "            geo_err_est_pairzo.append(\n",
    "                get_geo_error(\n",
    "                p2p_est_first[k], p2p_est_second[k],\n",
    "                evecs_first_zo, evecs_second_zo,\n",
    "                corr_first, corr_second,\n",
    "                num_evecs, True,\n",
    "                dist_x\n",
    "                ))\n",
    "        geo_err_est_pairzo = torch.tensor(geo_err_est_pairzo)\n",
    "        \n",
    "        # dirichlet geo error\n",
    "        geo_err_est_dirichlet = get_geo_error(\n",
    "            p2p_dirichlet_first, p2p_dirichlet_second,\n",
    "            evecs_first_zo, evecs_second_zo,\n",
    "            corr_first, corr_second,\n",
    "            num_evecs, True,\n",
    "            dist_x\n",
    "            )\n",
    "        \n",
    "        # median geo error\n",
    "        geo_err_est_median = get_geo_error(\n",
    "            p2p_median_first, p2p_median_second,\n",
    "            evecs_first_zo, evecs_second_zo,\n",
    "            corr_first, corr_second,\n",
    "            num_evecs, True,\n",
    "            dist_x\n",
    "            )\n",
    "\n",
    "        geo_errs_gt.append(geo_err_gt)\n",
    "        geo_errs_corr_gt.append(geo_err_corr_gt)\n",
    "        geo_errs_pairzo.append(geo_err_est_pairzo.mean())\n",
    "        geo_errs_dirichlet.append(geo_err_est_dirichlet)\n",
    "        geo_errs_median.append(geo_err_est_median)\n",
    "\n",
    "\n",
    "    geo_errs_gt = torch.tensor(geo_errs_gt)\n",
    "    geo_errs_corr_gt = torch.tensor(geo_errs_corr_gt)\n",
    "    geo_errs_pairzo = torch.tensor(geo_errs_pairzo)\n",
    "    geo_errs_dirichlet = torch.tensor(geo_errs_dirichlet)\n",
    "    geo_errs_median = torch.tensor(geo_errs_median)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile the code\n",
    "import cProfile\n",
    "\n",
    "cProfile.run('pairwise_stage()', 'restats')\n",
    "\n",
    "import pstats\n",
    "p = pstats.Stats('restats')\n",
    "p.sort_stats('cumulative').print_stats(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(1000)):\n",
    "\n",
    "    dist_x = torch.rand(6890, 6890, device='cuda')\n",
    "\n",
    "    corr_x = torch.randint(0, 6890, (6890,), device='cuda')\n",
    "    corr_y = torch.randint(0, 6890, (6890,), device='cuda')\n",
    "\n",
    "    p2p = torch.randint(0, 6890, (6890,), device='cuda')\n",
    "\n",
    "    result_np = calculate_geodesic_error(dist_x.cpu().numpy(), corr_x.cpu().numpy(), corr_y.cpu().numpy(), p2p.cpu().numpy(), return_mean=False)\n",
    "    result_torch = calculate_geodesic_error_torch(dist_x, corr_x, corr_y, p2p, return_mean=False)\n",
    "\n",
    "\n",
    "    assert torch.allclose(torch.tensor(result_np), result_torch.cpu()), f\"{result_np} != {result_torch}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

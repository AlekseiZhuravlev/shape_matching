{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "\n",
    "train_dataset_template = data_loading.get_val_dataset(\n",
    "    'FAUST_orig', 'train', 128, preload=False, return_evecs=True, centering='bbox'\n",
    "    )[1]\n",
    "test_dataset_single = data_loading.get_val_dataset(\n",
    "    'FAUST_orig', 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    ")[0]\n",
    "test_dataset_template = data_loading.get_val_dataset(\n",
    "    'FAUST_orig', 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    ")[1]\n",
    "\n",
    "test_dataset_single = [test_dataset_single[i] for i in range(len(test_dataset_single))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networks.diffusion_network as diffusion_network\n",
    "import yaml\n",
    "\n",
    "\n",
    "# exp_name = 'signNet_64_remeshed_mass_6b_1-2ev_10_0.2_0.8'\n",
    "# exp_name = 'signNet_64_FAUST_orig_1k'\n",
    "exp_name = 'signNet_32_FAUST_orig'\n",
    "\n",
    "# exp_name = 'signNet_remeshed_mass_6b_1ev_10_0.2_0.8'\n",
    "\n",
    "exp_dir = f'/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_net/{exp_name}'\n",
    "\n",
    "with open(f'{exp_dir}/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "start_dim = config['start_dim']\n",
    "feature_dim = config['feature_dim']\n",
    "evecs_per_support = config['evecs_per_support']\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = diffusion_network.DiffusionNet(\n",
    "    **config['net_params']\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.sign_canonicalization.test_sign_correction as test_sign_correction\n",
    "\n",
    "err_per_iter = []\n",
    "# # for n_iter in range(0, 4000 + 1, 400):\n",
    "# for n_iter in [0, 100, 200, 300, 400, 500, 600, 700, 800, 900]:\n",
    "for n_iter in [0, 4000]:\n",
    "\n",
    "    net.load_state_dict(torch.load(f'{exp_dir}/{n_iter}.pth'))\n",
    "    \n",
    "    mean_incorrect_signs, _ = test_sign_correction.test_on_dataset(\n",
    "        net, test_dataset_single,\n",
    "        config=config, n_epochs=100)\n",
    "    \n",
    "    print(f'{n_iter}.pth: {mean_incorrect_signs:.2f}')\n",
    "    err_per_iter.append((n_iter, mean_incorrect_signs, _))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n_iter, mean_incorrect_signs, _) in err_per_iter:\n",
    "    print(f'{n_iter}.pth: {mean_incorrect_signs / 32 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the summary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.sign_canonicalization.training as sign_training\n",
    "\n",
    "# net.load_state_dict(torch.load(f'{exp_dir}/2000.pth'))\n",
    "net.load_state_dict(torch.load(f'{exp_dir}/4000.pth'))\n",
    "# net.load_state_dict(torch.load(f'{exp_dir}/50000.pth'))\n",
    "\n",
    "# for curr_idx in range(len(test_dataset_single)):\n",
    "for curr_idx in [11]:\n",
    "\n",
    "    ##############################################\n",
    "    # Select a shape\n",
    "    ##############################################\n",
    "\n",
    "    train_shape = test_dataset_single[curr_idx]           \n",
    "    \n",
    "    ##############################################\n",
    "    # Set the variables\n",
    "    ##############################################\n",
    "\n",
    "    # train_shape = double_shape['second']\n",
    "    verts = train_shape['verts'].unsqueeze(0).to(device)\n",
    "    faces = train_shape['faces'].unsqueeze(0).to(device)    \n",
    "\n",
    "    evecs_orig = train_shape['evecs'].unsqueeze(0)[:, :, config['start_dim']:config['start_dim']+config['feature_dim']].to(device)\n",
    "    \n",
    "    if 'with_mass' in config and config['with_mass']:\n",
    "        mass_mat = torch.diag_embed(\n",
    "            train_shape['mass'].unsqueeze(0)\n",
    "            ).to(device)\n",
    "    else:\n",
    "        mass_mat = None\n",
    "\n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_0, supp_vec_0, prod_0 = sign_training.predict_sign_change(\n",
    "            net, verts, faces, evecs_orig, \n",
    "            mass_mat=mass_mat, input_type=net.input_type,\n",
    "            evecs_per_support=config['evecs_per_support'],\n",
    "            mass=train_shape['mass'].unsqueeze(0), L=train_shape['L'].unsqueeze(0),\n",
    "            evals=train_shape['evals'].unsqueeze(0), evecs=train_shape['evecs'].unsqueeze(0),\n",
    "            gradX=train_shape['gradX'].unsqueeze(0), gradY=train_shape['gradY'].unsqueeze(0)\n",
    "            )\n",
    "        \n",
    "    if 'with_mass' in config and config[\"with_mass\"]:\n",
    "\n",
    "        print('Using mass')\n",
    "\n",
    "        supp_vec_norm = torch.nn.functional.normalize(\n",
    "            supp_vec_0[0].transpose(0, 1) \\\n",
    "                @ mass_mat[0],\n",
    "            p=2, dim=1)\n",
    "        \n",
    "        evecs_cond = supp_vec_norm @ evecs_orig[0]\n",
    "        supp_vec_norm = supp_vec_norm.transpose(0, 1).unsqueeze(0)\n",
    "\n",
    "    else:\n",
    "        print('Not using mass')\n",
    "        \n",
    "        supp_vec_norm = torch.nn.functional.normalize(\n",
    "            supp_vec_0[0].transpose(0, 1),\n",
    "            p=2, dim=1)\n",
    "        evecs_cond = supp_vec_norm @ evecs_orig[0]\n",
    "        supp_vec_norm = supp_vec_norm.transpose(0, 1).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "# material=trimesh.visual.material.SimpleMaterial(\n",
    "#         image=None,\n",
    "#         diffuse=[240] * 4,\n",
    "#         # glossiness=0.5,\n",
    "#     )\n",
    "# mesh1.visual.material = material\n",
    "\n",
    "\n",
    "evec_id = 15\n",
    "\n",
    "# supp_vec = supp_vec_0[0, :, evec_id].cpu()\n",
    "supp_vec = supp_vec_norm[0, :, evec_id].cpu()\n",
    "\n",
    "# supp_vec is a vector in [-1, 1]\n",
    "# make that the minimum negative value and maximum positive value have the same absolute value\n",
    "# but the zero value is still zero\n",
    "max_abs = torch.max(torch.abs(supp_vec))\n",
    "\n",
    "idx_min = torch.argmin(supp_vec)\n",
    "idx_max = torch.argmax(supp_vec)\n",
    "\n",
    "supp_vec[idx_min] = -max_abs\n",
    "supp_vec[idx_max] = max_abs\n",
    "\n",
    "\n",
    "mesh1 = trimesh.Trimesh(verts[0].cpu().numpy(), faces[0].cpu().numpy())\n",
    "cmap1 = trimesh.visual.color.interpolate(supp_vec, 'bwr')\n",
    "\n",
    "# smooth the colors\n",
    "# cmap1 = (cmap1.astype(np.int32) + np.roll(cmap1.astype(np.int32), 1) + np.roll(cmap1.astype(np.int32), -1)) / 3\n",
    "# cmap1 = cmap1.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "cmap1_faces = trimesh.visual.color.vertex_to_face_color(cmap1, mesh1.faces)\n",
    "mesh1.visual.face_colors = cmap1_faces.clip(0, 255).astype(np.uint8)\n",
    "# mesh1.visual.vertex_colors = cmap1[:len(mesh1.vertices)].clip(0, 255).astype(np.uint8)\n",
    "\n",
    "mesh2 = trimesh.Trimesh(verts[0].cpu().numpy() + np.array([1, 0, 0]), faces[0].cpu().numpy())\n",
    "cmap2 = trimesh.visual.color.interpolate(evecs_orig[0, :, evec_id].cpu().numpy(), 'bwr')\n",
    "# mesh2.visual.vertex_colors = cmap2[:len(mesh2.vertices)].clip(0, 255).astype(np.uint8)\n",
    "\n",
    "cmap2_faces = trimesh.visual.color.vertex_to_face_color(cmap2, mesh2.faces)\n",
    "mesh2.visual.face_colors = cmap2_faces.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "scene.add_geometry(mesh1)\n",
    "scene.add_geometry(mesh2)\n",
    "\n",
    "scene.set_camera(angles=(-0.5, 0, 0), distance=(1.7), center=(0.5, 0, 0), resolution=None, fov=None)\n",
    "\n",
    "light = trimesh.scene.lighting.DirectionalLight(color=[255, 255, 255, 255])\n",
    "scene.lights = [light]\n",
    "\n",
    "print(f'evec n {evec_id + 1}')\n",
    "print(f'projection {prod_0[0][evec_id, evec_id].item():.2f}')\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "l = 0\n",
    "h = 64\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs, prod_0[0].cpu(), 'Projection', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].plot(supp_vec_norm[0, :, 16].cpu().numpy())\n",
    "ax[1].plot(supp_vec)\n",
    "\n",
    "# plt.plot(supp_vec_0[0, :, 16].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "net.load_state_dict(torch.load(f'{exp_dir}/4000.pth'))\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "C_xy_pred_list = torch.tensor([])\n",
    "C_xy_orig_list = torch.tensor([])\n",
    "prod_with_support_list = torch.tensor([])\n",
    "supp_vec_list = torch.tensor([])\n",
    "\n",
    "data_0 = train_dataset_template[0]\n",
    "verts_first = data_0['first']['verts'].unsqueeze(0).to(device)\n",
    "faces_first = data_0['first']['faces'].unsqueeze(0).to(device)\n",
    "evecs_first = data_0['first']['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "corr_first = data_0['first']['corr']\n",
    "mass_mat_first = torch.diag_embed(data_0['first']['mass'].unsqueeze(0)).to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    sign_pred_first = sign_training.predict_sign_change(\n",
    "        net, verts_first, faces_first, evecs_first, \n",
    "        mass_mat=mass_mat_first, input_type=net.input_type,\n",
    "        evecs_per_support=config['evecs_per_support'],\n",
    "        mass=data_0['first']['mass'].unsqueeze(0), L=data_0['first']['L'].unsqueeze(0),\n",
    "        evals=data_0['first']['evals'].unsqueeze(0), evecs=data_0['first']['evecs'].unsqueeze(0),\n",
    "        gradX=data_0['first']['gradX'].unsqueeze(0), gradY=data_0['first']['gradY'].unsqueeze(0)\n",
    "        )[0]\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(train_dataset_template))):\n",
    "    # data_0 = test_dataset[12]\n",
    "    data_0 = train_dataset_template[i]\n",
    "\n",
    "    verts_second = data_0['second']['verts'].unsqueeze(0).to(device)\n",
    "    faces_second = data_0['second']['faces'].unsqueeze(0).to(device)\n",
    "    evecs_second = data_0['second']['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "    corr_second = data_0['second']['corr']\n",
    "    \n",
    "    mass_mat_second = torch.diag_embed(data_0['second']['mass'].unsqueeze(0)).to(device)\n",
    "\n",
    "    C_gt_xy = data_0['second']['C_gt_xy'][0]\n",
    "\n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_second, supp_vec_second, prod_with_support = sign_training.predict_sign_change(\n",
    "            net, verts_second, faces_second, evecs_second, \n",
    "            mass_mat=mass_mat_second, input_type=net.input_type,\n",
    "            evecs_per_support=config['evecs_per_support'],\n",
    "            mass=data_0['second']['mass'].unsqueeze(0), L=data_0['second']['L'].unsqueeze(0),\n",
    "            evals=data_0['second']['evals'].unsqueeze(0), evecs=data_0['second']['evecs'].unsqueeze(0),\n",
    "            gradX=data_0['second']['gradX'].unsqueeze(0), gradY=data_0['second']['gradY'].unsqueeze(0)\n",
    "            )\n",
    "\n",
    "    # functional maps\n",
    "    C_xy_pred = torch.linalg.lstsq(\n",
    "        evecs_second.cpu()[0, corr_second] * torch.sign(sign_pred_second).cpu(),\n",
    "        evecs_first.cpu()[0, corr_first] * torch.sign(sign_pred_first).cpu()\n",
    "        ).solution\n",
    "    \n",
    "    C_xy_pred_list = torch.cat([C_xy_pred_list, C_xy_pred.unsqueeze(0)])\n",
    "    C_xy_orig_list = torch.cat([C_xy_orig_list, C_gt_xy.unsqueeze(0)])\n",
    "    \n",
    "    # conditioning\n",
    "    \n",
    "    evecs_second_corrected = evecs_second.cpu()[0] * torch.sign(sign_pred_second).cpu()\n",
    "    evecs_second_corrected_norm = evecs_second_corrected / torch.norm(evecs_second_corrected, dim=0, keepdim=True)\n",
    "    \n",
    "    evecs_cond_second = torch.nn.functional.normalize(\n",
    "        supp_vec_second[0].cpu().transpose(0, 1) \\\n",
    "            @ mass_mat_second[0].cpu(),\n",
    "        p=2, dim=1) \\\n",
    "            @ evecs_second_corrected_norm \n",
    "    \n",
    "    prod_with_support_list = torch.cat([prod_with_support_list, evecs_cond_second.cpu().unsqueeze(0)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # prod_with_support_list = torch.cat([prod_with_support_list, prod_with_support.cpu()])\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(test_dataset_template))):\n",
    "    # data_0 = test_dataset[12]\n",
    "    data_0 = test_dataset_template[i]\n",
    "\n",
    "    verts_second = data_0['second']['verts'].unsqueeze(0).to(device)\n",
    "    faces_second = data_0['second']['faces'].unsqueeze(0).to(device)\n",
    "    evecs_second = data_0['second']['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "    corr_second = data_0['second']['corr']\n",
    "    \n",
    "    mass_mat_second = torch.diag_embed(data_0['second']['mass'].unsqueeze(0)).to(device)\n",
    "\n",
    "    C_gt_xy = data_0['second']['C_gt_xy'][0]\n",
    "\n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_second, supp_vec_second, prod_with_support = sign_training.predict_sign_change(\n",
    "            net, verts_second, faces_second, evecs_second, \n",
    "            mass_mat=mass_mat_second, input_type=net.input_type,\n",
    "            evecs_per_support=config['evecs_per_support'],\n",
    "            mass=data_0['second']['mass'].unsqueeze(0), L=data_0['second']['L'].unsqueeze(0),\n",
    "            evals=data_0['second']['evals'].unsqueeze(0), evecs=data_0['second']['evecs'].unsqueeze(0),\n",
    "            gradX=data_0['second']['gradX'].unsqueeze(0), gradY=data_0['second']['gradY'].unsqueeze(0)\n",
    "            )\n",
    "\n",
    "    C_xy_pred = torch.linalg.lstsq(\n",
    "        evecs_second.cpu()[0, corr_second] * torch.sign(sign_pred_second).cpu(),\n",
    "        evecs_first.cpu()[0, corr_first] * torch.sign(sign_pred_first).cpu()\n",
    "        ).solution\n",
    "    \n",
    "    C_xy_pred_list = torch.cat([C_xy_pred_list, C_xy_pred.unsqueeze(0)])\n",
    "    C_xy_orig_list = torch.cat([C_xy_orig_list, C_gt_xy.unsqueeze(0)])\n",
    "    # prod_with_support_list = torch.cat([prod_with_support_list, prod_with_support.cpu()])\n",
    "\n",
    "\n",
    "    # conditioning\n",
    "    \n",
    "    evecs_second_corrected = evecs_second.cpu()[0] * torch.sign(sign_pred_second).cpu()\n",
    "    evecs_second_corrected_norm = evecs_second_corrected / torch.norm(evecs_second_corrected, dim=0, keepdim=True)\n",
    "    \n",
    "    evecs_cond_second = torch.nn.functional.normalize(\n",
    "        supp_vec_second[0].cpu().transpose(0, 1) \\\n",
    "            @ mass_mat_second[0].cpu(),\n",
    "        p=2, dim=1) \\\n",
    "            @ evecs_second_corrected_norm \n",
    "    \n",
    "    prod_with_support_list = torch.cat([prod_with_support_list, evecs_cond_second.cpu().unsqueeze(0)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_with_support_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "l = 0\n",
    "h = 32\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0], C_xy_orig_list[81], 'C_xy_orig', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1], C_xy_pred_list[81], 'C_xy_pred', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[2], prod_with_support_list[81], 'prod_with_support', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "\n",
    "# plotting_utils.plot_Cxy(fig, axs[1, 0], C_xy_orig_list[82], 'C_xy_pred', l, h, show_grid=False, show_colorbar=False)\n",
    "# plotting_utils.plot_Cxy(fig, axs[1, 1], C_xy_pred_list[82], 'C_xy_pred', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(plotting_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "import os\n",
    "\n",
    "l = 0\n",
    "h = 32\n",
    "\n",
    "fig, axs = plt.subplots(1, figsize=(5, 5))\n",
    "\n",
    "# make one figure and axes\n",
    "# fig, axs = plt.subplots(1, 5, figsize=(15, 4))\n",
    "\n",
    "# plotting_utils.plot_Cxy(fig, axs[0], C_xy_orig_list[81], 'C_xy_orig', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs, C_xy_pred_list[73], title=None, min_dim=l, max_dim=h, show_grid=False, show_colorbar=False)\n",
    "# plotting_utils.plot_Cxy(fig, axs[2], prod_with_support_list[81], 'prod_with_support', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "\n",
    "# plotting_utils.plot_Cxy(fig, axs[1, 0], C_xy_orig_list[82], 'C_xy_pred', l, h, show_grid=False, show_colorbar=False)\n",
    "# plotting_utils.plot_Cxy(fig, axs[1, 1], C_xy_pred_list[82], 'C_xy_pred', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "# get 5 random indices without replacement\n",
    "# rand_idx = np.random.choice(len(C_xy_orig_list), 5, replace=False)\n",
    "\n",
    "# print(rand_idx)\n",
    "\n",
    "# for i in range(5):\n",
    "#     plotting_utils.plot_Cxy(fig, axs[i], C_xy_pred_list[rand_idx[i]], title=None, min_dim=l, max_dim=h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "# remove axis ticks\n",
    "axs.set_xticks([])\n",
    "axs.set_yticks([])\n",
    "\n",
    "base_dir = f'/home/s94zalek_hpc/shape_matching/notebooks/rebuttal/noisy_fmaps'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "# get number of files in the directory\n",
    "# files = os.listdir(base_dir)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(f'{base_dir}/Cxy_73.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, figsize=(5, 5))\n",
    "\n",
    "random_noise = torch.randn_like(C_xy_pred_list[73]) * 0.15\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs, random_noise, title=None, min_dim=l, max_dim=h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "# remove axis ticks\n",
    "axs.set_xticks([])\n",
    "axs.set_yticks([])\n",
    "\n",
    "base_dir = f'/home/s94zalek_hpc/shape_matching/my_code/figures'\n",
    "# get number of files in the directory\n",
    "files = os.listdir(base_dir)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(f'{base_dir}/rand_{len(files)}.png', bbox_inches='tight')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, figsize=(5,5))\n",
    "\n",
    "random_noise = torch.randn_like(C_xy_pred_list[73]) * 0.1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    noisy_fmap = C_xy_pred_list[73] * (i + 3) / 10 + random_noise * (13 - i) / 10\n",
    "\n",
    "    # normalize between -1 and 1\n",
    "    # noisy_fmap = noisy_fmap / torch.max(torch.abs(noisy_fmap))\n",
    "\n",
    "    plotting_utils.plot_Cxy(fig, axs, noisy_fmap, title=None, min_dim=l, max_dim=h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "    # remove axis ticks\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    plt.savefig(f'{base_dir}/Cxy_rand_{i}.png', bbox_inches='tight')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "# plt.rcParams['text.usetex'] = True\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "# set the font to be Times New Roman\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "C_xy_pred_list_scaled = scaler.fit_transform(C_xy_pred_list.reshape(C_xy_pred_list.shape[0], -1))\n",
    "C_xy_pred_list_pca = pca.fit_transform(C_xy_pred_list_scaled)\n",
    "pca_df_pred = pd.DataFrame(C_xy_pred_list_pca[:, :2], columns=[f'PC {i}' for i in range(2)])\n",
    "pca_df_pred['class'] = [i // 10 for i in range(C_xy_pred_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "C_xy_orig_list_scaled = scaler.fit_transform(C_xy_orig_list.reshape(C_xy_orig_list.shape[0], -1))\n",
    "C_xy_orig_list_pca = pca.fit_transform(C_xy_orig_list_scaled)\n",
    "pca_df_orig = pd.DataFrame(C_xy_orig_list_pca[:, :2], columns=[f'PC {i}' for i in range(2)])\n",
    "pca_df_orig['class'] = [i // 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "\n",
    "prod_with_support_list_scaled = scaler.fit_transform(prod_with_support_list.reshape(prod_with_support_list.shape[0], -1))\n",
    "prod_with_support_list_pca = pca.fit_transform(prod_with_support_list_scaled)\n",
    "pca_df_prod = pd.DataFrame(prod_with_support_list_pca[:, :2], columns=[f'PC {i}' for i in range(2)])\n",
    "pca_df_prod['class'] = [i // 10 for i in range(prod_with_support_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "\n",
    "sns_plot_orig = sns.scatterplot(data=pca_df_orig, x='PC 0', y='PC 1', hue='class', palette='tab10',\n",
    "                s=80, ax=axs[0],\n",
    "                legend=False\n",
    ")\n",
    "sns_plot_pred = sns.scatterplot(data=pca_df_pred, x='PC 0', y='PC 1', hue='class', palette='tab10',\n",
    "                s=80, ax=axs[1],\n",
    "                # legend=False\n",
    ")\n",
    "sns_plot_prod = sns.scatterplot(data=pca_df_prod, x='PC 0', y='PC 1', hue='class', palette='tab10',\n",
    "                s=80, ax=axs[2],\n",
    "                legend=False\n",
    "                # legend should be horizontal\n",
    "                # legend='brief'\n",
    ")\n",
    "\n",
    "# put title under the plot instead of above\n",
    "axs[0].set_title('$C_{1T}$ before Sign Correction', y=-0.1, fontsize=16)\n",
    "axs[1].set_title('$C_{1T}$ after Sign Correction', y=-0.1, fontsize=16)\n",
    "axs[2].set_title('Conditioning $y$', y=-0.1, fontsize=16)\n",
    "\n",
    "\n",
    "plt.setp(axs[1].get_legend().get_texts(), fontsize='16')\n",
    "plt.setp(axs[1].get_legend().get_title(), fontsize='16')\n",
    "\n",
    "# axs[0].title.set_position([.5, 1.05])\n",
    "\n",
    "axs[0].set_xlim(-20, 20)\n",
    "axs[0].set_ylim(-20, 20)\n",
    "\n",
    "# axs[1].set_xlim(-20, 25)\n",
    "# axs[1].set_ylim(-20, 25)\n",
    "\n",
    "# axs[2].set_xlim(-20, 30)\n",
    "# axs[2].set_ylim(-25, 25)\n",
    "\n",
    "# remove axis labels\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "# set all x and y ticks to be multiples of 10\n",
    "for ax in axs:\n",
    "    min_x, max_x = ax.get_xlim()\n",
    "    min_y, max_y = ax.get_ylim()\n",
    "    \n",
    "    # ax.set_xticks(np.arange(np.ceil(min_x / 10) * 10, np.floor(max_x / 10) * 10 + 1, 10))\n",
    "    # ax.set_yticks(np.arange(np.ceil(min_y / 10) * 10, np.floor(max_y / 10) * 10 + 1, 10))\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "\n",
    "sns.move_legend(sns_plot_pred, 'upper right', bbox_to_anchor=(2.6, 1), ncol=1, fontsize=14)\n",
    "# sns.move_legend(sns_plot_prod, 'lower center', bbox_to_anchor=(0, -0.2), ncol=len(pca_df_pred['class'].unique()))\n",
    "\n",
    "\n",
    "# make legend horizontal\n",
    "# handles, labels = axs[1].get_legend_handles_labels()\n",
    "# axs[1].legend(handles=handles[1:], labels=labels[1:], loc='upper right', bbox_to_anchor=(1.5, 1), ncol=1)\n",
    "\n",
    "\n",
    "\n",
    "print('PCA on predicted')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "C_xy_orig_list_scaled = scaler.fit_transform(C_xy_orig_list.reshape(C_xy_orig_list.shape[0], -1))\n",
    "C_xy_orig_list_pca = pca.fit_transform(C_xy_orig_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(C_xy_orig_list_pca[:, :2], columns=[f'PCA_{i}' for i in range(2)])\n",
    "\n",
    "# remove the outliers based on standard deviation\n",
    "# pca_df = pca_df[(np.abs(pca_df) < 50).all(axis=1)]\n",
    "\n",
    "\n",
    "# pca_df['name'] = names_y\n",
    "pca_df['body_type'] = [i // 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "\n",
    "pca_df = pca_df[(np.abs(pca_df) < np.std(pca_df) * 6\n",
    "                 ).all(axis=1)]\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde', hue='body_type', palette='tab10')\n",
    "\n",
    "print('PCA on original')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "prod_with_support_list_scaled = scaler.fit_transform(prod_with_support_list.reshape(prod_with_support_list.shape[0], -1))\n",
    "prod_with_support_list_pca = pca.fit_transform(prod_with_support_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(prod_with_support_list_pca[:, :3], columns=[f'PCA_{i}' for i in range(3)])\n",
    "# pca_df['name'] = names_y\n",
    "pca_df['body_type'] = [i // 10 for i in range(prod_with_support_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde', hue='body_type', palette='tab10')\n",
    "\n",
    "print('PCA on product with support')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_vec_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "# supp_vec_list_scaled = scaler.fit_transform(supp_vec_list.reshape(supp_vec_list.shape[0], -1))\n",
    "# supp_vec_list_pca = pca.fit_transform(supp_vec_list_scaled)\n",
    "\n",
    "supp_vec_list_scaled = scaler.fit_transform(\n",
    "    (supp_vec_list.transpose(1, 2) @ supp_vec_list).reshape(supp_vec_list.shape[0], -1)\n",
    "    )\n",
    "supp_vec_list_pca = pca.fit_transform(supp_vec_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(supp_vec_list_pca[:, :3], columns=[f'PCA_{i}' for i in range(3)])\n",
    "# pca_df['name'] = names_y\n",
    "pca_df['body_type'] = [i // 10 for i in range(supp_vec_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde', hue='body_type', palette='tab10')\n",
    "\n",
    "print('PCA on product with support')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supp_vec_list_product = supp_vec_list.transpose(1, 2) @ supp_vec_list\n",
    "supp_vec_list_product = supp_vec_list_scaled.reshape(supp_vec_list.shape[0], feature_dim, feature_dim)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axs_0 = axs[0].imshow(supp_vec_list_product[5], cmap='bwr')\n",
    "plt.colorbar(axs_0, ax=axs[0])\n",
    "\n",
    "axs_1 = axs[1].imshow(supp_vec_list_product[6], cmap='bwr')\n",
    "plt.colorbar(axs_1, ax=axs[1])\n",
    "\n",
    "axs_2 = axs[2].imshow(supp_vec_list_product[7], cmap='bwr')\n",
    "plt.colorbar(axs_2, ax=axs[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "# supp_vec_list_scaled = scaler.fit_transform(supp_vec_list.reshape(supp_vec_list.shape[0], -1))\n",
    "# supp_vec_list_pca = pca.fit_transform(supp_vec_list_scaled)\n",
    "\n",
    "supp_vec_list_scaled = scaler.fit_transform(\n",
    "    (supp_vec_list.transpose(1, 2) @ supp_vec_list).reshape(supp_vec_list.shape[0], -1)\n",
    "    )\n",
    "supp_vec_list_pca = pca.fit_transform(supp_vec_list_scaled)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# plot explained variance\n",
    "axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "axs.set_title('Explained variance ratio')\n",
    "\n",
    "\n",
    "pca_df = pd.DataFrame(supp_vec_list_pca[:, :3], columns=[f'PCA_{i}' for i in range(3)])\n",
    "# pca_df['name'] = names_y\n",
    "pca_df['body_type'] = [i // 10 for i in range(supp_vec_list_pca.shape[0])]\n",
    "# pca_df['pose'] = [i % 10 for i in range(C_xy_orig_list_pca.shape[0])]\n",
    "\n",
    "\n",
    "# use numbers as markers\n",
    "sns.pairplot(pca_df, diag_kind='kde', hue='body_type', palette='tab10')\n",
    "\n",
    "print('PCA on product with support')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

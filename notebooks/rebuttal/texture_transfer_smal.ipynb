{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvirtualdisplay\n",
    "import trimesh\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import yaml\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import trimesh.scene\n",
    "import trimesh.scene.lighting\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "\n",
    "dataset_name = 'SMAL_nocat_pair'\n",
    "\n",
    "single_dataset, pair_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    ")\n",
    "\n",
    "\n",
    "if dataset_name == 'SHREC19_r_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_1-2ev_64-128-128_remeshed_fixed/eval/epoch_99/SHREC19_r_pair-test/no_smoothing/2024-11-04_22-27-59/pairwise_results.json'\n",
    "elif dataset_name == 'DT4D_intra_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_template_remeshed/eval/checkpoint_99.pt/DT4D_intra_pair-test/no_smoothing/2024-11-10_21-20-05/pairwise_results.json'\n",
    "elif dataset_name == 'DT4D_inter_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_template_remeshed/eval/checkpoint_99.pt/DT4D_inter_pair-test/no_smoothing/2024-11-10_21-20-05/pairwise_results.json'\n",
    "elif dataset_name == 'FAUST_r_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_1-2ev_64-128-128_remeshed_fixed/eval/epoch_99/FAUST_r_pair-test/no_smoothing/2024-11-04_22-27-59/pairwise_results.json'\n",
    "elif dataset_name == 'SCAPE_r_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_1-2ev_64-128-128_remeshed_fixed/eval/epoch_99/SCAPE_r_pair-test/no_smoothing/2024-11-04_22-27-59/pairwise_results.json'\n",
    "elif dataset_name == 'SMAL_nocat_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_SMAL_nocat_64_SMAL_isoRemesh_0.2_0.8_nocat_1-2ev_64k/eval/epoch_99/SMAL_nocat_pair-test/no_smoothing/2025-01-24_16-01-31/pairwise_results.json'\n",
    "        \n",
    "with open(file_name, 'r') as f:\n",
    "    p2p_saved = json.load(f)\n",
    "\n",
    "\n",
    "geo_err_list = torch.tensor([p2p_saved[i]['geo_err_median_pairzo'] for i in range(len(p2p_saved))])\n",
    "idxs_geo_err = torch.argsort(geo_err_list, descending=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 38\n",
    "\n",
    "data_i = pair_dataset[indx]\n",
    "p2p_i = p2p_saved[indx]\n",
    "p2p_pairzo = torch.tensor(p2p_i['p2p_median_pairzo'])\n",
    "\n",
    "print(p2p_i['geo_err_median_pairzo'])\n",
    "\n",
    "Cxy = torch.linalg.lstsq(\n",
    "    data_i['second']['evecs'],\n",
    "    data_i['first']['evecs'][p2p_pairzo],\n",
    ").solution\n",
    "\n",
    "Pyx = data_i['second']['evecs'] @ Cxy @ data_i['first']['evecs_trans']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read /home/s94zalek_hpc/shape_matching/figures/texture.png with PIL\n",
    "from PIL import Image\n",
    "import utils.texture_util as texture_util\n",
    "\n",
    "\n",
    "#########################################\n",
    "# X -> Y\n",
    "#########################################\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "# verts_x = data_i['first']['verts'].clone()\n",
    "# verts_y = data_i['second']['verts'].clone()\n",
    "\n",
    "# verts_x_cloned = verts_x.clone()\n",
    "\n",
    "# verts_x[:, 0] = verts_x_cloned[:, 2]\n",
    "# verts_x[:, 1] = -verts_x_cloned[:, 1]\n",
    "# verts_x[:, 2] = verts_x_cloned[:, 0]\n",
    "\n",
    "# verts_y_cloned = verts_y.clone()\n",
    "\n",
    "# verts_y[:, 0] = verts_y_cloned[:, 2]\n",
    "# verts_y[:, 1] = -verts_y_cloned[:, 1]\n",
    "# verts_y[:, 2] = verts_y_cloned[:, 0]\n",
    "\n",
    "\n",
    "# texture_img = Image.open('/home/s94zalek_hpc/shape_matching/figures/texture.png')\n",
    "# texture_img = Image.open('/home/s94zalek_hpc/shape_matching/figures/Custom_texture.png')\n",
    "texture_img = Image.open('/home/s94zalek_hpc/shape_matching/figures/CustomUVChecker_byValle_2K (7).png')\n",
    "\n",
    "# create material\n",
    "material=trimesh.visual.material.SimpleMaterial(\n",
    "        image=texture_img,\n",
    "        diffuse=[255, 255, 255, 255],\n",
    "    )\n",
    "\n",
    "# add the first mesh\n",
    "# mesh1 = trimesh.Trimesh(\n",
    "#     vertices=data_i['first']['verts'].numpy(), \n",
    "#     faces=data_i['first']['faces'].numpy(),\n",
    "#     process=False, validate=False,\n",
    "#     )\n",
    "\n",
    "mesh1 = trimesh.Trimesh(\n",
    "    vertices=data_i['first']['verts'].numpy(), \n",
    "    faces=data_i['first']['faces'].numpy(),\n",
    "    process=False, validate=False,\n",
    "    )\n",
    "\n",
    "# print(mesh1.vertices)\n",
    "\n",
    "rot_mat = trimesh.transformations.rotation_matrix(np.pi, [1, 0, 0], [0, 0, 0])\n",
    "mesh1.apply_transform(rot_mat)\n",
    "mesh1.apply_transform(trimesh.transformations.rotation_matrix(-np.pi/3, [0, 1, 0], [0, 0, 0]))\n",
    "\n",
    "# print(mesh1.vertices)\n",
    "\n",
    "uv1 = texture_util.generate_tex_coords(mesh1.vertices, col1=0, col2=1) * 1.5\n",
    "uv2 = Pyx @ uv1\n",
    "\n",
    "\n",
    "texture_visuals = trimesh.visual.texture.TextureVisuals(\n",
    "    uv=uv1[:len(mesh1.vertices)],\n",
    "    material=material\n",
    ")\n",
    "\n",
    "mesh1.visual = texture_visuals\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# correspondence we got from the functional map\n",
    "mesh2_after = trimesh.Trimesh(\n",
    "    vertices=data_i['second']['verts'].numpy() + np.array([1, 0, 0]), \n",
    "    faces=data_i['second']['faces'].numpy(),\n",
    "    process=False, validate=False,\n",
    "    )\n",
    "mesh2_after.apply_transform(rot_mat)\n",
    "mesh2_after.apply_transform(trimesh.transformations.rotation_matrix(-6*np.pi/6, [0, 1, 0], [1, 0, 0]))\n",
    "\n",
    "texture_visuals_after = trimesh.visual.texture.TextureVisuals(\n",
    "    uv=uv2[:len(mesh2_after.vertices)],\n",
    "    material=material\n",
    ")\n",
    "mesh2_after.visual = texture_visuals_after\n",
    "\n",
    "\n",
    "# scene.add_geometry(mesh1)\n",
    "scene.add_geometry(mesh2_after)\n",
    "\n",
    "scene.set_camera()\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/figures/p2p_texture'\n",
    "target_path = f'{base_path}/{dataset_name}/combined'\n",
    "\n",
    "os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "with pyvirtualdisplay.Display(visible=False, size=(1920, 1080)) as disp:\n",
    "    png = scene.save_image(resolution=(1920, 1080), visible=True)\n",
    "\n",
    "# png = scene.save_image(resolution=(int(1920*1080), 1080), visible=True)\n",
    "\n",
    "with open(f'{target_path}/002.png', \"wb\") as f:\n",
    "    f.write(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, combination in enumerate(pair_dataset.combinations):\n",
    "#     print(f'{i}: {single_dataset.off_files[combination[0]].split(\"/\")[-1].split(\".\")[0]} - {single_dataset.off_files[combination[1]].split(\"/\")[-1].split(\".\")[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

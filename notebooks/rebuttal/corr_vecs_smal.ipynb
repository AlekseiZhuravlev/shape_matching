{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvirtualdisplay\n",
    "import trimesh\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import yaml\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import trimesh.scene\n",
    "import trimesh.scene.lighting\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import networks.diffusion_network as diffusion_network\n",
    "import yaml\n",
    "import my_code.sign_canonicalization.training as sign_training\n",
    "\n",
    "\n",
    "import PIL.Image\n",
    "          \n",
    "          \n",
    "scene = trimesh.Scene()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'SMAL_cat_pair'\n",
    "\n",
    "single_dataset, pair_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'signNet_32_SMAL_isoRemesh_0.2_0.8'\n",
    "\n",
    "exp_dir = f'/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_net/{exp_name}'\n",
    "\n",
    "with open(f'{exp_dir}/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "start_dim = config['start_dim']\n",
    "feature_dim = config['feature_dim']\n",
    "evecs_per_support = config['evecs_per_support']\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = diffusion_network.DiffusionNet(\n",
    "    **config['net_params']\n",
    "    ).to(device)\n",
    "\n",
    "net.load_state_dict(torch.load(f'{exp_dir}/39440.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = single_dataset[10]\n",
    "        \n",
    "\n",
    "##############################################\n",
    "# Set the variables\n",
    "##############################################\n",
    "\n",
    "# data = double_shape['second']\n",
    "verts = data['verts'].unsqueeze(0).to(device)\n",
    "\n",
    "verts_cloned = verts.clone()\n",
    "\n",
    "verts[:, :, 0] = verts_cloned[:,:, 2]\n",
    "verts[:,:, 1] = -verts_cloned[:,:, 1]\n",
    "verts[:,:, 2] = verts_cloned[:,:, 0]\n",
    "\n",
    "faces = data['faces'].unsqueeze(0).to(device)    \n",
    "\n",
    "evecs_orig = data['evecs'].unsqueeze(0)[:, :, config['start_dim']:config['start_dim']+config['feature_dim']].to(device)\n",
    "\n",
    "if 'with_mass' in config and config['with_mass']:\n",
    "    mass_mat = torch.diag_embed(\n",
    "        data['mass'].unsqueeze(0)\n",
    "        ).to(device)\n",
    "else:\n",
    "    mass_mat = None\n",
    "\n",
    "# predict the sign change\n",
    "with torch.no_grad():\n",
    "    sign_pred_0, supp_vec_0, prod_0 = sign_training.predict_sign_change(\n",
    "        net, verts, faces, evecs_orig, \n",
    "        mass_mat=mass_mat, input_type=net.input_type,\n",
    "        evecs_per_support=config['evecs_per_support'],\n",
    "        mass=data['mass'].unsqueeze(0), L=data['L'].unsqueeze(0),\n",
    "        evals=data['evals'].unsqueeze(0), evecs=data['evecs'].unsqueeze(0),\n",
    "        gradX=data['gradX'].unsqueeze(0), gradY=data['gradY'].unsqueeze(0)\n",
    "        )\n",
    "    \n",
    "if 'with_mass' in config and config[\"with_mass\"]:\n",
    "\n",
    "    print('Using mass')\n",
    "\n",
    "    supp_vec_norm = torch.nn.functional.normalize(\n",
    "        supp_vec_0[0].transpose(0, 1) \\\n",
    "            @ mass_mat[0],\n",
    "        p=2, dim=1)\n",
    "    \n",
    "    evecs_cond = supp_vec_norm @ evecs_orig[0]\n",
    "    supp_vec_norm = supp_vec_norm.transpose(0, 1).unsqueeze(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evec_id = 25\n",
    "\n",
    "# supp_vec = supp_vec_0[0, :, evec_id].cpu()\n",
    "supp_vec = supp_vec_norm[0, :, evec_id].cpu()\n",
    "\n",
    "# supp_vec is a vector in [-1, 1]\n",
    "# make that the minimum negative value and maximum positive value have the same absolute value\n",
    "# but the zero value is still zero\n",
    "max_abs = torch.max(torch.abs(supp_vec))\n",
    "\n",
    "idx_min = torch.argmin(supp_vec)\n",
    "idx_max = torch.argmax(supp_vec)\n",
    "\n",
    "supp_vec[idx_min] = -max_abs\n",
    "supp_vec[idx_max] = max_abs\n",
    "\n",
    "\n",
    "mesh1 = trimesh.Trimesh(verts[0].cpu().numpy(), faces[0].cpu().numpy())\n",
    "cmap1 = trimesh.visual.color.interpolate(supp_vec, 'bwr')\n",
    "\n",
    "# smooth the colors\n",
    "# cmap1 = (cmap1.astype(np.int32) + np.roll(cmap1.astype(np.int32), 1) + np.roll(cmap1.astype(np.int32), -1)) / 3\n",
    "# cmap1 = cmap1.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "cmap1_faces = trimesh.visual.color.vertex_to_face_color(cmap1, mesh1.faces)\n",
    "mesh1.visual.face_colors = cmap1_faces.clip(0, 255).astype(np.uint8)\n",
    "# mesh1.visual.vertex_colors = cmap1[:len(mesh1.vertices)].clip(0, 255).astype(np.uint8)\n",
    "\n",
    "mesh2 = trimesh.Trimesh(verts[0].cpu().numpy() + np.array([1, 0, 0]), faces[0].cpu().numpy())\n",
    "cmap2 = trimesh.visual.color.interpolate(evecs_orig[0, :, evec_id].cpu().numpy(), 'bwr')\n",
    "# mesh2.visual.vertex_colors = cmap2[:len(mesh2.vertices)].clip(0, 255).astype(np.uint8)\n",
    "\n",
    "cmap2_faces = trimesh.visual.color.vertex_to_face_color(cmap2, mesh2.faces)\n",
    "mesh2.visual.face_colors = cmap2_faces.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "scene.add_geometry(mesh1)\n",
    "scene.add_geometry(mesh2)\n",
    "\n",
    "scene.add_geometry(trimesh.creation.axis(axis_length=1))\n",
    "\n",
    "scene.set_camera()\n",
    "scene.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

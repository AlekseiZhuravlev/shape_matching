{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvirtualdisplay\n",
    "import trimesh\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import yaml\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import trimesh.scene\n",
    "import trimesh.scene.lighting\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "\n",
    "dataset_name = 'FAUST_r_pair'\n",
    "\n",
    "single_dataset, pair_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    ")\n",
    "\n",
    "\n",
    "if dataset_name == 'SHREC19_r_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_1-2ev_64-128-128_remeshed_fixed/eval/epoch_99/SHREC19_r_pair-test/no_smoothing/2024-11-04_22-27-59/pairwise_results.json'\n",
    "elif dataset_name == 'DT4D_intra_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_template_remeshed/eval/checkpoint_99.pt/DT4D_intra_pair-test/no_smoothing/2024-11-10_21-20-05/pairwise_results.json'\n",
    "elif dataset_name == 'DT4D_inter_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_template_remeshed/eval/checkpoint_99.pt/DT4D_inter_pair-test/no_smoothing/2024-11-10_21-20-05/pairwise_results.json'\n",
    "elif dataset_name == 'FAUST_r_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_1-2ev_64-128-128_remeshed_fixed/eval/epoch_99/FAUST_r_pair-test/no_smoothing/2024-11-04_22-27-59/pairwise_results.json'\n",
    "elif dataset_name == 'SCAPE_r_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_1-2ev_64-128-128_remeshed_fixed/eval/epoch_99/SCAPE_r_pair-test/no_smoothing/2024-11-04_22-27-59/pairwise_results.json'\n",
    "elif dataset_name == 'SMAL_nocat_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_SMAL_nocat_64_SMAL_isoRemesh_0.2_0.8_nocat_1-2ev_64k/eval/epoch_99/SMAL_nocat_pair-test/no_smoothing/2025-01-24_16-01-31/pairwise_results.json'\n",
    "        \n",
    "with open(file_name, 'r') as f:\n",
    "    p2p_saved = json.load(f)\n",
    "\n",
    "\n",
    "geo_err_list = torch.tensor([p2p_saved[i]['geo_err_median_pairzo'] for i in range(len(p2p_saved))])\n",
    "idxs_geo_err = torch.argsort(geo_err_list, descending=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 1\n",
    "\n",
    "data_i = pair_dataset[indx]\n",
    "p2p_i = p2p_saved[indx]\n",
    "p2p_pairzo = torch.tensor(p2p_i['p2p_median_pairzo'])\n",
    "\n",
    "print(p2p_i['geo_err_median_pairzo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.texture_util as texture_util\n",
    "\n",
    "uv1 = texture_util.generate_tex_coords(data_i['first']['verts'].numpy())\n",
    "\n",
    "# uv2 = uv1[p2p_pairzo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cxy = torch.linalg.lstsq(\n",
    "    data_i['second']['evecs'],\n",
    "    data_i['first']['evecs'][p2p_pairzo],\n",
    ").solution\n",
    "\n",
    "# Cxy = torch.linalg.lstsq(\n",
    "#     data_i['second']['evecs'][data_i['second']['corr']],\n",
    "#     data_i['first']['evecs'][data_i['first']['corr']],\n",
    "# ).solution\n",
    "\n",
    "Pyx = data_i['second']['evecs'] @ Cxy @ data_i['first']['evecs_trans']\n",
    "\n",
    "uv2 = Pyx @ uv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read /home/s94zalek_hpc/shape_matching/figures/texture.png with PIL\n",
    "from PIL import Image\n",
    "\n",
    "#########################################\n",
    "# X -> Y\n",
    "#########################################\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "\n",
    "# texture_img = Image.open('/home/s94zalek_hpc/shape_matching/figures/texture.png')\n",
    "texture_img = Image.open('/home/s94zalek_hpc/shape_matching/figures/Custom_texture_w_border.png')\n",
    "\n",
    "# create material\n",
    "material=trimesh.visual.material.SimpleMaterial(\n",
    "        image=texture_img,\n",
    "        diffuse=[255, 255, 255, 255],\n",
    "    )\n",
    "\n",
    "# add the first mesh\n",
    "mesh1 = trimesh.Trimesh(\n",
    "    vertices=data_i['first']['verts'].numpy(), \n",
    "    faces=data_i['first']['faces'].numpy()\n",
    "    )\n",
    "\n",
    "texture_visuals = trimesh.visual.texture.TextureVisuals(\n",
    "    uv=uv1[:len(mesh1.vertices)],\n",
    "    material=material\n",
    ")\n",
    "\n",
    "mesh1.visual = texture_visuals\n",
    "\n",
    "scene.add_geometry(mesh1)\n",
    "\n",
    "\n",
    "# correspondence we got from the functional map\n",
    "mesh2_after = trimesh.Trimesh(\n",
    "    vertices=data_i['second']['verts'].numpy() + np.array([1, 0, 0]), \n",
    "    faces=data_i['second']['faces'].numpy()\n",
    "    )\n",
    "\n",
    "texture_visuals_after = trimesh.visual.texture.TextureVisuals(\n",
    "    uv=uv2[:len(mesh2_after.vertices)],\n",
    "    material=material\n",
    ")\n",
    "mesh2_after.visual = texture_visuals_after\n",
    "\n",
    "scene.add_geometry(mesh2_after)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 17\n",
    "ice = px.colors.sample_colorscale(\n",
    "    \n",
    "    # DT4D\n",
    "    px.colors.cyclical.Edge,\n",
    "    \n",
    "    # FAUST\n",
    "    # px.colors.sequential.Jet,\n",
    "    \n",
    "    # SHREC19\n",
    "    # px.colors.diverging.Picnic,\n",
    "    \n",
    "    # SCAPE\n",
    "    # px.colors.cyclical.HSV,\n",
    "    \n",
    "    # px.colors.cyclical.IceFire,\n",
    "    \n",
    "    \n",
    "    # px.colors.sequential.Blackbody,\n",
    "    # px.colors.sequential.Viridis,\n",
    "    \n",
    "    SAMPLES)\n",
    "\n",
    "rgb = [px.colors.unconvert_from_RGB_255(px.colors.unlabel_rgb(c)) for c in ice]\n",
    "\n",
    "cmap = mcolors.ListedColormap(rgb, name='Ice', N=SAMPLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb\n",
    "\n",
    "# for every entry, multiply it by 255\n",
    "# then convert to int\n",
    "\n",
    "for i in range(SAMPLES):\n",
    "    print(f'rgb({int(255*rgb[i][0])}, {int(255*rgb[i][1])}, {int(255*rgb[i][2])})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cmap(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

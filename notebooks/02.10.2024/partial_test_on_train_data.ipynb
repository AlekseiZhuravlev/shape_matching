{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# models\n",
    "from my_code.models.diag_conditional import DiagConditionedUnet\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "import my_code.datasets.template_dataset as template_dataset\n",
    "\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "\n",
    "import networks.diffusion_network as diffusion_network\n",
    "import matplotlib.pyplot as plt\n",
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "import utils.fmap_util as fmap_util\n",
    "import metrics.geodist_metric as geodist_metric\n",
    "from my_code.sign_canonicalization.training import predict_sign_change\n",
    "import argparse\n",
    "from pyFM_fork.pyFM.refine.zoomout import zoomout_refine\n",
    "import my_code.utils.zoomout_custom as zoomout_custom\n",
    "from utils.shape_util import compute_geodesic_distmat\n",
    "from my_code.diffusion_training_sign_corr.test.test_diffusion_cond import select_p2p_map_dirichlet, log_to_database, parse_args\n",
    "import accelerate\n",
    "import my_code.sign_canonicalization.test_sign_correction as test_sign_correction\n",
    "import networks.fmap_network as fmap_network\n",
    "from my_code.utils.median_p2p_map import dirichlet_energy\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "class RegularizedFMNet(torch.nn.Module):\n",
    "    \"\"\"Compute the functional map matrix representation in DPFM\"\"\"\n",
    "    def __init__(self, lmbda=0.01, resolvant_gamma=0.5, bidirectional=False):\n",
    "        super(RegularizedFMNet, self).__init__()\n",
    "        self.lmbda = lmbda\n",
    "        self.resolvant_gamma = resolvant_gamma\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "    def compute_functional_map(self, A, B, evals_x, evals_y):\n",
    "        # A = torch.bmm(evecs_trans_x, feat_x)  # [B, K, C]\n",
    "        # B = torch.bmm(evecs_trans_y, feat_y)  # [B, K, C]\n",
    "\n",
    "        D = fmap_network.get_mask(evals_x, evals_y, self.resolvant_gamma)  # [B, K, K]\n",
    "\n",
    "        A_t = A.transpose(1, 2)  # [B, C, K]\n",
    "        A_A_t = torch.bmm(A, A_t)  # [B, K, K]\n",
    "        B_A_t = torch.bmm(B, A_t)  # [B, K, K]\n",
    "\n",
    "        C_i = []\n",
    "        for i in range(evals_x.shape[1]):\n",
    "            D_i = torch.cat([torch.diag(D[bs, i, :].flatten()).unsqueeze(0) for bs in range(evals_x.shape[0])], dim=0)\n",
    "            C = torch.bmm(torch.inverse(A_A_t + self.lmbda * D_i), B_A_t[:, [i], :].transpose(1, 2))\n",
    "            C_i.append(C.transpose(1, 2))\n",
    "\n",
    "        Cxy = torch.cat(C_i, dim=1)\n",
    "         \n",
    "        return Cxy\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_geo_error(\n",
    "    p2p_first, p2p_second,\n",
    "    evecs_first, evecs_second,\n",
    "    corr_first, corr_second,\n",
    "    num_evecs, apply_zoomout,\n",
    "    dist_x,\n",
    "    regularized=False,\n",
    "    evecs_trans_first=None, evecs_trans_second=None,\n",
    "    evals_first=None, evals_second=None,\n",
    "    return_p2p=False, return_Cxy=False,\n",
    "    A2=None, fmnet=None\n",
    "    ):\n",
    "        \n",
    "    if regularized:\n",
    "        Cxy = fmnet.compute_functional_map(\n",
    "            evecs_trans_second[:num_evecs, p2p_second].unsqueeze(0),\n",
    "            evecs_trans_first[:num_evecs, p2p_first].unsqueeze(0),\n",
    "            evals_second[:num_evecs].unsqueeze(0),\n",
    "            evals_first[:num_evecs].unsqueeze(0), \n",
    "        )[0].T\n",
    "        \n",
    "    else:\n",
    "        Cxy = torch.linalg.lstsq(\n",
    "            evecs_second[:, :num_evecs][p2p_second],\n",
    "            evecs_first[:, :num_evecs][p2p_first]\n",
    "            ).solution\n",
    "    \n",
    "    \n",
    "    if apply_zoomout:\n",
    "        Cxy = zoomout_custom.zoomout(\n",
    "            FM_12=Cxy, \n",
    "            evects1=evecs_first,\n",
    "            evects2=evecs_second,\n",
    "            nit=evecs_first.shape[1] - num_evecs, step=1,\n",
    "            A2=A2\n",
    "        )\n",
    "        num_evecs = evecs_first.shape[1]\n",
    "        \n",
    "    p2p = fmap_util.fmap2pointmap(\n",
    "        C12=Cxy,\n",
    "        evecs_x=evecs_first[:, :num_evecs],\n",
    "        evecs_y=evecs_second[:, :num_evecs],\n",
    "        ).cpu()\n",
    "    \n",
    "    geo_err = geodist_metric.calculate_geodesic_error(\n",
    "        dist_x, corr_first.cpu(), corr_second.cpu(), p2p, return_mean=True\n",
    "    )\n",
    "    \n",
    "    # if return_p2p:\n",
    "    #     return geo_err * 100, p2p\n",
    "    # else:\n",
    "    #     return geo_err * 100\n",
    "    \n",
    "    if not return_p2p and not return_Cxy:\n",
    "        return geo_err * 100\n",
    "    \n",
    "    payload = [geo_err * 100]\n",
    "    \n",
    "    if return_p2p:\n",
    "        payload.append(p2p)\n",
    "    if return_Cxy:\n",
    "        payload.append(Cxy)\n",
    "        \n",
    "    return payload\n",
    "\n",
    "\n",
    "def filter_p2p_by_confidence(\n",
    "        p2p_first, p2p_second,\n",
    "        confidence_scores_first, confidence_scores_second,\n",
    "        confidence_threshold, log_file_name\n",
    "    ):\n",
    "    \n",
    "    assert p2p_first.shape[0] == p2p_second.shape[0]\n",
    "    \n",
    "    # select points with both confidence scores above threshold\n",
    "    valid_points = (confidence_scores_first < confidence_threshold) & (confidence_scores_second < confidence_threshold)\n",
    "    \n",
    "    with open(log_file_name, 'a') as f:\n",
    "        \n",
    "        while valid_points.sum() < 0.05 * len(valid_points):\n",
    "            confidence_threshold += 0.05\n",
    "            valid_points = (confidence_scores_first < confidence_threshold) & (confidence_scores_second < confidence_threshold)\n",
    "            \n",
    "            f.write(f'Increasing confidence threshold: {confidence_threshold}\\n')\n",
    "        f.write(f'Valid points: {valid_points.sum()}\\n')\n",
    "        assert valid_points.sum() > 0, \"No valid points found\"\n",
    "        \n",
    "    p2p_first = p2p_first[valid_points]\n",
    "    p2p_second = p2p_second[valid_points]\n",
    "    \n",
    "    return p2p_first, p2p_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fmaps_evec_signs(\n",
    "        data, model,\n",
    "        noise_scheduler, config, args,\n",
    "        template_shape, sign_corr_net\n",
    "    ):\n",
    "        \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    num_evecs = config[\"model_params\"][\"sample_size\"]\n",
    "\n",
    "        \n",
    "    verts_first = template_shape['verts'].unsqueeze(0).to(device)\n",
    "    verts_second = data['verts'].unsqueeze(0).to(device)\n",
    "    \n",
    "    faces_first = template_shape['faces'].unsqueeze(0).to(device)\n",
    "    faces_second = data['faces'].unsqueeze(0).to(device)\n",
    "\n",
    "    evecs_first = template_shape['evecs'][:, :num_evecs].unsqueeze(0).to(device)\n",
    "    evecs_second = data['evecs'][:, :num_evecs].unsqueeze(0).to(device)\n",
    "    \n",
    "\n",
    "    if config[\"sign_net\"][\"with_mass\"]:\n",
    "        mass_mat_first = torch.diag_embed(\n",
    "            template_shape['mass'].unsqueeze(0)\n",
    "            ).to(device)\n",
    "        mass_mat_second = torch.diag_embed(\n",
    "            data['mass'].unsqueeze(0)\n",
    "            ).to(device)\n",
    "    else:\n",
    "        mass_mat_first = None\n",
    "        mass_mat_second = None\n",
    "\n",
    "\n",
    "    ###############################################\n",
    "    # get conditioning and signs num_iters_avg times\n",
    "    ###############################################\n",
    "\n",
    "    evecs_cond_first_list = []\n",
    "    evecs_cond_second_list = []\n",
    "    evecs_first_signs_list = []\n",
    "    evecs_second_signs_list = []\n",
    "\n",
    "    for _ in range(args.num_iters_avg):\n",
    "\n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_first, support_vector_norm_first, _ = predict_sign_change(\n",
    "                sign_corr_net, verts_first, faces_first, evecs_first, \n",
    "                mass_mat=mass_mat_first, input_type=sign_corr_net.input_type,\n",
    "                evecs_per_support=config[\"sign_net\"][\"evecs_per_support\"],\n",
    "                \n",
    "                mass=template_shape['mass'].unsqueeze(0), L=template_shape['L'].unsqueeze(0),\n",
    "                evals=template_shape['evals'][:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "                evecs=template_shape['evecs'][:,:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "                gradX=template_shape['gradX'].unsqueeze(0), gradY=template_shape['gradY'].unsqueeze(0)\n",
    "                )\n",
    "            sign_pred_second, support_vector_norm_second, _ = predict_sign_change(\n",
    "                sign_corr_net, verts_second, faces_second, evecs_second, \n",
    "                mass_mat=mass_mat_second, input_type=sign_corr_net.input_type,\n",
    "                evecs_per_support=config[\"sign_net\"][\"evecs_per_support\"],\n",
    "                \n",
    "                mass=data['mass'].unsqueeze(0), L=data['L'].unsqueeze(0),\n",
    "                evals=data['evals'][:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "                evecs=data['evecs'][:,:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "                gradX=data['gradX'].unsqueeze(0), gradY=data['gradY'].unsqueeze(0)\n",
    "                )\n",
    "\n",
    "        # correct the evecs\n",
    "        evecs_first_corrected = evecs_first.cpu()[0] * torch.sign(sign_pred_first).cpu()\n",
    "        # evecs_first_corrected_norm = evecs_first_corrected / torch.norm(evecs_first_corrected, dim=0, keepdim=True)\n",
    "        evecs_first_corrected_norm = torch.nn.functional.normalize(evecs_first_corrected, p=2, dim=0)\n",
    "        \n",
    "        evecs_second_corrected = evecs_second.cpu()[0] * torch.sign(sign_pred_second).cpu()\n",
    "        # evecs_second_corrected_norm = evecs_second_corrected / torch.norm(evecs_second_corrected, dim=0, keepdim=True)\n",
    "        evecs_second_corrected_norm = torch.nn.functional.normalize(evecs_second_corrected, p=2, dim=0)\n",
    "        \n",
    "\n",
    "        # product with support\n",
    "        if config[\"sign_net\"][\"with_mass\"]:\n",
    "        # if config[\"sign_net\"]['cond_mass_normalize']:\n",
    "            \n",
    "            mass_mat_first = torch.diag_embed(\n",
    "                template_shape['mass'].unsqueeze(0)\n",
    "                ).to(device)\n",
    "            mass_mat_second = torch.diag_embed(\n",
    "                data['mass'].unsqueeze(0)\n",
    "                ).to(device)\n",
    "            \n",
    "            evecs_cond_first = torch.nn.functional.normalize(\n",
    "                support_vector_norm_first[0].cpu().transpose(0, 1) \\\n",
    "                    @ mass_mat_first[0].cpu(),\n",
    "                p=2, dim=1) \\\n",
    "                    @ evecs_first_corrected_norm\n",
    "            \n",
    "            evecs_cond_second = torch.nn.functional.normalize(\n",
    "                support_vector_norm_second[0].cpu().transpose(0, 1) \\\n",
    "                    @ mass_mat_second[0].cpu(),\n",
    "                p=2, dim=1) \\\n",
    "                    @ evecs_second_corrected_norm \n",
    "            \n",
    "        else:\n",
    "            evecs_cond_first = support_vector_norm_first[0].cpu().transpose(0, 1) @ evecs_first_corrected_norm\n",
    "            evecs_cond_second = support_vector_norm_second[0].cpu().transpose(0, 1) @ evecs_second_corrected_norm\n",
    "            \n",
    "        evecs_cond_first_list.append(evecs_cond_first)\n",
    "        evecs_cond_second_list.append(evecs_cond_second)\n",
    "        evecs_first_signs_list.append(torch.sign(sign_pred_first).cpu())\n",
    "        evecs_second_signs_list.append(torch.sign(sign_pred_second).cpu())\n",
    "        \n",
    "    evecs_cond_first_list = torch.stack(evecs_cond_first_list)\n",
    "    evecs_cond_second_list = torch.stack(evecs_cond_second_list)\n",
    "    evecs_first_signs_list = torch.stack(evecs_first_signs_list)\n",
    "    evecs_second_signs_list = torch.stack(evecs_second_signs_list)    \n",
    "    \n",
    "    \n",
    "    ###############################################\n",
    "    # Conditioning\n",
    "    ###############################################\n",
    "\n",
    "    conditioning = torch.cat(\n",
    "        (evecs_cond_first_list.unsqueeze(1), evecs_cond_second_list.unsqueeze(1)),\n",
    "        1)\n",
    "    \n",
    "    ###############################################\n",
    "    # Sample the model\n",
    "    ###############################################\n",
    "    \n",
    "    x_sampled = torch.rand(args.num_iters_avg, 1, \n",
    "                        config[\"model_params\"][\"sample_size\"],\n",
    "                        config[\"model_params\"][\"sample_size\"]).to(device)\n",
    "    y = conditioning.to(device)    \n",
    "        \n",
    "    # Sampling loop\n",
    "    for t in noise_scheduler.timesteps:\n",
    "\n",
    "        # Get model pred\n",
    "        with torch.no_grad():\n",
    "            residual = model(x_sampled, t,\n",
    "                                conditioning=y\n",
    "                                ).sample\n",
    "\n",
    "        # Update sample with step\n",
    "        x_sampled = noise_scheduler.step(residual, t, x_sampled).prev_sample\n",
    "        \n",
    "    return x_sampled, evecs_first_signs_list, evecs_second_signs_list\n",
    "\n",
    "\n",
    "def get_p2p_maps_template(\n",
    "        data,\n",
    "        C_yx_est_i, evecs_first_signs_i, evecs_second_signs_i,\n",
    "        template_shape, args, log_file_name, config,\n",
    "        apply_zoomout\n",
    "    ):\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    num_evecs = config[\"model_params\"][\"sample_size\"]\n",
    "    \n",
    "    f = open(log_file_name, 'a', buffering=1)\n",
    "    \n",
    "    verts_second = data['verts']\n",
    "    faces_second = data['faces']\n",
    "    \n",
    "    evecs_first = template_shape['evecs']\n",
    "    evecs_second = data['evecs']\n",
    "    \n",
    "    # evecs_first = template_shape['evecs']\n",
    "    # evecs_second = data['evecs']\n",
    "    \n",
    "    dist_second = torch.tensor(\n",
    "        compute_geodesic_distmat(\n",
    "            verts_second.numpy(),\n",
    "            faces_second.numpy())    \n",
    "    )\n",
    "    \n",
    "    ##########################################################\n",
    "    # Convert fmaps to p2p maps to template\n",
    "    ##########################################################\n",
    "    \n",
    "    p2p_est = []\n",
    "    \n",
    "    # version without zoomout and dirichlet energy condition\n",
    "    for k in range(args.num_iters_avg):\n",
    "\n",
    "        evecs_first_corrected = evecs_first[:, :num_evecs] * evecs_first_signs_i[k]\n",
    "        evecs_second_corrected = evecs_second[:, :num_evecs] * evecs_second_signs_i[k]\n",
    "        \n",
    "        evecs_first_zo = torch.cat((evecs_first_corrected, evecs_first[:, num_evecs:]), dim=1)\n",
    "        evecs_second_zo = torch.cat((evecs_second_corrected, evecs_second[:, num_evecs:]), dim=1)\n",
    "        \n",
    "        \n",
    "        Cyx_est_k = C_yx_est_i[k][0].cpu()\n",
    "        \n",
    "        if apply_zoomout:\n",
    "        \n",
    "            Cyx_zo_k = zoomout_custom.zoomout(\n",
    "                FM_12=Cyx_est_k.to(device), \n",
    "                evects1=evecs_second_zo.to(device),\n",
    "                evects2=evecs_first_zo.to(device),\n",
    "                nit=evecs_first.shape[1] - num_evecs, step=1,\n",
    "                A2=template_shape['mass'].to(device)\n",
    "            )\n",
    "\n",
    "            p2p_est_k = fmap_util.fmap2pointmap(\n",
    "                C12=Cyx_zo_k.to(device),\n",
    "                evecs_x=evecs_second_zo.to(device),\n",
    "                evecs_y=evecs_first_zo.to(device),\n",
    "                ).cpu()\n",
    "\n",
    "        else:\n",
    "            p2p_est_k = fmap_util.fmap2pointmap(\n",
    "                C12=Cyx_est_k.to(device),\n",
    "                evecs_x=evecs_second_corrected.to(device),\n",
    "                evecs_y=evecs_first_corrected.to(device),\n",
    "                ).cpu()\n",
    "\n",
    "        p2p_est.append(p2p_est_k)\n",
    "                \n",
    "\n",
    "    p2p_est = torch.stack(p2p_est)\n",
    "        \n",
    "    ##########################################################\n",
    "    # p2p map selection\n",
    "    ##########################################################\n",
    "    \n",
    "    p2p_dirichlet, p2p_median, confidence_scores, dirichlet_energy_list = select_p2p_map_dirichlet(\n",
    "        p2p_est,\n",
    "        verts_second,\n",
    "        template_shape['L'], \n",
    "        dist_second,\n",
    "        num_samples_median=args.num_samples_median\n",
    "        )\n",
    "         \n",
    "    # f.write(f'Template stage\\n')\n",
    "    # f.write(f'Dirichlet energy: {dirichlet_energy_list}\\n')\n",
    "    # f.write(f'Confidence scores: {confidence_scores}\\n')\n",
    "    # f.write(f'Mean confidence score: {confidence_scores.mean():.3f}\\n')\n",
    "    # f.write(f'Median confidence score: {confidence_scores.median():.3f}\\n')\n",
    "    # f.write('\\n')\n",
    "    \n",
    "    # replace the code above with print, remove \\n at the end\n",
    "    print(f'Template stage')\n",
    "    print(f'Dirichlet energy: {dirichlet_energy_list}')\n",
    "    print(f'Confidence scores: {confidence_scores}')\n",
    "    print(f'Mean confidence score: {confidence_scores.mean():.3f}')\n",
    "    print(f'Median confidence score: {confidence_scores.median():.3f}')\n",
    "        \n",
    "    f.close()\n",
    "        \n",
    "    return p2p_est, p2p_dirichlet, p2p_median, confidence_scores, dist_second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self):\n",
    "        self.experiment_name='partial_0.8_5k_xyz_32_1_lambda_0.001_anisRemesh_cuts_bbox_partial_0.8_xy'\n",
    "        self.checkpoint_name='epoch_90'\n",
    "        \n",
    "        self.dataset_name='FAUST_orig_pair'\n",
    "        self.split='test'\n",
    "        \n",
    "        self.num_iters_avg=32\n",
    "        self.num_samples_median=4\n",
    "        self.confidence_threshold=0.3\n",
    "        \n",
    "        self.smoothing_type=None\n",
    "        self.smoothing_iter=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# args = parse_args()\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "# configuration\n",
    "experiment_name = args.experiment_name\n",
    "checkpoint_name = args.checkpoint_name\n",
    "\n",
    "### config\n",
    "exp_base_folder = f'/home/s94zalek_hpc/shape_matching/my_code/experiments/ddpm/{experiment_name}'\n",
    "with open(f'{exp_base_folder}/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "### model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = DiagConditionedUnet(config[\"model_params\"])\n",
    "\n",
    "if \"accelerate\" in config and config[\"accelerate\"]:\n",
    "    accelerate.load_checkpoint_in_model(model, f\"{exp_base_folder}/checkpoints/{checkpoint_name}/model.safetensors\")\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f\"{exp_base_folder}/checkpoints/{checkpoint_name}\"))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "### Sign correction network\n",
    "sign_corr_net = diffusion_network.DiffusionNet(\n",
    "    **config[\"sign_net\"][\"net_params\"]\n",
    "    )        \n",
    "sign_corr_net.load_state_dict(torch.load(\n",
    "        f'{config[\"sign_net\"][\"net_path\"]}/{config[\"sign_net\"][\"n_iter\"]}.pth'\n",
    "        ))\n",
    "sign_corr_net.to(device)\n",
    "\n",
    "\n",
    "### noise scheduler\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='squaredcos_cap_v2',\n",
    "                                clip_sample=True) \n",
    "\n",
    "# fmap network\n",
    "fmnet = RegularizedFMNet(lmbda=0.01, resolvant_gamma=0.5)\n",
    "\n",
    "\n",
    "### test dataset\n",
    "dataset_name = args.dataset_name\n",
    "split = args.split\n",
    "\n",
    "single_dataset, test_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, split, 200, preload=False, return_evecs=True, centering='bbox'\n",
    "    )\n",
    "# sign_corr_net.cache_dir = single_dataset.lb_cache_dir\n",
    "\n",
    "num_evecs = config[\"model_params\"][\"sample_size\"]\n",
    "\n",
    "##########################################\n",
    "# Template\n",
    "##########################################\n",
    "\n",
    "# template_shape = template_dataset.get_template(\n",
    "#     num_evecs=200,\n",
    "#     centering='bbox',\n",
    "#     template_path=f'/home/s94zalek_hpc/shape_matching/data/SURREAL_full/template/{config[\"sign_net\"][\"template_type\"]}/template.off',\n",
    "#     template_corr=np.loadtxt(\n",
    "#         f'/home/s94zalek_hpc/shape_matching/data/SURREAL_full/template/{config[\"sign_net\"][\"template_type\"]}/corr.txt',\n",
    "#         dtype=np.int32) - 1\n",
    "#     )    \n",
    "\n",
    "##########################################\n",
    "# Logging\n",
    "##########################################\n",
    "\n",
    "if args.smoothing_type is not None:\n",
    "    test_name = f'{args.smoothing_type}-{args.smoothing_iter}'\n",
    "else:\n",
    "    test_name = 'no_smoothing'\n",
    "\n",
    "log_dir = f'{exp_base_folder}/eval/{checkpoint_name}/{dataset_name}-{split}/{test_name}'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "fig_dir = f'{log_dir}/figs'\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "log_file_name = f'{log_dir}/log_{test_name}.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_code.datasets.surreal_dataset_3dc import TemplateSurrealDataset3DC\n",
    "\n",
    "\n",
    "augmentations = {\n",
    "        \"remesh\": {\n",
    "            \"isotropic\": {\n",
    "                \"n_remesh_iters\": 10,\n",
    "                \"remesh_targetlen\": 1,\n",
    "                \"simplify_strength_min\": 0.2,\n",
    "                \"simplify_strength_max\": 0.8,\n",
    "            },\n",
    "            \"anisotropic\": {\n",
    "                \"probability\": 0.35,\n",
    "                    \n",
    "                \"n_remesh_iters\": 10,\n",
    "                \"fraction_to_simplify_min\": 0.2,\n",
    "                \"fraction_to_simplify_max\": 0.6,\n",
    "                \"simplify_strength_min\": 0.2,\n",
    "                \"simplify_strength_max\": 0.5,\n",
    "                \"weighted_by\": \"face_count\",\n",
    "            },\n",
    "            \"partial\": {\n",
    "                \"probability\": 1,\n",
    "                \"n_remesh_iters\": 10,\n",
    "                \"fraction_to_keep_min\": 0.5,\n",
    "                \"fraction_to_keep_max\": 0.8,\n",
    "                \"n_seed_samples\": [5, 25],\n",
    "                \"weighted_by\": \"face_count\",\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "test_dataset = TemplateSurrealDataset3DC(\n",
    "    shape_path='/lustre/mlnvme/data/s94zalek_hpc-shape_matching/mmap_datas_surreal_train.pth',\n",
    "    num_evecs=128,\n",
    "    cache_lb_dir=None,\n",
    "    return_evecs=True,\n",
    "    return_fmap=False,\n",
    "    mmap=True,\n",
    "    augmentations=augmentations,\n",
    "    template_path=f'/home/s94zalek_hpc/shape_matching/data/SURREAL_full/template/remeshed/template.off',\n",
    "    template_corr=np.loadtxt(\n",
    "        f'/home/s94zalek_hpc/shape_matching/data/SURREAL_full/template/remeshed/corr.txt',\n",
    "        dtype=np.int32) - 1,\n",
    "    \n",
    "    # template_corr=np.loadtxt(\n",
    "    #     f'/home/s94zalek_hpc/shape_matching/data/SURREAL_full/template/remeshed/corr_symmetric.txt',\n",
    "    #     dtype=np.int32) - 1,\n",
    "    \n",
    "    centering='bbox',\n",
    ")   \n",
    "\n",
    "# print('!!! Using symmetric correspondence !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_dataset[1]        \n",
    "\n",
    "evecs_first = data['first']['evecs'][:, :].to(device)\n",
    "evecs_second = data['second']['evecs'][:, :].to(device)\n",
    "\n",
    "evecs_trans_first = data['first']['evecs_trans'][:, :].to(device)\n",
    "evecs_trans_second = data['second']['evecs_trans'][:, :].to(device)\n",
    "\n",
    "evals_first = data['first']['evals'][:num_evecs].to(device)\n",
    "evals_second = data['second']['evals'][:num_evecs].to(device)\n",
    "\n",
    "corr_first = data['first']['corr'].to(device)\n",
    "corr_second = data['second']['corr'].to(device)\n",
    "\n",
    "mass_second = data['second']['mass'].to(device)\n",
    "\n",
    "###############################################\n",
    "# Functional maps\n",
    "###############################################\n",
    "\n",
    "# second mesh\n",
    "\n",
    "\n",
    "if config[\"fmap_direction\"] == 'xy':\n",
    "\n",
    "    Cxy_second_list, evecs_first_signs_list_second, evecs_second_signs_list_second = get_fmaps_evec_signs(\n",
    "        data['second'], model,\n",
    "        noise_scheduler, config, args,\n",
    "        data['first'], sign_corr_net\n",
    "    )\n",
    "    # transpose the functional maps\n",
    "    Cyx_second_list = Cxy_second_list.transpose(2, 3)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    Cyx_second_list, evecs_first_signs_list_second, evecs_second_signs_list_second = get_fmaps_evec_signs(\n",
    "        data['second'], model,\n",
    "        noise_scheduler, config, args,\n",
    "        data['first'], sign_corr_net\n",
    "    )\n",
    "    \n",
    "    Cxy_second_list = Cyx_second_list.transpose(2, 3)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_err_full(dist_mat, corr_first, corr_second, p2p_est_list, p2p_dirichlet, p2p_median):\n",
    "    geo_err_est_list = []\n",
    "\n",
    "    for i in range(args.num_iters_avg):\n",
    "        geo_err_i = geodist_metric.calculate_geodesic_error(\n",
    "            dist_mat, corr_first.cpu(), corr_second.cpu(), p2p_est_list[i], return_mean=True\n",
    "        )\n",
    "        geo_err_est_list.append(geo_err_i * 100)\n",
    "        \n",
    "    geo_err_est_list = torch.tensor(geo_err_est_list)\n",
    "\n",
    "    geo_err_dirichlet = geodist_metric.calculate_geodesic_error(\n",
    "        dist_mat, corr_first.cpu(), corr_second.cpu(), p2p_dirichlet, return_mean=True\n",
    "    ) * 100\n",
    "\n",
    "    geo_err_median = geodist_metric.calculate_geodesic_error(\n",
    "        dist_mat, corr_first.cpu(), corr_second.cpu(), p2p_median, return_mean=True\n",
    "    ) * 100\n",
    "\n",
    "    print(geo_err_est_list)\n",
    "\n",
    "    print(f'Geo error est mean: {geo_err_est_list.mean().item():.3f}')\n",
    "    print(f\"Geo error est median: {geo_err_est_list.median().item():.3f}\")\n",
    "    print(f'Geo error dirichlet: {geo_err_dirichlet:.3f}')\n",
    "    print(f'Geo error median: {geo_err_median:.3f}')\n",
    "    \n",
    "    return geo_err_est_list.mean().item(), geo_err_dirichlet, geo_err_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p_est_second, p2p_dirichlet_second, p2p_median_second, confidence_scores_second, dist_y = get_p2p_maps_template(\n",
    "    data['second'],\n",
    "    Cyx_second_list, evecs_first_signs_list_second, evecs_second_signs_list_second,\n",
    "    data['first'], args, log_file_name, config,\n",
    "    apply_zoomout=False\n",
    ")\n",
    "\n",
    "p2p_est_second_rev, p2p_dirichlet_second_rev, p2p_median_second_rev, confidence_scores_second_rev, dist_x = get_p2p_maps_template(\n",
    "    data['first'],\n",
    "    Cxy_second_list, evecs_second_signs_list_second, evecs_first_signs_list_second,\n",
    "    data['second'], args, log_file_name, config,\n",
    "    apply_zoomout=False\n",
    ")\n",
    "\n",
    "print('##############################')\n",
    "print('# Forward')\n",
    "print('##############################')\n",
    "\n",
    "get_geo_err_full(dist_y, corr_second, corr_first, p2p_est_second, p2p_dirichlet_second, p2p_median_second)\n",
    "\n",
    "\n",
    "print('##############################')\n",
    "print('# Reverse')\n",
    "print('##############################')\n",
    "get_geo_err_full(dist_x, corr_first, corr_second, p2p_est_second_rev, p2p_dirichlet_second_rev, p2p_median_second_rev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    \n",
    "    data['second']['verts'], data['second']['faces'],\n",
    "    data['first']['verts'], data['first']['faces'],\n",
    "    \n",
    "    # p2p_est_second[0].cpu(),\n",
    "    p2p_dirichlet_second.cpu(),\n",
    "    # p2p_median_second.cpu(),\n",
    "    \n",
    "    \n",
    "    axes_color_gradient=[0, 1],\n",
    "    base_cmap='hsv'\n",
    ")\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    \n",
    "    data['first']['verts'], data['first']['faces'],\n",
    "    data['second']['verts'], data['second']['faces'],\n",
    "    \n",
    "    \n",
    "    p2p_dirichlet_second_rev.cpu(),\n",
    "    # p2p_median_second_rev.cpu(),\n",
    "    # p2p_est_second_rev[0].cpu(),\n",
    "    axes_color_gradient=[0, 1],\n",
    "    base_cmap='hsv'\n",
    ")\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# C_gt_xy = fmnet.compute_functional_map(\n",
    "#     (data['second']['evecs_trans'][:num_evecs, data['second']['corr']] * evecs_second_signs_list_second[0].T).unsqueeze(0),\n",
    "#     (data['first']['evecs_trans'][:num_evecs, data['first']['corr']] * evecs_first_signs_list_second[0].T).unsqueeze(0),\n",
    "#     data['second']['evals'][:num_evecs].unsqueeze(0),\n",
    "#     data['first']['evals'][:num_evecs].unsqueeze(0), \n",
    "# )[0].T\n",
    "\n",
    "# C_gt_yx = fmnet.compute_functional_map(\n",
    "#     (data['first']['evecs_trans'][:num_evecs, data['first']['corr']] * evecs_first_signs_list_second[0].T).unsqueeze(0),\n",
    "#     (data['second']['evecs_trans'][:num_evecs, data['second']['corr']] * evecs_second_signs_list_second[0].T).unsqueeze(0),\n",
    "#     data['first']['evals'][:num_evecs].unsqueeze(0), \n",
    "#     data['second']['evals'][:num_evecs].unsqueeze(0),\n",
    "# )[0].T\n",
    "\n",
    "C_gt_xy = torch.linalg.lstsq(\n",
    "    (data['second']['evecs'][:, :num_evecs][data['second']['corr']] * evecs_second_signs_list_second[0]).to(device),\n",
    "    (data['first']['evecs'][:, :num_evecs][data['first']['corr']] * evecs_first_signs_list_second[0]).to(device)\n",
    "    ).solution.to('cpu') #.unsqueeze(0)\n",
    "\n",
    "C_gt_yx = torch.linalg.lstsq(\n",
    "    (data['first']['evecs'][:, :num_evecs][data['first']['corr']] * evecs_first_signs_list_second[0]).to(device),\n",
    "    (data['second']['evecs'][:, :num_evecs][data['second']['corr']] * evecs_second_signs_list_second[0]).to(device)\n",
    "    ).solution.to('cpu') #.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "l = 0\n",
    "h = num_evecs\n",
    "\n",
    "fig, axs = plt.subplots(1, 7, figsize=(16, 4))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0], C_gt_xy.cpu(),\n",
    "                        'C_gt_xy', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1], Cxy_second_list[0][0].cpu(),\n",
    "                        'Cxy_second_list', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[2], C_gt_xy.cpu() - Cxy_second_list[0][0].cpu(),\n",
    "                        'diff', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[3], C_gt_xy.abs().cpu() - Cxy_second_list[0][0].abs().cpu(),\n",
    "                        'abs diff', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[4], C_gt_yx.cpu(),\n",
    "                        'C_gt_yx', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[5],  Cyx_second_list[0][0].cpu(),\n",
    "                        'Cyx_second_list', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[6], C_gt_yx.cpu() - Cyx_second_list[0][0].cpu(),\n",
    "                        'diff', l, h, show_grid=False, show_colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "h = num_evecs\n",
    "\n",
    "fig, axs = plt.subplots(1, 6, figsize=(16, 4))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0], C_gt_xy.cpu(),\n",
    "                        'C_gt_xy', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1], Cxy_second_list[0][0].cpu(),\n",
    "                        'Cxy_second_list', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[2], Cxy_second_list[13][0].cpu(),\n",
    "                        'Cxy_second_list', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[3], (Cxy_second_list[0][0] - Cxy_second_list[13][0]).cpu(),\n",
    "                        'diff', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[4], (Cxy_second_list[0][0].abs() - Cxy_second_list[13][0].abs()).cpu(),\n",
    "                        'abs diff', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "# select elements in both matrices which have abs > 0.1\n",
    "mask = ((Cxy_second_list[0][0].abs() > 0.1) & (Cxy_second_list[13][0].abs() > 0.1)).int()\n",
    "\n",
    "\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[5], (Cxy_second_list[0][0].sign() * Cxy_second_list[13][0].sign()).cpu() * mask.cpu(),\n",
    "                        'abs diff', l, h, show_grid=False, show_colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_grad(verts_first, verts_second, gradX_first, gradY_first, gradX_second, gradY_second, corr_first, corr_second):\n",
    "    prodX_first = gradX_first.to_dense() @ verts_first\n",
    "    prodY_first = gradY_first.to_dense() @ verts_first\n",
    "\n",
    "    prodX_second = gradX_second.to_dense() @ verts_second\n",
    "    prodY_second = gradY_second.to_dense() @ verts_second\n",
    "\n",
    "    x_score = (prodX_first[corr_first] @ prodX_second[corr_second].T).diagonal().sum()\n",
    "    y_score = (prodY_first[corr_first] @ prodY_second[corr_second].T).diagonal().sum()\n",
    "    \n",
    "    return torch.sqrt(x_score**2 + y_score**2)\n",
    "\n",
    "\n",
    "grad_scores = []\n",
    "for i in range(args.num_iters_avg):\n",
    "    grad_proj = project_grad(\n",
    "        data['first']['verts'], data['second']['verts'],\n",
    "        data['first']['gradX'], data['first']['gradY'],\n",
    "        data['second']['gradX'], data['second']['gradY'],\n",
    "        torch.ones_like(p2p_est_second[i]), p2p_est_second[i],\n",
    "    )\n",
    "    grad_scores.append(grad_proj.item())\n",
    "grad_scores = torch.tensor(grad_scores)\n",
    "\n",
    "grad_scores_rev = []\n",
    "for i in range(args.num_iters_avg):\n",
    "    grad_proj = project_grad(\n",
    "        data['first']['verts'], data['second']['verts'],\n",
    "        data['first']['gradX'], data['first']['gradY'],\n",
    "        data['second']['gradX'], data['second']['gradY'],\n",
    "        p2p_est_second_rev[i], torch.ones_like(p2p_est_second_rev[i])\n",
    "    )\n",
    "    grad_scores_rev.append(grad_proj.item())\n",
    "grad_scores_rev = torch.tensor(grad_scores_rev)\n",
    "  \n",
    "  \n",
    "print(grad_scores)  \n",
    "print(grad_scores_rev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the template a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_equal_signs(evecs_signs_list):\n",
    "\n",
    "    n_same = torch.zeros(evecs_signs_list.shape[0])\n",
    "    for i in range(evecs_signs_list.shape[0]):\n",
    "        for j in range(evecs_signs_list.shape[0]):\n",
    "            n_same[i] += (evecs_signs_list[i] == evecs_signs_list[j]).all().int()\n",
    "\n",
    "    return n_same\n",
    "    \n",
    "print('first', get_n_equal_signs(evecs_first_signs_list_second))\n",
    "print('second', get_n_equal_signs(evecs_second_signs_list_second))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the mesh area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_second = trimesh.Trimesh(vertices=data['second']['verts'].cpu(), faces=data['second']['faces'].cpu())\n",
    "\n",
    "mesh_second.area_faces.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the GT map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    \n",
    "    data['first']['verts'], data['first']['faces'],\n",
    "    data['second']['verts'], data['second']['faces'],\n",
    "    \n",
    "    \n",
    "    data['first']['corr'].cpu(),\n",
    "    # p2p_est_second[k].cpu(),\n",
    "    axes_color_gradient=[0, 1],\n",
    "    base_cmap='hsv'\n",
    ")\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnet = RegularizedFMNet(lmbda=0.001, resolvant_gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = test_dataset[10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_evecs_test = 32\n",
    "\n",
    "# C_gt_xy = torch.linalg.lstsq(\n",
    "#     data['second']['evecs'][:, :num_evecs_test][data['second']['corr']].to(device),\n",
    "#     data['first']['evecs'][:, :num_evecs_test][data['first']['corr']].to(device)\n",
    "#     ).solution.to('cpu') #.unsqueeze(0)\n",
    "\n",
    "# C_gt_yx = torch.linalg.lstsq(\n",
    "#     data['first']['evecs'][:, :num_evecs_test][data['first']['corr']].to(device),\n",
    "#     data['second']['evecs'][:, :num_evecs_test][data['second']['corr']].to(device)\n",
    "#     ).solution.to('cpu') #.unsqueeze(0)\n",
    "\n",
    "# p2p_xy = fmap_util.fmap2pointmap(\n",
    "#     C12=C_gt_xy,\n",
    "#     evecs_x=data['first']['evecs'][:, :num_evecs_test],\n",
    "#     evecs_y=data['second']['evecs'][:, :num_evecs_test],\n",
    "#     ).cpu()\n",
    "\n",
    "# p2p_yx = fmap_util.fmap2pointmap(\n",
    "#     C12=C_gt_yx,\n",
    "#     evecs_x=data['second']['evecs'][:, :num_evecs_test],\n",
    "#     evecs_y=data['first']['evecs'][:, :num_evecs_test],\n",
    "#     ).cpu()\n",
    "\n",
    "C_gt_xy = torch.linalg.lstsq(\n",
    "    (data['second']['evecs'][:, :num_evecs_test][data['second']['corr']] * evecs_second_signs_list_second[0]).to(device),\n",
    "    (data['first']['evecs'][:, :num_evecs_test][data['first']['corr']] * evecs_first_signs_list_second[0]).to(device)\n",
    "    ).solution.to('cpu') #.unsqueeze(0)\n",
    "\n",
    "C_gt_yx = torch.linalg.lstsq(\n",
    "    (data['first']['evecs'][:, :num_evecs_test][data['first']['corr']] * evecs_first_signs_list_second[0]).to(device),\n",
    "    (data['second']['evecs'][:, :num_evecs_test][data['second']['corr']] * evecs_second_signs_list_second[0]).to(device)\n",
    "    ).solution.to('cpu') #.unsqueeze(0)\n",
    "\n",
    "\n",
    "p2p_xy = fmap_util.fmap2pointmap(\n",
    "    C12=C_gt_xy,\n",
    "    evecs_x=(data['first']['evecs'][:, :num_evecs_test] * evecs_first_signs_list_second[0]),\n",
    "    evecs_y=(data['second']['evecs'][:, :num_evecs_test] * evecs_second_signs_list_second[0]),\n",
    "    ).cpu()\n",
    "\n",
    "p2p_yx = fmap_util.fmap2pointmap(\n",
    "    C12=C_gt_yx,\n",
    "    evecs_x=(data['second']['evecs'][:, :num_evecs_test] * evecs_second_signs_list_second[0]),\n",
    "    evecs_y=(data['first']['evecs'][:, :num_evecs_test] * evecs_first_signs_list_second[0]),\n",
    "    ).cpu()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_gt_xy_reg = fmnet.compute_functional_map(\n",
    "    data['second']['evecs_trans'][:num_evecs_test, data['second']['corr']].unsqueeze(0),\n",
    "    data['first']['evecs_trans'][:num_evecs_test, data['first']['corr']].unsqueeze(0),\n",
    "    data['second']['evals'][:num_evecs_test].unsqueeze(0),\n",
    "    data['first']['evals'][:num_evecs_test].unsqueeze(0), \n",
    ")[0].T\n",
    "\n",
    "C_gt_yx_reg = fmnet.compute_functional_map(\n",
    "    data['first']['evecs_trans'][:num_evecs_test, data['first']['corr']].unsqueeze(0),\n",
    "    data['second']['evecs_trans'][:num_evecs_test, data['second']['corr']].unsqueeze(0),\n",
    "    data['first']['evals'][:num_evecs_test].unsqueeze(0), \n",
    "    data['second']['evals'][:num_evecs_test].unsqueeze(0),\n",
    ")[0].T\n",
    "\n",
    "p2p_xy_reg = fmap_util.fmap2pointmap(\n",
    "    C12=C_gt_xy_reg,\n",
    "    evecs_x=data['first']['evecs'][:, :num_evecs_test],\n",
    "    evecs_y=data['second']['evecs'][:, :num_evecs_test],\n",
    "    ).cpu()\n",
    "\n",
    "p2p_yx_reg = fmap_util.fmap2pointmap(\n",
    "    C12=C_gt_yx_reg,\n",
    "    evecs_x=data['second']['evecs'][:, :num_evecs_test],\n",
    "    evecs_y=data['first']['evecs'][:, :num_evecs_test],\n",
    "    ).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "l = 0\n",
    "h = 64\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0], C_gt_xy.cpu(),\n",
    "                        'fmnet', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1],  C_gt_yx.cpu(),\n",
    "                        'fmnet', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[2],  C_gt_xy_reg.cpu(),\n",
    "                        'fmnet', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[3],  C_gt_yx_reg.cpu(),\n",
    "                        'fmnet', l, h, show_grid=False, show_colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    \n",
    "    data['first']['verts'], data['first']['faces'],\n",
    "    data['second']['verts'], data['second']['faces'],\n",
    "    \n",
    "    \n",
    "    p2p_xy.cpu(),\n",
    "    # p2p_est_second[k].cpu(),\n",
    "    axes_color_gradient=[0, 1],\n",
    "    base_cmap='hsv'\n",
    ")\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    data['second']['verts'], data['second']['faces'],    \n",
    "    data['first']['verts'], data['first']['faces'],\n",
    "\n",
    "    p2p_yx.cpu(),\n",
    "    # p2p_est_second[k].cpu(),\n",
    "    axes_color_gradient=[0, 1],\n",
    "    base_cmap='hsv'\n",
    ")\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    \n",
    "    data['first']['verts'], data['first']['faces'],\n",
    "    data['second']['verts'], data['second']['faces'],\n",
    "    \n",
    "    \n",
    "    p2p_xy_reg.cpu(),\n",
    "    # p2p_est_second[k].cpu(),\n",
    "    axes_color_gradient=[0, 1],\n",
    "    base_cmap='hsv'\n",
    ")\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    data['second']['verts'], data['second']['faces'],    \n",
    "    data['first']['verts'], data['first']['faces'],\n",
    "\n",
    "    p2p_yx_reg.cpu(),\n",
    "    # p2p_est_second[k].cpu(),\n",
    "    axes_color_gradient=[0, 1],\n",
    "    base_cmap='hsv'\n",
    ")\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['first']['evecs'].shape, data['first']['mass'][None].shape)\n",
    "\n",
    "(data['first']['evecs'].T * data['first']['mass'][None]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pfarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a random mesh from /home/s94zalek_hpc/shape_matching/data/pfarm/shapes\n",
    "\n",
    "import os\n",
    "\n",
    "random_mesh = np.random.choice(os.listdir('/home/s94zalek_hpc/shape_matching/data/pfarm/shapes'))\n",
    "\n",
    "mesh = trimesh.load_mesh(f'/home/s94zalek_hpc/shape_matching/data/pfarm/shapes/{random_mesh}',\n",
    "                         validate=True, process=False)\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "scene.add_geometry(mesh)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching to half of template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_template = trimesh.Trimesh(\n",
    "    data['first']['verts'].cpu().numpy(),\n",
    "    data['first']['faces'].cpu().numpy()\n",
    ")\n",
    "mesh_template.apply_transform(mesh_template.principal_inertia_transform)\n",
    "\n",
    "# scene.geometry.clear()\n",
    "\n",
    "# scene.add_geometry(mesh_template)\n",
    "\n",
    "# scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "verts_left = mesh_template.vertices[:, 1] < 0\n",
    "\n",
    "mesh_template.visual.vertex_colors = np.ones((mesh_template.vertices.shape[0], 4)) * 255\n",
    "mesh_template.visual.vertex_colors[verts_left] = [255, 0, 0, 255]\n",
    "\n",
    "\n",
    "# mesh_left = trimesh.intersections.slice_mesh_plane(\n",
    "#     mesh_template,\n",
    "#     plane_normal=[0, -1, 0],\n",
    "#     plane_origin=[0, 0, 0],\n",
    "#     )\n",
    "\n",
    "# make a new mesh from the left part of the template\n",
    "\n",
    "# mesh_left = trimesh.Trimesh(\n",
    "    \n",
    "# mesh_left.vertices += np.array([0, 0.5, 0])\n",
    "\n",
    "scene.add_geometry(trimesh.creation.axis(origin_size=0.1))\n",
    "scene.add_geometry(mesh_template)\n",
    "\n",
    "# scene.add_geometry(trimesh.Trimesh(vertices=mesh_left.vertices + np.array([0, 0.5, 0]), faces=mesh_left.faces))\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only faces with all vertices in verts_left\n",
    "faces_left = np.all(verts_left[mesh_template.faces], axis=1)\n",
    "\n",
    "faces_left_idx = np.where(faces_left)[0]\n",
    "faces_left_idx\n",
    "\n",
    "mesh_left = mesh_template.submesh([faces_left_idx], only_watertight=False)[0]\n",
    "\n",
    "# select only vertices from mesh_template that are in faces_left\n",
    "verts_left = np.unique(mesh_left.faces)\n",
    "# convert to boolean mask\n",
    "verts_left = np.isin(np.arange(mesh_template.vertices.shape[0]), verts_left)\n",
    "\n",
    "print(verts_left)\n",
    "\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "scene.add_geometry(trimesh.creation.axis(origin_size=0.1))\n",
    "scene.add_geometry(mesh_left)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p2p_maps_template_half(\n",
    "        data,\n",
    "        C_yx_est_i, evecs_first_signs_i, evecs_second_signs_i,\n",
    "        template_shape, args, log_file_name, config,\n",
    "        apply_zoomout\n",
    "    ):\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    num_evecs = config[\"model_params\"][\"sample_size\"]\n",
    "    \n",
    "    f = open(log_file_name, 'a', buffering=1)\n",
    "    \n",
    "    verts_second = data['verts']\n",
    "    faces_second = data['faces']\n",
    "    \n",
    "    evecs_first = template_shape['evecs'][verts_left]\n",
    "    # evecs_first = template_shape['evecs']\n",
    "    # evecs_first[~verts_left] = 100000000\n",
    "    evecs_second = data['evecs']\n",
    "    \n",
    "    # evecs_first = template_shape['evecs']\n",
    "    # evecs_second = data['evecs']\n",
    "    \n",
    "    dist_second = torch.tensor(\n",
    "        compute_geodesic_distmat(\n",
    "            verts_second.numpy(),\n",
    "            faces_second.numpy())    \n",
    "    )\n",
    "    \n",
    "    ##########################################################\n",
    "    # Convert fmaps to p2p maps to template\n",
    "    ##########################################################\n",
    "    \n",
    "    p2p_est = []\n",
    "    \n",
    "    # version without zoomout and dirichlet energy condition\n",
    "    for k in range(args.num_iters_avg):\n",
    "\n",
    "        evecs_first_corrected = evecs_first[:, :num_evecs] * evecs_first_signs_i[k]\n",
    "        evecs_second_corrected = evecs_second[:, :num_evecs] * evecs_second_signs_i[k]\n",
    "        \n",
    "        evecs_first_zo = torch.cat((evecs_first_corrected, evecs_first[:, num_evecs:]), dim=1)\n",
    "        evecs_second_zo = torch.cat((evecs_second_corrected, evecs_second[:, num_evecs:]), dim=1)\n",
    "        \n",
    "        \n",
    "        Cyx_est_k = C_yx_est_i[k][0].cpu()\n",
    "        \n",
    "        p2p_est_k = fmap_util.fmap2pointmap(\n",
    "            C12=Cyx_est_k.to(device),\n",
    "            evecs_x=evecs_second_corrected.to(device),\n",
    "            evecs_y=evecs_first_corrected.to(device),\n",
    "            ).cpu()\n",
    "        \n",
    "        # p2p_est_k = nn_query(torch.matmul(evecs_x, C12.t()), evecs_y)\n",
    "\n",
    "\n",
    "        p2p_est.append(p2p_est_k)\n",
    "        \n",
    "    p2p_est = torch.stack(p2p_est)\n",
    "        \n",
    "    return p2p_est\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p_est_second_half = get_p2p_maps_template_half(\n",
    "    data['second'],\n",
    "    Cyx_second_list, evecs_first_signs_list_second, evecs_second_signs_list_second,\n",
    "    data['first'], args, log_file_name, config,\n",
    "    apply_zoomout=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    \n",
    "    # data['first']['verts'], data['first']['faces'],\n",
    "    \n",
    "    data['second']['verts'], data['second']['faces'],\n",
    "    \n",
    "    # data['first']['verts'], data['first']['faces'],\n",
    "    \n",
    "    torch.tensor(mesh_left.vertices), torch.tensor(mesh_left.faces),\n",
    "    \n",
    "    p2p_est_second_half[0],\n",
    "    # p2p_xy.cpu(),\n",
    "    # p2p_est_second[k].cpu(),\n",
    "    axes_color_gradient=[0, 1],\n",
    "    base_cmap='hsv'\n",
    ")\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

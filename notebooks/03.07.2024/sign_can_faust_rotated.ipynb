{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading base dataset: 100%|████████████████████████████████████████████████████████████████████████████| 80/80 [00:14<00:00,  5.68it/s]\n",
      "Loading base dataset: 100%|████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  9.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import my_code.diffusion_training.data_loading as data_loading\n",
    "\n",
    "train_dataset = data_loading.get_val_dataset(\n",
    "    'FAUST_r', 'train', 200, canonicalize_fmap=None\n",
    "    )[1]\n",
    "test_dataset = data_loading.get_val_dataset(\n",
    "    'FAUST_r', 'test', 200, canonicalize_fmap=None\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "l = 0\n",
    "h = 32\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0], train_dataset[55]['second']['C_gt_xy'][0],\n",
    "                        'C_xy 55', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1], train_dataset[67]['second']['C_gt_xy'][0],\n",
    "                        'C_xy 67', l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[2], train_dataset[78]['second']['C_gt_xy'][0],\n",
    "                        'C_xy 78', l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networks.diffusion_network as diffusion_network\n",
    "\n",
    "condition_dim = 0\n",
    "start_dim = 0\n",
    "\n",
    "feature_dim = 32\n",
    "evecs_per_support = 4\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = diffusion_network.DiffusionNet(\n",
    "    in_channels=feature_dim,\n",
    "    out_channels=feature_dim // evecs_per_support,\n",
    "    cache_dir=None,\n",
    "    input_type='wks',\n",
    "    k_eig=128,\n",
    "    n_block=6\n",
    "    ).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "# add scheduler, decay by 0.1 every 30k iterations\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(opt, start_factor=1, end_factor=0.1, total_iters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/notebooks/19.06.2024/sign_double_start_0_feat_64.pth'))\n",
    "# net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/notebooks/03.07.2024/sign_double_start_0_feat_64_180xyz_scaling_09_11.pth'))\n",
    "# net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_double_start_0_feat_64_6block_factor4_180xyz_09_11_wks/39360.pth'))\n",
    "# net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_double_start_0_feat_64_6block_factor4_180xyz_09_11_noise0.01_meshLapl/39360.pth'))\n",
    "\n",
    "\n",
    "input_type = 'wks'\n",
    "net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_double_start_0_feat_32_6block_factor4_dataset_SURREAL_train_rot_180_180_180_normal_True_noise_0.0_-0.05_0.05_lapl_mesh_scale_0.9_1.1_wks/40000.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.sign_canonicalization.training as sign_training\n",
    "\n",
    "\n",
    "# train_folder = 'FAUST_rot_xyz_180_scaling_0.9_1.1'\n",
    "# train_shapes, train_diff_folder = sign_training.load_cached_shapes(\n",
    "#     f'/home/s94zalek_hpc/shape_matching/data_sign_training/train/{train_folder}'\n",
    "# )\n",
    "\n",
    "test_folder = 'FAUST_rot_xyz_180_scaling_0.9_1.1_noise_0.01_meshLapl'\n",
    "# test_folder = 'FAUST_rot_xyz_180_scaling_0.9_1.1_noise_0.01_meshLapl'\n",
    "test_shapes, test_diff_folder = sign_training.load_cached_shapes(\n",
    "    f'/home/s94zalek_hpc/shape_matching/data_sign_training/test/{test_folder}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.sign_canonicalization.training as sign_training\n",
    "\n",
    "# only keep the train and test meshes with index % 10 == 1\n",
    "# train_shapes = [train_shapes[i] for i in range(len(train_shapes)) if i % 10 == 1]\n",
    "# test_shapes = [test_shapes[i] for i in range(len(test_shapes)) if i % 10 == 1]\n",
    "\n",
    "train_shapes = [train_dataset[i]['second'] for i in range(len(train_dataset))]\n",
    "test_shapes = [test_dataset[i]['second'] for i in range(len(test_dataset))]\n",
    "\n",
    "train_diff_folder = '/home/s94zalek_hpc/shape_matching/data_with_smpl_corr/FAUST_r/diffusion'\n",
    "test_diff_folder = '/home/s94zalek_hpc/shape_matching/data_with_smpl_corr/FAUST_r/diffusion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 4 random training shapes to trimesh scene\n",
    "\n",
    "# np.random.shuffle(train_shapes)\n",
    "scene.geometry.clear()\n",
    "\n",
    "rand_idx_train = np.random.randint(0, len(train_shapes), 5)\n",
    "rand_idx_test = np.random.randint(0, len(test_shapes), 5)\n",
    "\n",
    "for i, idx in enumerate(rand_idx_train):\n",
    "    scene.add_geometry(trimesh.Trimesh(\n",
    "        vertices=train_shapes[idx]['verts'] + torch.tensor([i, 0, 0]),\n",
    "        faces=train_shapes[idx]['faces']))\n",
    "    \n",
    "for i, idx in enumerate(rand_idx_test):\n",
    "    scene.add_geometry(trimesh.Trimesh(\n",
    "        vertices=test_shapes[idx]['verts'] + torch.tensor([i, -1, 0]),\n",
    "        faces=test_shapes[idx]['faces']))\n",
    "    \n",
    "axis = trimesh.creation.axis(axis_length=1)\n",
    "scene.add_geometry(axis)\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from utils.geometry_util import get_operators\n",
    "\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "losses = torch.tensor([])\n",
    "iterator = tqdm(range(50001))\n",
    "\n",
    "# train_shapes = [train_dataset[i]['second'] for i in range(len(train_dataset))]\n",
    "# train_shapes = [train_dataset[i]['second'] for i in range(2)]\n",
    "              \n",
    "net.cache_dir = train_diff_folder      \n",
    "        \n",
    "curr_iter = 0\n",
    "for epoch in range(len(iterator) // len(train_shapes)):\n",
    "    \n",
    "    # train_shapes_shuffled = train_shapes.copy()\n",
    "    np.random.shuffle(train_shapes)\n",
    "    \n",
    "    \n",
    "    for curr_idx in range(len(train_shapes)):     \n",
    "\n",
    "        ##############################################\n",
    "        # Select a shape\n",
    "        ##############################################\n",
    "        # curr_idx = np.random.randint(0, len(train_shapes))\n",
    "    \n",
    "        train_shape = train_shapes[curr_idx]\n",
    "\n",
    "        verts = train_shape['verts'].unsqueeze(0).to(device)\n",
    "        faces = train_shape['faces'].unsqueeze(0).to(device)\n",
    "\n",
    "        evecs_orig = train_shape['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        # Set the signs on shape 0\n",
    "        ##############################################\n",
    "\n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_0 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_0[sign_gt_0 == 0] = -1\n",
    "        sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "        \n",
    "        # predict the sign change\n",
    "        sign_pred_0 = predict_sign_change(net, verts, faces, evecs_flip_0, \n",
    "                                                evecs_cond=None)[0]\n",
    "        \n",
    "        ##############################################\n",
    "        # Set the signs on shape 1\n",
    "        ##############################################\n",
    "        \n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_1 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_1[sign_gt_1 == 0] = -1\n",
    "        sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "        \n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "        \n",
    "        # predict the sign change\n",
    "        sign_pred_1 = predict_sign_change(net, verts, faces, evecs_flip_1, \n",
    "                                                evecs_cond=None)[0]\n",
    "        \n",
    "        ##############################################\n",
    "        # Calculate the loss\n",
    "        ##############################################\n",
    "        \n",
    "        # calculate the ground truth sign difference\n",
    "        sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "        \n",
    "        # calculate the sign difference between predicted evecs\n",
    "        sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = loss_fn(\n",
    "            sign_diff_pred.reshape(sign_diff_pred.shape[0], -1),\n",
    "            sign_diff_gt.reshape(sign_diff_gt.shape[0], -1)\n",
    "            )\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        losses = torch.cat([losses, torch.tensor([loss.item()])])\n",
    "        \n",
    "        # print mean of last 10 losses\n",
    "        iterator.set_description(f'loss={torch.mean(losses[-10:]):.3f}')\n",
    "        \n",
    "        # plot the losses every 1000 iterations\n",
    "        if curr_iter > 0 and curr_iter % (len(iterator) // 10) == 0:\n",
    "            pd.Series(losses.numpy()).rolling(10).mean().plot()\n",
    "            plt.yscale('log')\n",
    "            plt.show()\n",
    "            \n",
    "        curr_iter += 1\n",
    "        iterator.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model checkpoint\n",
    "torch.save(net.state_dict(), '/home/s94zalek_hpc/shape_matching/notebooks/03.07.2024/sign_double_start_0_feat_64_6ch_180xyz_09_11_factor4.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtqdm\u001b[49m\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39mclear()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "tqdm._instances.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean incorrect signs 0.62 / 32: 100%|██████████████████████████████████████████████████████████████| 1000/1000 [01:15<00:00, 13.21it/s]\n",
      "Mean incorrect signs 0.52 / 32:  96%|████████████████████████████████████████████████████████████▍  | 959/1000 [00:48<00:02, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 960 test shapes\n",
      "Incorrect signs per shape: 0.52 / 32\n",
      "Max incorrect signs tensor(7.)\n",
      "\n",
      "GT tensor([[ 1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,\n",
      "          1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1.,\n",
      "         -1.,  1., -1.,  1.]], device='cuda:0')\n",
      "PRED tensor([[ 0.3014, -0.3003,  0.2576,  0.1619, -0.2271, -0.5958, -0.3125, -0.0026,\n",
      "         -0.2664,  0.3985, -0.3048,  0.1556, -0.2514,  0.1290,  0.5954,  0.0018,\n",
      "         -0.2199, -0.3204, -0.3712,  0.1082,  0.1839, -0.6598, -0.0231, -0.0143,\n",
      "         -0.0096,  0.0949, -0.0126,  0.0020, -0.0025,  0.0122, -0.5950,  0.0027]],\n",
      "       device='cuda:0')\n",
      "Correct tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "       device='cuda:0')\n",
      "Incorrect signs 0 / 32\n",
      "tensor([0., 0., 1., 1., 0., 0., 2., 0., 1., 0., 1., 0., 0., 7., 0., 1., 2., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 2., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 3., 0., 2., 0.,\n",
      "        1., 0., 0., 3., 0., 2., 4., 0., 3., 0., 0., 0., 0., 0., 0., 0., 2., 0.,\n",
      "        1., 0., 1., 0., 0., 2., 0., 0., 3., 0., 0., 1., 1., 1., 0., 0., 2., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 2.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 3., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 2., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 2., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 2., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 0., 4., 0., 0., 2., 1., 2., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 4., 0., 3., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 3., 1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1., 2., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 2., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 3., 0., 0., 1., 1., 0., 0., 2.,\n",
      "        1., 0., 3., 0., 1., 1., 0., 0., 0., 6., 0., 1., 5., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 2., 1., 1., 0., 1., 1., 0., 0., 2., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 2., 0., 0., 5., 0., 1., 1., 1., 0., 0., 6.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 2., 0., 0., 3., 0., 1., 1., 0., 2., 1., 0., 2., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 2., 1., 0., 1., 1., 0., 0., 2., 1., 0.,\n",
      "        5., 0., 2., 0., 0., 0., 0., 6., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 0., 1., 2., 0., 0., 2., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 2., 1., 0., 0., 1., 2., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 3., 0., 0., 5., 0., 1., 1., 0., 1., 0., 1., 0., 2.,\n",
      "        5., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 2.,\n",
      "        0., 0., 2., 0., 1., 1., 0., 1., 1., 0., 0., 2., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 3., 0., 0., 2., 0.,\n",
      "        2., 0., 0., 0., 0., 2., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 2.,\n",
      "        0., 1., 2., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        2., 1., 0., 0., 0., 0., 2., 0., 1., 1., 0., 0., 0., 2., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 2., 0., 0., 2.,\n",
      "        2., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 2., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 2., 0., 0., 1., 2., 0., 0., 0., 2., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 3., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 2., 0., 0., 3., 1., 3., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 2., 0., 1.,\n",
      "        0., 1., 0., 0., 3., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 2., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 2., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 2., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 2., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean incorrect signs 0.52 / 32:  96%|████████████████████████████████████████████████████████████▍  | 960/1000 [01:07<00:02, 19.76it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import utils.geometry_util as geometry_util\n",
    "import robust_laplacian\n",
    "import scipy.sparse.linalg as sla\n",
    "import utils.geometry_util as geometry_util\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "# shapes_to_test = test_shapes\n",
    "# net.cache_dir = test_diff_folder\n",
    "\n",
    "shapes_to_test = train_shapes\n",
    "net.cache_dir = train_diff_folder\n",
    "         \n",
    "             \n",
    "              \n",
    "iterator = tqdm(range(1000))\n",
    "incorrect_signs_list = torch.tensor([])\n",
    "curr_iter = 0\n",
    "\n",
    "for epoch in range(len(iterator) // len(shapes_to_test)):\n",
    "    \n",
    "    # train_shapes_shuffled = train_shapes.copy()\n",
    "    # np.random.shuffle(test_shapes_list)\n",
    "    \n",
    "    \n",
    "    for curr_idx in range(len(shapes_to_test)):     \n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        # Select a shape\n",
    "        ##############################################\n",
    "        \n",
    "        test_shape = shapes_to_test[curr_idx]    \n",
    "        \n",
    "        verts = test_shape['verts'].unsqueeze(0).to(device)\n",
    "        faces = test_shape['faces'].unsqueeze(0).to(device)\n",
    "        evecs_orig = test_shape['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "\n",
    "        ##############################################\n",
    "        # Set the signs on shape 0\n",
    "        ##############################################\n",
    "\n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_0 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_0[sign_gt_0 == 0] = -1\n",
    "        sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_0, supp_vec_0, _ = sign_training.predict_sign_change(\n",
    "                net, verts, faces, evecs_flip_0, evecs_cond=None, input_type=input_type)\n",
    "        \n",
    "        ##############################################\n",
    "        # Set the signs on shape 1\n",
    "        ##############################################\n",
    "        \n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_1 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_1[sign_gt_1 == 0] = -1\n",
    "        sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "        \n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_1, supp_vec_1, _ = sign_training.predict_sign_change(\n",
    "                net, verts, faces, evecs_flip_1, evecs_cond=None, input_type=input_type)\n",
    "        \n",
    "        ##############################################\n",
    "        # Calculate the loss\n",
    "        ##############################################\n",
    "        \n",
    "        # calculate the ground truth sign difference\n",
    "        sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "        \n",
    "        # calculate the sign difference between predicted evecs\n",
    "        sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "        \n",
    "        sign_correct = sign_diff_pred.sign() * sign_diff_gt.sign() \n",
    "        \n",
    "        \n",
    "        # count the number of incorrect signs\n",
    "        count_incorrect_signs = (sign_correct < 0).int().sum()\n",
    "            \n",
    "        # incorrect_signs_list.append(count_incorrect_signs)\n",
    "        incorrect_signs_list = torch.cat([incorrect_signs_list, torch.tensor([count_incorrect_signs])])\n",
    "        \n",
    "        \n",
    "        iterator.set_description(f'Mean incorrect signs {incorrect_signs_list.float().mean():.2f} / {feature_dim}')\n",
    "        iterator.update(1)\n",
    "        # if count_incorrect_signs > 7:\n",
    "        #     raise ValueError('Too many incorrect signs')\n",
    "    \n",
    "    \n",
    "print(f'Results for {len(incorrect_signs_list)} test shapes')\n",
    "print(f'Incorrect signs per shape: {incorrect_signs_list.float().mean():.2f} / {feature_dim}')\n",
    "\n",
    "print('Max incorrect signs', incorrect_signs_list.max())\n",
    "\n",
    "print()\n",
    "# print('Shape idx', curr_idx)\n",
    "print('GT', sign_diff_gt)\n",
    "print('PRED', sign_diff_pred)\n",
    "print('Correct', sign_correct)\n",
    "print(f'Incorrect signs {torch.sum(sign_correct != 1)} / {feature_dim}')\n",
    "print(incorrect_signs_list)\n",
    "\n",
    "\n",
    "# plt.plot(support_vector_norm.squeeze().detach().cpu().numpy(), '.', alpha=0.1)\n",
    "# plt.ylim(-0.1, 0.1)\n",
    "# # plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which shapes have the most incorrect signs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print indices where incorrect_signs_list > 10\n",
    "print('incorrect > 10, % 20:', torch.where(incorrect_signs_list > 3)[0] % 20)\n",
    "print('incorrect > 10:', torch.where(incorrect_signs_list > 3)[0])\n",
    "\n",
    "# for each index % 0 - 19, print the mean number of incorrect signs\n",
    "\n",
    "unique_shape_idx = torch.zeros(20)\n",
    "for i in range(len(incorrect_signs_list)):\n",
    "    unique_shape_idx[i % 20] += incorrect_signs_list[i]\n",
    "    \n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].plot(unique_shape_idx)\n",
    "axs[0].set_title('Incorrect signs per unique test shape')\n",
    "\n",
    "incorrect_signs_1 = []\n",
    "incorrect_signs_11 = []\n",
    "for i in range(len(incorrect_signs_list)):\n",
    "    if i % 20 == 11:\n",
    "        incorrect_signs_11.append(incorrect_signs_list[i])\n",
    "    if i % 20 == 1:\n",
    "        incorrect_signs_1.append(incorrect_signs_list[i])\n",
    "        \n",
    "axs[1].plot(incorrect_signs_1, '.', label='shape 1')\n",
    "axs[1].plot(incorrect_signs_11, '.', label='shape 11')\n",
    "\n",
    "axs[1].set_title('Incorrect signs for shape 1 and 11')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "# mesh_orig = trimesh.Trimesh(vertices=test_shapes[173]['verts'], faces=test_shapes[11]['faces'])\n",
    "# scene.add_geometry(mesh_orig)\n",
    "\n",
    "# mesh_orig = trimesh.Trimesh(vertices=test_shapes[224]['verts'] + torch.tensor([1, 0, 0])\n",
    "#                             , faces=test_shapes[101]['faces'])\n",
    "# scene.add_geometry(mesh_orig)\n",
    "\n",
    "for i, shape_idx in enumerate(torch.where(incorrect_signs_list > 10)[0]):\n",
    "    mesh_orig = trimesh.Trimesh(vertices=test_shapes[shape_idx]['verts'] + torch.tensor([i, 0, 0])\n",
    "                                , faces=test_shapes[shape_idx]['faces'])\n",
    "    scene.add_geometry(mesh_orig)\n",
    "\n",
    "\n",
    "axis = trimesh.creation.axis(axis_length=0.5)\n",
    "scene.add_geometry(axis)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the evecs on failed shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.geometry_util import get_operators\n",
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "import robust_laplacian\n",
    "import scipy.sparse.linalg as sla\n",
    "import utils.geometry_util as geometry_util\n",
    "import potpourri3d as pp3d\n",
    "\n",
    "evec_n = 60\n",
    "\n",
    "feature_dim = 64\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "verts_0 = test_shapes[0]['verts']\n",
    "faces_0 = test_shapes[0]['faces']\n",
    "# evecs_0 = test_shapes[11]['evecs'][:, start_dim:start_dim+feature_dim]\n",
    "# evecs_0 = torch.nn.functional.normalize(evecs_0, p=2, dim=0)\n",
    "\n",
    "# verts_0 = verts_0 * 2.5\n",
    "\n",
    "# L_0 = pp3d.cotan_laplacian(verts_0.numpy(), faces_0.numpy(), denom_eps=1e-10)\n",
    "# M_0 = pp3d.vertex_areas(verts_0.numpy(), faces_0.numpy())\n",
    "# M_0 += 1e-8 * np.mean(M_0)\n",
    "# M_0 = np.diag(M_0).astype(np.float32)\n",
    "\n",
    "# print(L_0.dtype, M_0.dtype)\n",
    "\n",
    "L_0, M_0 = robust_laplacian.mesh_laplacian(verts_0.numpy(), faces_0.numpy())\n",
    "# L_0, M_0 = robust_laplacian.point_cloud_laplacian(verts_0.numpy())\n",
    "evals_0, evecs_0 = sla.eigsh(L_0, feature_dim, M_0, sigma=1e-8)\n",
    "evecs_0 = torch.tensor(evecs_0)\n",
    "\n",
    "\n",
    "verts_1 = test_shapes[1]['verts']\n",
    "faces_1 = test_shapes[1]['faces']\n",
    "# evecs_1 = test_shapes[91]['evecs'][:, start_dim:start_dim+feature_dim]\n",
    "# evecs_1 = torch.nn.functional.normalize(evecs_1, p=2, dim=0)\n",
    "\n",
    "# L_1 = pp3d.cotan_laplacian(verts_1.numpy(), faces_1.numpy(), denom_eps=1e-10)\n",
    "# M_1 = pp3d.vertex_areas(verts_1.numpy(), faces_1.numpy())\n",
    "# M_1 += 1e-8 * np.mean(M_1)\n",
    "# M_1 = np.diag(M_1).astype(np.float32)\n",
    "\n",
    "L_1, M_1 = robust_laplacian.mesh_laplacian(verts_1.numpy(), faces_1.numpy())\n",
    "# L_1, M_1 = robust_laplacian.point_cloud_laplacian(verts_1.numpy())\n",
    "evals_1, evecs_1 = sla.eigsh(L_1, feature_dim, M_1, sigma=1e-8)\n",
    "evecs_1 = torch.tensor(evecs_1)\n",
    "\n",
    "\n",
    "cmap_0 = trimesh.visual.color.interpolate(\n",
    "    torch.nn.functional.normalize(evecs_0[:, evec_n], p=2, dim=0),\n",
    "    'bwr')\n",
    "\n",
    "cmap_1 = trimesh.visual.color.interpolate(\n",
    "    torch.nn.functional.normalize(evecs_1[:, evec_n], p=2, dim=0)\n",
    "    , 'bwr')\n",
    "\n",
    "\n",
    "# chng_by_evec = (evecs_0.abs() - evecs_1.abs()).abs().sum(dim=0)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(evecs_0[:, evec_n].abs().cpu().numpy(), label='11')\n",
    "axs[0].plot(evecs_1[:, evec_n].abs().cpu().numpy(), label='101')\n",
    "axs[0].legend()\n",
    "\n",
    "C_orig_rot = torch.linalg.lstsq(evecs_0, evecs_1).solution\n",
    "plotting_utils.plot_Cxy(fig, axs[1], C_orig_rot,\n",
    "                        'C_orig_rot', 0, 64, show_grid=False, show_colorbar=False)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mesh_0 = trimesh.Trimesh(vertices=verts_0, faces=faces_0, vertex_colors=cmap_0[:len(verts_0)])\n",
    "mesh_1 = trimesh.Trimesh(vertices=verts_1 + np.array([1, 0, 0]), faces=faces_1,\n",
    "                           vertex_colors=cmap_1[:len(verts_1)])\n",
    "\n",
    "scene.add_geometry(mesh_0)\n",
    "scene.add_geometry(mesh_1)\n",
    "\n",
    "axis = trimesh.creation.axis(axis_length=1)\n",
    "scene.add_geometry(axis)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_0[l:h].mean(), evals_1[l:h].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 48\n",
    "h = 64\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(evals_0[l:h], '.-', label='evals_0')\n",
    "axs[0].plot(evals_1[l:h], '.-', label='evals_1')\n",
    "\n",
    "axs[1].plot(evals_0[l:h] - evals_0[l:h].mean(), '.-', label='evals_0')\n",
    "axs[1].plot(evals_1[l:h] - evals_1[l:h].mean(), '.-', label='evals_1')\n",
    "\n",
    "\n",
    "# plt.plot(train_dataset[78]['second']['evals'][0][l:h], '.-', label='evals_78')\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plt.imshow((supp_vec_0.transpose(1, 2) @ evecs_flip_0)[0].cpu(), cmap='bwr')\n",
    "plt.colorbar(plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marker color = blue if incorrect, red if correct\n",
    "color = np.where(sign_correct.squeeze().detach().cpu().numpy() == 1, 'red', 'blue')\n",
    "\n",
    "plt.scatter(np.arange(feature_dim), sign_diff_pred.squeeze().detach().cpu().numpy(), c=color)\n",
    "\n",
    "# plt.ylim(-0.3, 0.3)\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "# plt.plot(sign_correct.squeeze().detach().cpu().numpy(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(3, 1, figsize=(5, 10))\n",
    "\n",
    "# for i, idx in enumerate(range(1, 4)):\n",
    "#     axs[i].plot(supp_vec_0[0, :, -idx].cpu(), '-')\n",
    "plt.plot(supp_vec_0[0, :, -4].cpu(), '-')\n",
    "plt.plot(supp_vec_1[0, :, -4].cpu(), '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "verts = test_shape['verts'].cpu().numpy()\n",
    "faces = test_shape['faces'].cpu().numpy()\n",
    "\n",
    "cmap = np.ones((verts.shape[0], 4))\n",
    "\n",
    "# set cmap to 1 where supp_vec_0[0, :, -4] > 0.02\n",
    "cmap[supp_vec_0[0, :, -2].cpu().abs() > 0.015, :2] = 0\n",
    "# cmap *= 255\n",
    "\n",
    "mesh = trimesh.Trimesh(vertices=verts, faces=faces, vertex_colors=cmap)\n",
    "scene.add_geometry(mesh)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "train_shape = train_dataset[58]['second']\n",
    "verts_orig = train_shape['verts']\n",
    "faces = train_shape['faces']\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for i in range(10):\n",
    "    _, _, _, _, evecs_orig, _, _ = get_operators(verts_orig, faces,\n",
    "                                                    k=feature_dim,\n",
    "                                                    cache_dir=None)\n",
    "time_get_operators = time.time() - time_start\n",
    "\n",
    "for i in range(10):\n",
    "    L_orig, M_orig = robust_laplacian.mesh_laplacian(verts_orig.numpy(), faces.numpy())\n",
    "    # L_orig, M_orig = robust_laplacian.point_cloud_laplacian(verts_orig.numpy())\n",
    "    evals_orig, evecs_orig = sla.eigsh(L_orig, feature_dim, M_orig, sigma=1e-8)\n",
    "    evecs_orig = torch.tensor(evecs_orig)\n",
    "\n",
    "time_robust_laplacian = time.time() - time_start - time_get_operators\n",
    "\n",
    "print(f'time_get_operators: {time_get_operators}')\n",
    "print(f'time_robust_laplacian: {time_robust_laplacian}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

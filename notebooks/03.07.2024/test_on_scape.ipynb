{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.datasets.shape_dataset as shape_dataset\n",
    "\n",
    "train_dataset = shape_dataset.SingleScapeDataset(\n",
    "    phase='train',\n",
    "    data_root = 'data/SCAPE_r',\n",
    "    centering = 'bbox',\n",
    "    num_evecs=200,\n",
    "    lb_cache_dir=f'data/SCAPE_r/diffusion'\n",
    ")\n",
    "test_dataset = shape_dataset.SingleScapeDataset(\n",
    "    phase='test',\n",
    "    data_root = 'data/SCAPE_r',\n",
    "    centering = 'bbox',\n",
    "    num_evecs=200,\n",
    "    lb_cache_dir=f'data/SCAPE_r/diffusion'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shapes = [train_dataset[i] for i in range(len(train_dataset))]\n",
    "test_shapes = [test_dataset[i] for i in range(len(test_dataset))]\n",
    "\n",
    "train_diff_folder = 'data/SCAPE_r/diffusion'\n",
    "test_diff_folder = 'data/SCAPE_r/diffusion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 4 random training shapes to trimesh scene\n",
    "\n",
    "# np.random.shuffle(train_shapes)\n",
    "scene.geometry.clear()\n",
    "\n",
    "rand_idx_train = np.random.randint(0, len(train_shapes), 5)\n",
    "rand_idx_test = np.random.randint(0, len(test_shapes), 5)\n",
    "\n",
    "for i, idx in enumerate(rand_idx_train):\n",
    "    scene.add_geometry(trimesh.Trimesh(\n",
    "        vertices=train_shapes[idx]['verts'] + torch.tensor([i, 0, 0]),\n",
    "        faces=train_shapes[idx]['faces']))\n",
    "    \n",
    "for i, idx in enumerate(rand_idx_test):\n",
    "    scene.add_geometry(trimesh.Trimesh(\n",
    "        vertices=test_shapes[idx]['verts'] + torch.tensor([i, -1, 0]),\n",
    "        faces=test_shapes[idx]['faces']))\n",
    "    \n",
    "axis = trimesh.creation.axis(axis_length=1)\n",
    "scene.add_geometry(axis)\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networks.diffusion_network as diffusion_network\n",
    "\n",
    "condition_dim = 0\n",
    "start_dim = 0\n",
    "\n",
    "feature_dim = 64\n",
    "evecs_per_support = 4\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = diffusion_network.DiffusionNet(\n",
    "    in_channels=feature_dim,\n",
    "    out_channels=feature_dim // evecs_per_support,\n",
    "    cache_dir=None,\n",
    "    input_type='wks',\n",
    "    k_eig=128,\n",
    "    n_block=6\n",
    "    ).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "# add scheduler, decay by 0.1 every 30k iterations\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(opt, start_factor=1, end_factor=0.1, total_iters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = 'wks'\n",
    "\n",
    "# net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/notebooks/03.07.2024/sign_double_start_0_feat_64_6ch_180xyz_09_11_factor4.pth'))\n",
    "net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_double_start_0_feat_64_6block_factor4_180xyz_09_11_wks/39360.pth'))\n",
    "# net.load_state_dict(torch.load('/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_double_start_0_feat_64_6block_factor4_180xyz_09_11_noise0.01_meshLapl_wks/39360.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import utils.geometry_util as geometry_util\n",
    "import robust_laplacian\n",
    "import scipy.sparse.linalg as sla\n",
    "import utils.geometry_util as geometry_util\n",
    "import my_code.sign_canonicalization.training as sign_training\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "shapes_to_test = test_shapes\n",
    "net.cache_dir = test_diff_folder\n",
    "\n",
    "# shapes_to_test = train_shapes\n",
    "# net.cache_dir = train_diff_folder\n",
    "         \n",
    "             \n",
    "              \n",
    "iterator = tqdm(range(1000))\n",
    "incorrect_signs_list = torch.tensor([])\n",
    "curr_iter = 0\n",
    "\n",
    "for epoch in range(len(iterator) // len(shapes_to_test)):\n",
    "    \n",
    "    # train_shapes_shuffled = train_shapes.copy()\n",
    "    # np.random.shuffle(test_shapes_list)\n",
    "    \n",
    "    \n",
    "    for curr_idx in range(len(shapes_to_test)):     \n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        # Select a shape\n",
    "        ##############################################\n",
    "        \n",
    "        test_shape = shapes_to_test[curr_idx]    \n",
    "        \n",
    "        verts = test_shape['verts'].unsqueeze(0).to(device)\n",
    "        faces = test_shape['faces'].unsqueeze(0).to(device)\n",
    "        evecs_orig = test_shape['evecs'][:, start_dim:start_dim+feature_dim].unsqueeze(0).to(device)\n",
    "\n",
    "        ##############################################\n",
    "        # Set the signs on shape 0\n",
    "        ##############################################\n",
    "\n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_0 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_0[sign_gt_0 == 0] = -1\n",
    "        sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_0, supp_vec_0, _ = sign_training.predict_sign_change(net, verts, faces, evecs_flip_0, \n",
    "                                                evecs_cond=None, input_type=input_type)\n",
    "        \n",
    "        ##############################################\n",
    "        # Set the signs on shape 1\n",
    "        ##############################################\n",
    "        \n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_1 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_1[sign_gt_1 == 0] = -1\n",
    "        sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "        \n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_1, supp_vec_1, _ = sign_training.predict_sign_change(net, verts, faces, evecs_flip_1, \n",
    "                                                evecs_cond=None, input_type=input_type)\n",
    "        \n",
    "        ##############################################\n",
    "        # Calculate the loss\n",
    "        ##############################################\n",
    "        \n",
    "        # calculate the ground truth sign difference\n",
    "        sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "        \n",
    "        # calculate the sign difference between predicted evecs\n",
    "        sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "        \n",
    "        sign_correct = sign_diff_pred.sign() * sign_diff_gt.sign() \n",
    "        \n",
    "        \n",
    "        # count the number of incorrect signs\n",
    "        count_incorrect_signs = (sign_correct < 0).int().sum()\n",
    "            \n",
    "        # incorrect_signs_list.append(count_incorrect_signs)\n",
    "        incorrect_signs_list = torch.cat([incorrect_signs_list, torch.tensor([count_incorrect_signs])])\n",
    "        \n",
    "        \n",
    "        iterator.set_description(f'Mean incorrect signs {incorrect_signs_list.float().mean():.2f} / {feature_dim}')\n",
    "        iterator.update(1)\n",
    "        # if count_incorrect_signs > 7:\n",
    "        #     raise ValueError('Too many incorrect signs')\n",
    "    \n",
    "    \n",
    "print(f'Results for {len(incorrect_signs_list)} test shapes')\n",
    "print(f'Incorrect signs per shape: {incorrect_signs_list.float().mean():.2f} / {feature_dim}')\n",
    "\n",
    "print('Max incorrect signs', incorrect_signs_list.max())\n",
    "\n",
    "print()\n",
    "# print('Shape idx', curr_idx)\n",
    "print('GT', sign_diff_gt)\n",
    "print('PRED', sign_diff_pred)\n",
    "print('Correct', sign_correct)\n",
    "print(f'Incorrect signs {torch.sum(sign_correct != 1)} / {feature_dim}')\n",
    "print(incorrect_signs_list)\n",
    "\n",
    "\n",
    "# plt.plot(support_vector_norm.squeeze().detach().cpu().numpy(), '.', alpha=0.1)\n",
    "# plt.ylim(-0.1, 0.1)\n",
    "# # plt.yscale('log')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of trainable parameters\n",
    "print(f'Number of trainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(3, 1, figsize=(5, 10))\n",
    "\n",
    "# for i, idx in enumerate(range(1, 4)):\n",
    "#     axs[i].plot(supp_vec_0[0, :, -idx].cpu(), '-')\n",
    "plt.plot(supp_vec_0[0, :, -2].cpu(), '-')\n",
    "plt.plot(supp_vec_1[0, :, -2].cpu(), '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "verts = test_shape['verts'].cpu().numpy()\n",
    "faces = test_shape['faces'].cpu().numpy()\n",
    "\n",
    "cmap = np.ones((verts.shape[0], 4))\n",
    "\n",
    "# set cmap to 1 where supp_vec_0[0, :, -4] > 0.02\n",
    "cmap[supp_vec_0[0, :, -2].cpu().abs() > 0.015, :2] = 0\n",
    "# cmap *= 255\n",
    "\n",
    "mesh = trimesh.Trimesh(vertices=verts, faces=faces, vertex_colors=cmap)\n",
    "scene.add_geometry(mesh)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with 1 summary per evec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

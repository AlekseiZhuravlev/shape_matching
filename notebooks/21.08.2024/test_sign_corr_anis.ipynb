{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "scene = trimesh.Scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networks.diffusion_network as diffusion_network\n",
    "from tqdm import tqdm\n",
    "import my_code.sign_canonicalization.training as sign_training\n",
    "import torch\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import yaml\n",
    "\n",
    "exp_name = 'signNet_remeshed_4b_mass_10_0.2_0.8' \n",
    "# exp_name = 'signNet_isoRemesh_targetlen_3'\n",
    "# exp_name = 'signNet_anisRemesh' \n",
    "# exp_name = 'signNet_FAUST_a'\n",
    "\n",
    "exp_dir = f'/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_net/{exp_name}'\n",
    "\n",
    "with open(f'{exp_dir}/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "start_dim = config['start_dim']\n",
    "\n",
    "feature_dim = config['feature_dim']\n",
    "evecs_per_support = config['evecs_per_support']\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = diffusion_network.DiffusionNet(\n",
    "    **config['net_params']\n",
    "    ).to(device)\n",
    "\n",
    "input_type = config['net_params']['input_type']\n",
    "\n",
    "net.load_state_dict(torch.load(f'{exp_dir}/{config[\"n_iter\"]}.pth'))\n",
    "\n",
    "test_dataset = data_loading.get_val_dataset(\n",
    "    'SHREC19', 'test', 128, canonicalize_fmap=None, preload=False, return_evecs=True\n",
    "    )[0]     \n",
    "# test_dataset = data_loading.get_val_dataset(\n",
    "#     'FAUST_orig', 'test', 128, canonicalize_fmap=None, preload=False, return_evecs=True\n",
    "#     )[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.sign_canonicalization.remesh as remesh\n",
    "import torch\n",
    "import my_code.datasets.preprocessing as preprocessing\n",
    "\n",
    "\n",
    "tqdm._instances.clear()\n",
    "    \n",
    "with_mass = config['with_mass']\n",
    "n_epochs = 1\n",
    "iterator = tqdm(total=len(test_dataset) * n_epochs)\n",
    "incorrect_signs_list = torch.tensor([])\n",
    "curr_iter = 0\n",
    "    \n",
    "for _ in range(n_epochs):\n",
    "    for curr_idx in range(len(test_dataset)):\n",
    "        \n",
    "        curr_idx = 19\n",
    "\n",
    "        ##############################################\n",
    "        # Select a shape\n",
    "        ##############################################\n",
    "\n",
    "        train_shape_orig = test_dataset[curr_idx]\n",
    "\n",
    "        verts_orig = train_shape_orig['verts']\n",
    "        faces_orig = train_shape_orig['faces']\n",
    "        \n",
    "        verts, faces = remesh.remesh_simplify_iso(\n",
    "            verts_orig,\n",
    "            faces_orig,\n",
    "            n_remesh_iters=10,\n",
    "            remesh_targetlen=1,\n",
    "            simplify_strength=1,\n",
    "        )\n",
    "        \n",
    "        mesh_anis_remeshed = trimesh.Trimesh(verts, faces)\n",
    "        # apply laplacian smoothing\n",
    "        # trimesh.smoothing.filter_laplacian(mesh_anis_remeshed, lamb=0.5, iterations=smoothing_iter)\n",
    "        trimesh.smoothing.filter_taubin(\n",
    "            mesh_anis_remeshed, lamb=0.5,\n",
    "            iterations=5\n",
    "            )\n",
    "        \n",
    "        train_shape = {\n",
    "            'verts': torch.tensor(mesh_anis_remeshed.vertices).float(),\n",
    "            'faces': torch.tensor(mesh_anis_remeshed.faces).int(),\n",
    "        }\n",
    "        train_shape = preprocessing.get_spectral_ops(train_shape, num_evecs=128,\n",
    "                                    cache_dir=None)\n",
    "        \n",
    "\n",
    "        # train_shape = double_shape['second']\n",
    "        verts = train_shape['verts'].unsqueeze(0).to(device)\n",
    "        faces = train_shape['faces'].unsqueeze(0).to(device)    \n",
    "\n",
    "        evecs_orig = train_shape['evecs'].unsqueeze(0)[:, :, start_dim:start_dim+feature_dim].to(device)\n",
    "        \n",
    "        if with_mass:\n",
    "            mass_mat = torch.diag_embed(\n",
    "                train_shape['mass'].unsqueeze(0)\n",
    "                ).to(device)\n",
    "        else:\n",
    "            mass_mat = None\n",
    "\n",
    "        ##############################################\n",
    "        # Set the signs on shape 0\n",
    "        ##############################################\n",
    "\n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_0 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_0[sign_gt_0 == 0] = -1\n",
    "        sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "        # print('evecs_orig', evecs_orig.shape, 'sign_gt_0', sign_gt_0.shape)\n",
    "\n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "        \n",
    "        \n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_0, supp_vec_0, _ = sign_training.predict_sign_change(\n",
    "                net, verts, faces, evecs_flip_0, \n",
    "                mass_mat=mass_mat, input_type=net.input_type,\n",
    "                \n",
    "                mass=train_shape['mass'].unsqueeze(0), L=train_shape['L'].unsqueeze(0),\n",
    "                evals=train_shape['evals'].unsqueeze(0), evecs=train_shape['evecs'].unsqueeze(0),\n",
    "                gradX=train_shape['gradX'].unsqueeze(0), gradY=train_shape['gradY'].unsqueeze(0)\n",
    "                )\n",
    "        \n",
    "        ##############################################\n",
    "        # Set the signs on shape 1\n",
    "        ##############################################\n",
    "        \n",
    "        # create a random combilation of +1 and -1, length = feature_dim\n",
    "        sign_gt_1 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "        \n",
    "        sign_gt_1[sign_gt_1 == 0] = -1\n",
    "        sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "        \n",
    "        # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "        evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "        \n",
    "        # predict the sign change\n",
    "        with torch.no_grad():\n",
    "            sign_pred_1, supp_vec_1, _ = sign_training.predict_sign_change(\n",
    "                net, verts, faces, evecs_flip_1, \n",
    "                mass_mat=mass_mat, input_type=net.input_type,\n",
    "                \n",
    "                mass=train_shape['mass'].unsqueeze(0), L=train_shape['L'].unsqueeze(0),\n",
    "                evals=train_shape['evals'].unsqueeze(0), evecs=train_shape['evecs'].unsqueeze(0),\n",
    "                gradX=train_shape['gradX'].unsqueeze(0), gradY=train_shape['gradY'].unsqueeze(0)\n",
    "                )\n",
    "        \n",
    "        ##############################################\n",
    "        # Calculate the loss\n",
    "        ##############################################\n",
    "        \n",
    "        # calculate the ground truth sign difference\n",
    "        sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "        \n",
    "        # calculate the sign difference between predicted evecs\n",
    "        sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "        \n",
    "        sign_correct = sign_diff_pred.sign() * sign_diff_gt.sign() \n",
    "        \n",
    "        \n",
    "        # count the number of incorrect signs\n",
    "        count_incorrect_signs = (sign_correct < 0).int().sum()\n",
    "        \n",
    "        # if count_incorrect_signs > 2:\n",
    "        #     break\n",
    "        \n",
    "        if curr_idx == 19:\n",
    "            break\n",
    "            \n",
    "        # incorrect_signs_list.append(count_incorrect_signs)\n",
    "        incorrect_signs_list = torch.cat([incorrect_signs_list, torch.tensor([count_incorrect_signs])])\n",
    "        \n",
    "        \n",
    "        iterator.set_description(f'Mean incorrect signs {incorrect_signs_list.float().mean():.2f} / {feature_dim}, max {incorrect_signs_list.max()}')\n",
    "        iterator.update(1)\n",
    "        # if count_incorrect_signs > 7:\n",
    "        #     raise ValueError('Too many incorrect signs')\n",
    "        \n",
    "    # return incorrect_signs_list.float().mean(), incorrect_signs_list.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sign_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh.visual\n",
    "\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "verts = train_shape['verts'].cpu().numpy()\n",
    "faces = train_shape['faces'].cpu().numpy()\n",
    "\n",
    "for i in range(supp_vec_0.shape[-1] // evecs_per_support):\n",
    "\n",
    "    cmap = np.ones((verts.shape[0], 4))\n",
    "\n",
    "    # set cmap to 1 where supp_vec_0[0, :, -4] > 0.02\n",
    "    cmap[supp_vec_0[0, :, i * evecs_per_support].cpu().abs() > 0.015, :2] = 0\n",
    "    cmap *= 255\n",
    "    \n",
    "    # supp_vec_i = supp_vec_0[0, :, i * evecs_per_support].cpu().numpy()\n",
    "    \n",
    "    # set values with abs < 0.015 to 0   \n",
    "    # cmap = trimesh.visual.color.interpolate(supp_vec_i, 'bwr')\n",
    "    # cmap[np.abs(supp_vec_i) < 0.015] = 255\n",
    "\n",
    "    mesh = trimesh.Trimesh(vertices=verts + np.array([i, 0, 0]), faces=faces, vertex_colors=cmap)\n",
    "    scene.add_geometry(mesh)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "verts = train_shape['verts'].cpu().numpy()\n",
    "faces = train_shape['faces'].cpu().numpy()\n",
    "\n",
    "for i in range(supp_vec_0.shape[-1] // evecs_per_support):\n",
    "\n",
    "    cmap = np.ones((verts.shape[0], 4))\n",
    "\n",
    "    # set cmap to 1 where supp_vec_0[0, :, -4] > 0.02\n",
    "    cmap[supp_vec_0[0, :, i * evecs_per_support].cpu().abs() > 0.015, :2] = 0\n",
    "    # cmap *= 255\n",
    "\n",
    "    mesh = trimesh.Trimesh(vertices=verts + np.array([i, 0, 0]), faces=faces, vertex_colors=cmap)\n",
    "    scene.add_geometry(mesh)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shape = test_dataset[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.geometry_util as geometry_util\n",
    "\n",
    "wks_orig = geometry_util.compute_wks_autoscale(\n",
    "    train_shape['evals'].unsqueeze(0), \n",
    "    train_shape['evecs'].unsqueeze(0), \n",
    "    train_shape['mass'].unsqueeze(0))[0]\n",
    "\n",
    "hks_orig = geometry_util.compute_hks_autoscale(\n",
    "    train_shape['evals'].unsqueeze(0), \n",
    "    train_shape['evecs'].unsqueeze(0), \n",
    "    16)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# wks_orig.shape\n",
    "plt.plot(hks_orig[:, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "verts = train_shape['verts'].cpu().numpy()\n",
    "faces = train_shape['faces'].cpu().numpy()\n",
    "\n",
    "for i, idx in enumerate(range(1, 10, 1)):\n",
    "    mesh = trimesh.Trimesh(vertices=verts + np.array([i, 0, 0]), faces=faces)\n",
    "    cmap = trimesh.visual.color.interpolate(hks_orig[:, idx].cpu().numpy(), 'bwr')\n",
    "    mesh.visual.vertex_colors = cmap\n",
    "    scene.add_geometry(mesh)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "verts = train_shape['verts'].cpu().numpy()\n",
    "faces = train_shape['faces'].cpu().numpy()\n",
    "\n",
    "for i, idx in enumerate(range(1, 82, 10)):\n",
    "    mesh = trimesh.Trimesh(vertices=verts + np.array([i, 0, 0]), faces=faces)\n",
    "    cmap = trimesh.visual.color.interpolate(wks_orig[:, idx].cpu().numpy(), 'bwr')\n",
    "    mesh.visual.vertex_colors = cmap\n",
    "    scene.add_geometry(mesh)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "sys.path.append('/home/s94zalek_hpc/shape_matching/pyFM_fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read /home/s94zalek_hpc/shape_matching/data/SHREC19_r/off/19.off\n",
    "mesh = trimesh.load('/home/s94zalek_hpc/shape_matching/data/SHREC19_r/off/20.off')\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFM.mesh import TriMesh\n",
    "\n",
    "mesh_pyfm = TriMesh(mesh.vertices, mesh.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFM.signatures.WKS_functions import mesh_WKS\n",
    "\n",
    "mesh_pyfm.process(k=128, intrinsic=False, verbose=True)\n",
    "wks_pyfm = mesh_WKS(mesh_pyfm, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs_pyfm = mesh_pyfm.eigenvectors\n",
    "evals_pyfm = mesh_pyfm.eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "# verts = train_shape['verts'].cpu().numpy()\n",
    "# faces = train_shape['faces'].cpu().numpy()\n",
    "\n",
    "verts = np.array(mesh.vertices)\n",
    "faces = np.array(mesh.faces)\n",
    "\n",
    "for i, idx in enumerate(range(1, 10, 1)):\n",
    "    mesh = trimesh.Trimesh(vertices=verts + np.array([i, 0, 0]), faces=faces)\n",
    "    cmap = trimesh.visual.color.interpolate(wks_pyfm[:, idx], 'bwr')\n",
    "    mesh.visual.vertex_colors = cmap\n",
    "    scene.add_geometry(mesh)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare cotan with robust laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robust_laplacian\n",
    "import potpourri3d as pp3d\n",
    "import scipy.sparse.linalg as sla\n",
    "import scipy.sparse\n",
    "\n",
    "eps = 1e-8\n",
    "\n",
    "# L = pp3d.cotan_laplacian(verts, faces, denom_eps=1e-10)\n",
    "# massvec_np = pp3d.vertex_areas(verts, faces)\n",
    "# massvec_np += eps * np.mean(massvec_np)\n",
    "\n",
    "L, M = robust_laplacian.mesh_laplacian(verts, faces)\n",
    "massvec_np = M.diagonal()\n",
    "\n",
    "L_eigsh = (L + eps * scipy.sparse.identity(L.shape[0])).tocsc()\n",
    "massvec_eigsh = massvec_np\n",
    "Mmat = scipy.sparse.diags(massvec_eigsh)\n",
    "eigs_sigma = eps\n",
    "\n",
    "fail_cnt = 0\n",
    "\n",
    "evals_np, evecs_np = sla.eigsh(L_eigsh, k=128, M=Mmat, sigma=eigs_sigma)\n",
    "# Clip off any eigenvalues that end up slightly negative due to numerical error\n",
    "evals_np = np.clip(evals_np, a_min=0., a_max=float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts.shape, evecs_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.geometry_util as geometry_util\n",
    "\n",
    "# wks_lapl = geometry_util.compute_hks_autoscale(\n",
    "#     torch.tensor(evals_np).unsqueeze(0), \n",
    "#     torch.tensor(evecs_np).unsqueeze(0), \n",
    "#     torch.tensor(massvec_np).unsqueeze(0),\n",
    "#     )[0]\n",
    "\n",
    "wks_lapl = geometry_util.auto_wks(\n",
    "    torch.tensor(evals_np), \n",
    "    torch.tensor(evecs_np), \n",
    "    128,\n",
    "    # scaled=False\n",
    "    )\n",
    "\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "# verts = train_shape['verts'].cpu().numpy()\n",
    "# faces = train_shape['faces'].cpu().numpy()\n",
    "\n",
    "for i, idx in enumerate(range(1, 10, 1)):\n",
    "    mesh_i = trimesh.Trimesh(vertices=verts + np.array([i, 0, 0]), faces=faces)\n",
    "    cmap = trimesh.visual.color.interpolate(wks_lapl[:, idx], 'bwr')\n",
    "    mesh_i.visual.vertex_colors = cmap\n",
    "    scene.add_geometry(mesh_i)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "# verts = train_shape['verts'].cpu().numpy()\n",
    "# faces = train_shape['faces'].cpu().numpy()\n",
    "\n",
    "for i in range(5, 10):\n",
    "    mesh_pyfm = trimesh.Trimesh(vertices=verts + np.array([0, -i, 0]), faces=faces)\n",
    "    cmap = trimesh.visual.color.interpolate(evecs_pyfm[:, i], 'bwr')\n",
    "    mesh_pyfm.visual.vertex_colors = cmap\n",
    "    scene.add_geometry(mesh_pyfm)\n",
    "\n",
    "    mesh_lapl = trimesh.Trimesh(vertices=verts + np.array([1, -i, 0]), faces=faces)\n",
    "    cmap = trimesh.visual.color.interpolate(evecs_np[:, i], 'bwr')\n",
    "    mesh_lapl.visual.vertex_colors = cmap\n",
    "    scene.add_geometry(mesh_lapl)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sum(np.abs(evecs_pyfm) - np.abs(evecs_np), axis = 0))\n",
    "print(np.sum(np.abs(evecs_pyfm) - np.abs(evecs_np), axis = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

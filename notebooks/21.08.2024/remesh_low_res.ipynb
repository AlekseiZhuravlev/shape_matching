{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymeshlab\n",
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()\n",
    "ms = pymeshlab.MeshSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "\n",
    "test_dataset = data_loading.get_val_dataset(\n",
    "    'FAUST_a', 'test', 128, canonicalize_fmap=None, preload=False, return_evecs=True\n",
    "    )[1]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = test_dataset[0]\n",
    "\n",
    "# mesh_anis = trimesh.load_mesh('/home/s94zalek_hpc/shape_matching/data/FAUST_a/off/tr_reg_080.off')\n",
    "mesh_anis = trimesh.Trimesh(vertices=data_0['second']['verts'], faces=data_0['second']['faces'])\n",
    "mesh_anis.vertices += [1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remesh the mesh\n",
    "ms.clear()\n",
    "# ms.load_new_mesh('/home/s94zalek_hpc/shape_matching/data/FAUST_a/off/tr_reg_080.off')\n",
    "\n",
    "# v_anis, f_anis = trimesh.remesh.subdivide_to_size(mesh_anis.vertices, mesh_anis.faces, max_edge=0.01)\n",
    "\n",
    "v_anis = mesh_anis.vertices\n",
    "f_anis = mesh_anis.faces\n",
    "ms.add_mesh(pymeshlab.Mesh(v_anis, f_anis))\n",
    "\n",
    "ms.meshing_isotropic_explicit_remeshing(\n",
    "    iterations=10,\n",
    "    targetlen=pymeshlab.PercentageValue(1)\n",
    ")\n",
    "\n",
    "# ms.apply_coord_hc_laplacian_smoothing(\n",
    "#     # stepsmoothnum=1\n",
    "# )\n",
    "# ms.apply_coord_laplacian_smoothing(\n",
    "#     stepsmoothnum=1\n",
    "# )\n",
    "\n",
    "v_anis = ms.current_mesh().vertex_matrix()\n",
    "f_anis = ms.current_mesh().face_matrix()\n",
    "\n",
    "# mesh_anis_remeshed = trimesh.Trimesh(v_anis, f_anis)\n",
    "\n",
    "# v_anis, f_anis = trimesh.remesh.subdivide_to_size(v_anis, f_anis, max_edge=0.02)\n",
    "mesh_anis_remeshed = trimesh.Trimesh(v_anis + [1, 0, 0], f_anis)\n",
    "# # apply laplacian smoothing\n",
    "trimesh.smoothing.filter_laplacian(mesh_anis_remeshed, lamb=0.5, iterations=3)\n",
    "# trimesh.smoothing.filter_humphrey(mesh_anis_remeshed, iterations=3)\n",
    "\n",
    "print('before', mesh_anis.vertices.shape, mesh_anis.faces.shape)\n",
    "print('after remesh', v_anis.shape, f_anis.shape)\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "scene.add_geometry(trimesh.creation.axis())\n",
    "\n",
    "scene.add_geometry(mesh_anis)\n",
    "scene.add_geometry(mesh_anis_remeshed)\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_anis_remeshed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "edges_len_anis = mesh_anis.edges_unique_length\n",
    "edges_len_remeshed = mesh_anis_remeshed.edges_unique_length\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "axs[0].hist(edges_len_anis, bins=100, cumulative=False, density=True)\n",
    "axs[0].set_title('Anisotropic mesh')\n",
    "\n",
    "axs[1].hist(edges_len_remeshed, bins=100, cumulative=False, density=True)\n",
    "axs[1].set_title('Remeshed mesh')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.fmap_util as fmap_util\n",
    "import torch\n",
    "\n",
    "p2p_aR_a = fmap_util.nn_query(\n",
    "    torch.tensor(mesh_anis_remeshed.vertices), \n",
    "    torch.tensor(mesh_anis.vertices),\n",
    "    )\n",
    "p2p_aR_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p_a_t = data_0['second']['corr']\n",
    "p2p_aR_t = p2p_aR_a[p2p_a_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "plotting_utils.plot_p2p_map(\n",
    "    scene,\n",
    "    mesh_anis_remeshed.vertices, mesh_anis_remeshed.faces,\n",
    "    mesh_anis.vertices, mesh_anis.faces,\n",
    "    p2p_aR_a\n",
    "    )\n",
    "    \n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.geometry_util import get_operators\n",
    "\n",
    "evecs_a = data_0['second']['evecs']\n",
    "evecs_t = data_0['first']['evecs']\n",
    "\n",
    "evecs_aR = get_operators(\n",
    "    torch.tensor(mesh_anis_remeshed.vertices),\n",
    "    torch.tensor(mesh_anis_remeshed.faces),\n",
    "    k=128,\n",
    "    cache_dir=None)[4].float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs_aR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p_aR_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap_a_t = torch.linalg.lstsq(\n",
    "    evecs_a[p2p_a_t],\n",
    "    evecs_t\n",
    "    ).solution.to('cpu')\n",
    "\n",
    "fmap_aR_t = torch.linalg.lstsq(\n",
    "    evecs_aR[p2p_aR_t],\n",
    "    evecs_t\n",
    "    ).solution.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "\n",
    "l = 0\n",
    "h = 32\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "plotting_utils.plot_Cxy(fig, axs[0], fmap_a_t, 'fmap_a_t',\n",
    "                        l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[1], fmap_aR_t, 'fmap_aR_t',\n",
    "                        l, h, show_grid=False, show_colorbar=False)\n",
    "plotting_utils.plot_Cxy(fig, axs[2], fmap_a_t.abs() - fmap_aR_t.abs(), 'abs diff',\n",
    "                        l, h, show_grid=False, show_colorbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_code.sign_canonicalization.test_sign_correction as test_sign_correction\n",
    "\n",
    "name = 'FAUST_orig'\n",
    "split = 'test'\n",
    "remesh_targetlen = 3\n",
    "\n",
    "test_dataset_curr = data_loading.get_val_dataset(\n",
    "    name, split, 128, canonicalize_fmap=None, preload=False, return_evecs=True\n",
    "    )[0]\n",
    "\n",
    "test_dataset = test_sign_correction.remesh_dataset(\n",
    "    test_dataset_curr, f'{name}-{split}',\n",
    "    remesh_targetlen, num_evecs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "for i, idx in enumerate(range(len(test_dataset))):\n",
    "    data = test_dataset[idx]\n",
    "\n",
    "    mesh = trimesh.Trimesh(vertices=data['verts'], faces=data['faces'])\n",
    "    \n",
    "    mesh.vertices += [i, 0, 0]\n",
    "\n",
    "    scene.add_geometry(mesh)\n",
    "    \n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_verts = 0\n",
    "n_faces = 0\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    n_verts += test_dataset[i]['verts'].shape[0]\n",
    "    n_faces += test_dataset[i]['faces'].shape[0]\n",
    "    \n",
    "print(f'{name}, mean verts: {n_verts / len(test_dataset)}, mean faces: {n_faces / len(test_dataset)}')\n",
    "    "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networks.diffusion_network as diffusion_network\n",
    "from tqdm import tqdm\n",
    "import my_code.sign_canonicalization.training as sign_training\n",
    "import my_code.sign_canonicalization.remesh as remesh\n",
    "import torch\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import yaml\n",
    "import my_code.datasets.preprocessing as preprocessing\n",
    "import trimesh\n",
    "\n",
    "\n",
    "def remesh_dataset(dataset, name, remesh_targetlen, smoothing_iter, num_evecs):\n",
    "\n",
    "    new_dataset = []\n",
    "\n",
    "    for i in tqdm(range(len(dataset)), desc=f'Remeshing the dataset {name}'):\n",
    "        \n",
    "        train_shape_orig = dataset[i]\n",
    "\n",
    "        verts_orig = train_shape_orig['verts']\n",
    "        faces_orig = train_shape_orig['faces']\n",
    "        \n",
    "        verts, faces = remesh.remesh_simplify_iso(\n",
    "            verts_orig,\n",
    "            faces_orig,\n",
    "            n_remesh_iters=10,\n",
    "            remesh_targetlen=remesh_targetlen,\n",
    "            simplify_strength=1,\n",
    "        )\n",
    "        \n",
    "        verts = verts_orig\n",
    "        faces = faces_orig\n",
    "        \n",
    "        mesh_anis_remeshed = trimesh.Trimesh(verts, faces)\n",
    "        # apply laplacian smoothing\n",
    "        trimesh.smoothing.filter_laplacian(mesh_anis_remeshed, lamb=0.5, iterations=smoothing_iter)\n",
    "        \n",
    "        train_shape = {\n",
    "            'verts': torch.tensor(mesh_anis_remeshed.vertices).float(),\n",
    "            'faces': torch.tensor(mesh_anis_remeshed.faces).int(),\n",
    "        }\n",
    "        train_shape = preprocessing.get_spectral_ops(train_shape, num_evecs=num_evecs,\n",
    "                                    cache_dir=None)\n",
    "        \n",
    "        new_dataset.append(train_shape)\n",
    "    \n",
    "    return new_dataset\n",
    "\n",
    "\n",
    "def test_on_dataset(net, test_dataset, with_mass, n_epochs):\n",
    "\n",
    "    tqdm._instances.clear()\n",
    "        \n",
    "    iterator = tqdm(total=len(test_dataset) * n_epochs)\n",
    "    incorrect_signs_list = torch.tensor([])\n",
    "    curr_iter = 0\n",
    "\n",
    "        \n",
    "    for _ in range(n_epochs):\n",
    "        for curr_idx in range(len(test_dataset)):\n",
    "\n",
    "            ##############################################\n",
    "            # Select a shape\n",
    "            ##############################################\n",
    "\n",
    "            train_shape = test_dataset[curr_idx]           \n",
    "            \n",
    "            ##############################################\n",
    "            # Set the variables\n",
    "            ##############################################\n",
    "\n",
    "            # train_shape = double_shape['second']\n",
    "            verts = train_shape['verts'].unsqueeze(0).to(device)\n",
    "            faces = train_shape['faces'].unsqueeze(0).to(device)    \n",
    "\n",
    "            evecs_orig = train_shape['evecs'].unsqueeze(0)[:, :, start_dim:start_dim+feature_dim].to(device)\n",
    "            \n",
    "            if with_mass:\n",
    "                mass_mat = torch.diag_embed(\n",
    "                    train_shape['mass'].unsqueeze(0)\n",
    "                    ).to(device)\n",
    "            else:\n",
    "                mass_mat = None\n",
    "\n",
    "            ##############################################\n",
    "            # Set the signs on shape 0\n",
    "            ##############################################\n",
    "\n",
    "            # create a random combilation of +1 and -1, length = feature_dim\n",
    "            sign_gt_0 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "            \n",
    "            sign_gt_0[sign_gt_0 == 0] = -1\n",
    "            sign_gt_0 = sign_gt_0.float().unsqueeze(0)\n",
    "\n",
    "            # print('evecs_orig', evecs_orig.shape, 'sign_gt_0', sign_gt_0.shape)\n",
    "\n",
    "            # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "            evecs_flip_0 = evecs_orig * sign_gt_0\n",
    "            \n",
    "            \n",
    "            \n",
    "            # predict the sign change\n",
    "            with torch.no_grad():\n",
    "                sign_pred_0, supp_vec_0, _ = sign_training.predict_sign_change(\n",
    "                    net, verts, faces, evecs_flip_0, \n",
    "                    mass_mat=mass_mat, input_type=net.input_type,\n",
    "                    \n",
    "                    mass=train_shape['mass'].unsqueeze(0), L=train_shape['L'].unsqueeze(0),\n",
    "                    evals=train_shape['evals'].unsqueeze(0), evecs=train_shape['evecs'].unsqueeze(0),\n",
    "                    gradX=train_shape['gradX'].unsqueeze(0), gradY=train_shape['gradY'].unsqueeze(0)\n",
    "                    )\n",
    "            \n",
    "            ##############################################\n",
    "            # Set the signs on shape 1\n",
    "            ##############################################\n",
    "            \n",
    "            # create a random combilation of +1 and -1, length = feature_dim\n",
    "            sign_gt_1 = torch.randint(0, 2, (feature_dim,)).float().to(device)\n",
    "            \n",
    "            sign_gt_1[sign_gt_1 == 0] = -1\n",
    "            sign_gt_1 = sign_gt_1.float().unsqueeze(0)\n",
    "            \n",
    "            # multiply evecs [6890 x 16] by sign_flip [16]\n",
    "            evecs_flip_1 = evecs_orig * sign_gt_1\n",
    "            \n",
    "            # predict the sign change\n",
    "            with torch.no_grad():\n",
    "                sign_pred_1, supp_vec_1, _ = sign_training.predict_sign_change(\n",
    "                    net, verts, faces, evecs_flip_1, \n",
    "                    mass_mat=mass_mat, input_type=net.input_type,\n",
    "                    \n",
    "                    mass=train_shape['mass'].unsqueeze(0), L=train_shape['L'].unsqueeze(0),\n",
    "                    evals=train_shape['evals'].unsqueeze(0), evecs=train_shape['evecs'].unsqueeze(0),\n",
    "                    gradX=train_shape['gradX'].unsqueeze(0), gradY=train_shape['gradY'].unsqueeze(0)\n",
    "                    )\n",
    "            \n",
    "            ##############################################\n",
    "            # Calculate the loss\n",
    "            ##############################################\n",
    "            \n",
    "            # calculate the ground truth sign difference\n",
    "            sign_diff_gt = sign_gt_1 * sign_gt_0\n",
    "            \n",
    "            # calculate the sign difference between predicted evecs\n",
    "            sign_diff_pred = sign_pred_1 * sign_pred_0\n",
    "            \n",
    "            sign_correct = sign_diff_pred.sign() * sign_diff_gt.sign() \n",
    "            \n",
    "            \n",
    "            # count the number of incorrect signs\n",
    "            count_incorrect_signs = (sign_correct < 0).int().sum()\n",
    "                \n",
    "            # incorrect_signs_list.append(count_incorrect_signs)\n",
    "            incorrect_signs_list = torch.cat([incorrect_signs_list, torch.tensor([count_incorrect_signs])])\n",
    "            \n",
    "            \n",
    "            iterator.set_description(f'Mean incorrect signs {incorrect_signs_list.float().mean():.2f} / {feature_dim}, max {incorrect_signs_list.max()}')\n",
    "            iterator.update(1)\n",
    "            # if count_incorrect_signs > 7:\n",
    "            #     raise ValueError('Too many incorrect signs')\n",
    "        \n",
    "    return incorrect_signs_list.float().mean(), incorrect_signs_list.max()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        \n",
    "    exp_name = 'signNet_remeshed_4b_10_0.2_0.8' \n",
    "    \n",
    "    \n",
    "    exp_dir = f'/home/s94zalek_hpc/shape_matching/my_code/experiments/sign_net/{exp_name}'\n",
    "    \n",
    "    with open(f'{exp_dir}/config.yaml', 'r') as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    remesh_targetlen = 1\n",
    "    smoothing_iter = 5\n",
    "    # remesh_targetlen = config['dataset']['remesh']['isotropic']['remesh_targetlen']\n",
    "        \n",
    "    start_dim = config['start_dim']\n",
    "\n",
    "    feature_dim = config['feature_dim']\n",
    "    evecs_per_support = config['evecs_per_support']\n",
    "\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = diffusion_network.DiffusionNet(\n",
    "        **config['net_params']\n",
    "        ).to(device)\n",
    "\n",
    "    input_type = config['net_params']['input_type']\n",
    "    \n",
    "    \n",
    "    log_file = f'{exp_dir}/log_10ep_remesh_{remesh_targetlen}_smooth_{smoothing_iter}.txt'\n",
    "    # log_file = f'{exp_dir}/log_10ep_noRemesh.txt'\n",
    "    \n",
    "\n",
    "    for n_iter in [50000]:\n",
    "    # for n_iter in [200, 600, 1000, 1400, 2000]:\n",
    "\n",
    "        net.load_state_dict(torch.load(f'{exp_dir}/{n_iter}.pth'))\n",
    "\n",
    "\n",
    "        for dataset_name, split in [\n",
    "            # (config[\"train_folder\"], 'train'),\n",
    "            ('FAUST_a', 'test'),\n",
    "            # ('SHREC19', 'train'), \n",
    "            # ('FAUST_r', 'test'),\n",
    "            # ('FAUST_orig', 'test'), \n",
    "            # ('FAUST_r', 'train'), \n",
    "            # ('FAUST_orig', 'train'), \n",
    "            ]:\n",
    "            \n",
    "            if dataset_name == config[\"train_folder\"]:\n",
    "                test_dataset_curr, _ = sign_training.load_cached_shapes(\n",
    "                    f'/home/s94zalek_hpc/shape_matching/data_sign_training/train/{config[\"train_folder\"]}',\n",
    "                    unsqueeze=False\n",
    "                )  \n",
    "\n",
    "                    \n",
    "                mean_incorrect_signs, max_incorrect_signs = test_on_dataset(net, test_dataset_curr, with_mass=config['with_mass'], n_epochs=1)\n",
    "                \n",
    "            else:\n",
    "                test_dataset_curr = data_loading.get_val_dataset(\n",
    "                    dataset_name, split, 128, canonicalize_fmap=None, preload=False, return_evecs=True\n",
    "                    )[0]\n",
    "                \n",
    "                if remesh_targetlen is not None:\n",
    "                    test_dataset_curr = remesh_dataset(\n",
    "                        test_dataset_curr, dataset_name,\n",
    "                        remesh_targetlen, num_evecs=net.k_eig,\n",
    "                        smoothing_iter=smoothing_iter)\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.geometry.clear()\n",
    "\n",
    "for i, idx in enumerate(range(len(test_dataset_curr))):\n",
    "    mesh_i = trimesh.Trimesh(\n",
    "        test_dataset_curr[idx]['verts'].to('cpu').numpy() + [i, 0, 0],\n",
    "        test_dataset_curr[idx]['faces'].to('cpu').numpy()\n",
    "        )\n",
    "    scene.add_geometry(mesh_i)\n",
    "    \n",
    "scene.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

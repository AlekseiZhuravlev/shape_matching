{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "/home/s94zalek/shape_matching\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/s94zalek/shape_matching')\n",
    "\n",
    "# set logging level to info\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from datasets_code import build_dataloader, build_dataset\n",
    "from utils.options import parse_options\n",
    "from train import create_train_val_dataloader\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.chdir('/home/s94zalek/shape_matching')\n",
    "\n",
    "# print current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend DataParallel.\n",
      "Path already exists. Rename it to /home/s94zalek/shape_matching/results/faust_archived_20240503_085119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing DatasetFromListOfDicts: 100%|████████████████████████████████████████████████████████████████████████| 80/80 [00:12<00:00,  6.66it/s]\n",
      "Calculating functional maps: 100%|████████████████████████████████████████████████████████████████████████████| 6400/6400 [01:19<00:00, 80.10it/s]\n",
      "2024-05-03 08:52:51,244 INFO: Dataset [PairFaustDataset]-[FaustTrain] is built.\n",
      "Constructing DatasetFromListOfDicts: 100%|████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  9.13it/s]\n",
      "Calculating functional maps: 100%|█████████████████████████████████████████████████████████████████████████████| 400/400 [00:03<00:00, 104.02it/s]\n",
      "2024-05-03 08:52:57,288 INFO: Dataset [PairFaustDataset]-[FaustTest] is built.\n",
      "Constructing DatasetFromListOfDicts: 100%|████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 29.34it/s]\n",
      "Calculating functional maps: 100%|█████████████████████████████████████████████████████████████████████████████| 400/400 [00:03<00:00, 104.23it/s]\n",
      "2024-05-03 08:53:01,814 INFO: Dataset [PairFaustDataset]-[FaustTest] is built.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# root_path = osp.abspath(osp.join(__file__, osp.pardir))\n",
    "root_path = '/home/s94zalek/shape_matching'\n",
    "\n",
    "opt = parse_options(root_path, is_train=False, use_argparse=False,\n",
    "                    opt_path = 'options/train/faust.yaml')\n",
    "\n",
    "opt['root_path'] = root_path\n",
    "opt['dist'] = False\n",
    "\n",
    "opt['datasets']['train_dataset']['return_corr'] = True\n",
    "opt['datasets']['train_dataset']['return_dist'] = False\n",
    "opt['datasets']['test_dataset']['return_dist'] = False\n",
    "\n",
    "# create train and validation dataloaders\n",
    "result = create_train_val_dataloader(opt)\n",
    "train_loader, train_sampler, val_loader, total_epochs, total_iters = result\n",
    "\n",
    "test_set = build_dataset(opt['datasets']['test_dataset'])\n",
    "test_loader = build_dataloader(\n",
    "test_set, opt['datasets']['test_dataset'], phase='val', num_gpu=opt['num_gpu'], dist=opt['dist'], sampler=None, seed=opt['manual_seed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cxy_40 = []\n",
    "Dx_40 = []\n",
    "Dy_40 = []\n",
    "\n",
    "Vxy_computed_40 = []\n",
    "Rxy_computed_40 = []\n",
    "\n",
    "data_40 = []\n",
    "\n",
    "train_dataset = train_loader.dataset\n",
    "for i in range(len(train_dataset)):\n",
    "    data = train_dataset[i]\n",
    "    if data['first']['name'] == 'tr_reg_040':\n",
    "        \n",
    "        Cxy_40.append(data['Cxy'])\n",
    "        \n",
    "        Dx_40.append(data['first']['evals'])\n",
    "        Dy_40.append(data['second']['evals'])\n",
    "        \n",
    "        Vxy_computed_40.append(data['Vxy'])\n",
    "        Rxy_computed_40.append(data['Rxy'])\n",
    "        \n",
    "        data_40.append(data)\n",
    "        \n",
    "Cxy_40_full = torch.stack(Cxy_40)\n",
    "Cxy_40_truncated = torch.stack(Cxy_40)[:, :20, :20]\n",
    "\n",
    "Dx_40_full = torch.stack(Dx_40)\n",
    "Dy_40_full = torch.stack(Dy_40)\n",
    "\n",
    "Vxy_computed_40_full = torch.stack(Vxy_computed_40)\n",
    "Rxy_computed_40_full = torch.stack(Rxy_computed_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# Check if difference operators in dataset are correct\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cxy_T_Cxy_40_full = torch.bmm(Cxy_40_full.transpose(1, 2), Cxy_40_full)\n",
    "\n",
    "Rxy_40_left = torch.bmm(\n",
    "    torch.diag_embed(-1 / Dx_40_full),\n",
    "    Cxy_40_full.transpose(1, 2)\n",
    "    )\n",
    "Rxy_40_right = torch.bmm(\n",
    "    torch.diag_embed(-Dy_40_full),\n",
    "    Cxy_40_full\n",
    "    )\n",
    "\n",
    "Rxy_40_full = torch.bmm(Rxy_40_left, Rxy_40_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vxy in dataset - Vxy computed: tensor(0.0002)\n",
      "Rxy in dataset - Rxy computed: tensor(-6.4227e-05)\n"
     ]
    }
   ],
   "source": [
    "print('Vxy in dataset - Vxy computed:', (Vxy_computed_40_full - Cxy_T_Cxy_40_full).sum())\n",
    "print('Rxy in dataset - Rxy computed:', (Rxy_40_full - Rxy_computed_40_full).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#\n",
    "# Descriptor preservation by GT Fmap\n",
    "#\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 200]), torch.Size([200, 5001]), torch.Size([5001, 200]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_40[21]\n",
    "data_x = data['first']\n",
    "data_y = data['second']\n",
    "\n",
    "data['Cxy'].shape, data_x['evecs_trans'].shape, data_y['evecs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicator preserv. loss,  50 ef, sum: tensor(0.3631) mean: tensor(0.0001)\n",
      "Indicator preserv. loss, 100 ef, sum: tensor(1.6721) mean: tensor(0.0002)\n",
      "Indicator preserv. loss, 150 ef, sum: tensor(3.8614) mean: tensor(0.0002)\n",
      "Indicator preserv. loss, 200 ef, sum: tensor(5.6738) mean: tensor(0.0001)\n"
     ]
    }
   ],
   "source": [
    "# indicator functions as descriptors\n",
    "\n",
    "ind_pres_loss = (data['Cxy'] @ data_x['evecs_trans'] - data_y['evecs_trans']).abs()\n",
    "\n",
    "print('Indicator preserv. loss,  50 ef, sum:',\n",
    "      ind_pres_loss[:50, :50].sum(), 'mean:', ind_pres_loss[:50, :50].mean())\n",
    "print('Indicator preserv. loss, 100 ef, sum:', ind_pres_loss[:100, :100].sum(),\n",
    "      'mean:', ind_pres_loss[:100, :100].mean())\n",
    "print('Indicator preserv. loss, 150 ef, sum:', ind_pres_loss[:150, :150].sum(),\n",
    "      'mean:', ind_pres_loss[:150, :150].mean())\n",
    "print('Indicator preserv. loss, 200 ef, sum:', ind_pres_loss[:200, :200].sum(),\n",
    "      'mean:', ind_pres_loss[:200, :200].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I guess this counts as preservation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HKS preserv. loss,  50 ef, sum: tensor(17.4320) mean: tensor(0.0218)\n",
      "HKS preserv. loss, 100 ef, sum: tensor(21.4995) mean: tensor(0.0134)\n",
      "HKS preserv. loss, 150 ef, sum: tensor(24.1054) mean: tensor(0.0100)\n",
      "HKS preserv. loss, 200 ef, sum: tensor(25.4915) mean: tensor(0.0080)\n"
     ]
    }
   ],
   "source": [
    "import utils.geometry_util as geometry_util\n",
    "\n",
    "# hks as descriptors\n",
    "hks_x = geometry_util.compute_hks_autoscale(data_x['evals'].unsqueeze(0), data_x['evecs'].unsqueeze(0), 16)[0]\n",
    "hks_y = geometry_util.compute_hks_autoscale(data_y['evals'].unsqueeze(0), data_y['evecs'].unsqueeze(0), 16)[0]\n",
    "\n",
    "hks_pres_loss = (data['Cxy'] @ data_x['evecs_trans'] @ hks_x - data_y['evecs_trans'] @ hks_y).abs()\n",
    "\n",
    "print('HKS preserv. loss,  50 ef, sum:', hks_pres_loss[:50, :50].sum(), 'mean:', hks_pres_loss[:50, :50].mean())\n",
    "print('HKS preserv. loss, 100 ef, sum:', hks_pres_loss[:100, :100].sum(), 'mean:', hks_pres_loss[:100, :100].mean())\n",
    "print('HKS preserv. loss, 150 ef, sum:', hks_pres_loss[:150, :150].sum(), 'mean:', hks_pres_loss[:150, :150].mean())\n",
    "print('HKS preserv. loss, 200 ef, sum:', hks_pres_loss[:200, :200].sum(), 'mean:', hks_pres_loss[:200, :200].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WKS preserv. loss,  50 ef, sum: tensor(25.3663) mean: tensor(0.0101)\n",
      "WKS preserv. loss, 100 ef, sum: tensor(77.3188) mean: tensor(0.0077)\n",
      "WKS preserv. loss, 150 ef, sum: tensor(126.9926) mean: tensor(0.0066)\n",
      "WKS preserv. loss, 200 ef, sum: tensor(149.6696) mean: tensor(0.0058)\n"
     ]
    }
   ],
   "source": [
    "# wks as descriptors\n",
    "\n",
    "wks_x = geometry_util.compute_wks_autoscale(data_x['evals'].unsqueeze(0), data_x['evecs'].unsqueeze(0), data_x['mass'].unsqueeze(0))[0]\n",
    "wks_y = geometry_util.compute_wks_autoscale(data_y['evals'].unsqueeze(0), data_y['evecs'].unsqueeze(0), data_y['mass'].unsqueeze(0))[0]\n",
    "\n",
    "wks_pres_loss = (data['Cxy'] @ data_x['evecs_trans'] @ wks_x - data_y['evecs_trans'] @ wks_y).abs()\n",
    "\n",
    "print('WKS preserv. loss,  50 ef, sum:', wks_pres_loss[:50, :50].sum(), 'mean:', wks_pres_loss[:50, :50].mean())\n",
    "print('WKS preserv. loss, 100 ef, sum:', wks_pres_loss[:100, :100].sum(), 'mean:', wks_pres_loss[:100, :100].mean())\n",
    "print('WKS preserv. loss, 150 ef, sum:', wks_pres_loss[:150, :150].sum(), 'mean:', wks_pres_loss[:150, :150].mean())\n",
    "print('WKS preserv. loss, 200 ef, sum:', wks_pres_loss[:200, :200].sum(), 'mean:', wks_pres_loss[:200, :200].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#\n",
    "# Does this count as descriptor preservation?\n",
    "# I guess it does\n",
    "#\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cxy_lstsq error,      50 ef, sum: tensor(146.2175) mean: tensor(0.0585)\n",
      "Cxy_lstsq error,     100 ef, sum: tensor(481.7635) mean: tensor(0.0482)\n",
      "Cxy_lstsq error,     200 ef, sum: tensor(1554.0223) mean: tensor(0.0389)\n",
      "\n",
      "Cxy_hks_lstsq error,  50 ef, sum: tensor(169.5795) mean: tensor(0.0678)\n",
      "Cxy_hks_lstsq error, 100 ef, sum: tensor(472.1356) mean: tensor(0.0472)\n",
      "Cxy_hks_lstsq error, 200 ef, sum: tensor(1363.8035) mean: tensor(0.0341)\n",
      "\n",
      "Cxy_wks_lstsq error,  50 ef, sum: tensor(260.7804) mean: tensor(0.1043)\n",
      "Cxy_wks_lstsq error, 100 ef, sum: tensor(678.8275) mean: tensor(0.0679)\n",
      "Cxy_wks_lstsq error, 200 ef, sum: tensor(1659.1672) mean: tensor(0.0415)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "Cxy_lstsq = torch.linalg.lstsq(\n",
    "    (data_x['evecs_trans']).T,\n",
    "    (data_y['evecs_trans']).T\n",
    ").solution.T\n",
    "\n",
    "Cxy_hks_lstsq = torch.linalg.lstsq(\n",
    "    hks_x.T @ data_x['evecs_trans'].T,\n",
    "    hks_y.T @ data_y['evecs_trans'].T\n",
    ").solution.T\n",
    "\n",
    "Cxy_wks_lstsq = torch.linalg.lstsq(\n",
    "    wks_x.T @ data_x['evecs_trans'].T,\n",
    "    wks_y.T @ data_y['evecs_trans'].T\n",
    ").solution.T\n",
    "\n",
    "print('Cxy_lstsq error,      50 ef, sum:', (Cxy_lstsq - data['Cxy']).abs()[:50, :50].sum(), 'mean:', (Cxy_lstsq - data['Cxy']).abs()[:50, :50].mean())\n",
    "print('Cxy_lstsq error,     100 ef, sum:', (Cxy_lstsq - data['Cxy']).abs()[:100, :100].sum(), 'mean:', (Cxy_lstsq - data['Cxy']).abs()[:100, :100].mean())\n",
    "print('Cxy_lstsq error,     200 ef, sum:', (Cxy_lstsq - data['Cxy']).abs().sum(), 'mean:', (Cxy_lstsq - data['Cxy']).abs().mean())\n",
    "print()\n",
    "print('Cxy_hks_lstsq error,  50 ef, sum:', (Cxy_hks_lstsq - data['Cxy']).abs()[:50, :50].sum(), 'mean:', (Cxy_hks_lstsq - data['Cxy']).abs()[:50, :50].mean())\n",
    "print('Cxy_hks_lstsq error, 100 ef, sum:', (Cxy_hks_lstsq - data['Cxy']).abs()[:100, :100].sum(), 'mean:', (Cxy_hks_lstsq - data['Cxy']).abs()[:100, :100].mean())\n",
    "print('Cxy_hks_lstsq error, 200 ef, sum:', (Cxy_hks_lstsq - data['Cxy']).abs().sum(), 'mean:', (Cxy_hks_lstsq - data['Cxy']).abs().mean())\n",
    "print()\n",
    "print('Cxy_wks_lstsq error,  50 ef, sum:', (Cxy_wks_lstsq - data['Cxy']).abs()[:50, :50].sum(), 'mean:', (Cxy_wks_lstsq - data['Cxy']).abs()[:50, :50].mean())\n",
    "print('Cxy_wks_lstsq error, 100 ef, sum:', (Cxy_wks_lstsq - data['Cxy']).abs()[:100, :100].sum(), 'mean:', (Cxy_wks_lstsq - data['Cxy']).abs()[:100, :100].mean())\n",
    "print('Cxy_wks_lstsq error, 200 ef, sum:', (Cxy_wks_lstsq - data['Cxy']).abs().sum(), 'mean:', (Cxy_wks_lstsq - data['Cxy']).abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cxy_gt\n",
      "0: desc 0.0139030, laplace 0.0003710, area 0.0000000, conf 0.0000000\n",
      "---------------------------------\n",
      "0: desc 0.0080456, laplace 0.0005256, area 0.0272858, conf 0.0000481\n",
      "10000: desc 0.0082145, laplace 0.0007532, area 0.0094935, conf 0.0000046\n",
      "20000: desc 0.0080711, laplace 0.0004005, area 0.0075172, conf 0.0000061\n",
      "30000: desc 0.0082834, laplace 0.0003767, area 0.0053022, conf 0.0000196\n",
      "40000: desc 0.0084635, laplace 0.0004066, area 0.0030422, conf 0.0000062\n",
      "50000: desc 0.0085401, laplace 0.0004058, area 0.0019669, conf 0.0000058\n",
      "60000: desc 0.0086851, laplace 0.0003920, area 0.0013787, conf 0.0000194\n",
      "70000: desc 0.0086927, laplace 0.0003296, area 0.0004975, conf 0.0000055\n",
      "80000: desc 0.0086342, laplace 0.0002922, area 0.0001527, conf 0.0000043\n",
      "90000: desc 0.0085809, laplace 0.0002503, area 0.0000961, conf 0.0000037\n",
      "100000: desc 0.0084872, laplace 0.0001469, area 0.0000489, conf 0.0000040\n",
      "110000: desc 0.0084571, laplace 0.0000956, area 0.0000349, conf 0.0000030\n",
      "120000: desc 0.0084485, laplace 0.0000791, area 0.0000153, conf 0.0000037\n",
      "130000: desc 0.0084441, laplace 0.0000627, area 0.0000083, conf 0.0000035\n",
      "140000: desc 0.0084434, laplace 0.0000504, area 0.0000067, conf 0.0000026\n",
      "150000: desc 0.0084405, laplace 0.0000475, area 0.0000082, conf 0.0000025\n",
      "160000: desc 0.0084328, laplace 0.0000428, area 0.0000083, conf 0.0000033\n",
      "170000: desc 0.0084260, laplace 0.0000450, area 0.0000044, conf 0.0000035\n",
      "180000: desc 0.0084249, laplace 0.0000455, area 0.0000037, conf 0.0000034\n",
      "190000: desc 0.0084234, laplace 0.0000455, area 0.0000031, conf 0.0000027\n",
      "200000: desc 0.0084217, laplace 0.0000458, area 0.0000029, conf 0.0000026\n",
      "210000: desc 0.0084204, laplace 0.0000460, area 0.0000028, conf 0.0000027\n",
      "220000: desc 0.0084185, laplace 0.0000467, area 0.0000030, conf 0.0000027\n",
      "230000: desc 0.0084176, laplace 0.0000471, area 0.0000028, conf 0.0000026\n",
      "240000: desc 0.0084172, laplace 0.0000474, area 0.0000025, conf 0.0000024\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Optimization problem with area and conformal difference\n",
    "######################################################\n",
    "\n",
    "import scipy.optimize as opt\n",
    "\n",
    "evecs_x = data_x['evecs'].cpu().numpy()[:, :50]\n",
    "evecs_y = data_y['evecs'].cpu().numpy()[:, :50]\n",
    "evecs_trans_x = data_x['evecs_trans'].cpu().numpy()[:50, :]\n",
    "evecs_trans_y = data_y['evecs_trans'].cpu().numpy()[:50, :]\n",
    "Cxy_gt = data['Cxy'].cpu().numpy()[:50, :50]\n",
    "\n",
    "evals_x = data_x['evals'].cpu().numpy()[:50]\n",
    "evals_y = data_y['evals'].cpu().numpy()[:50]\n",
    "\n",
    "V_gt = Cxy_gt.T @ Cxy_gt\n",
    "R_gt = np.diag(-1/evals_x) @ Cxy_gt.T @ np.diag(evals_y) @ Cxy_gt\n",
    "\n",
    "ev_sqdiff = np.square(evals_x[None, :] - evals_y[:, None])\n",
    "ev_sqdiff = ev_sqdiff / ev_sqdiff.sum()\n",
    "\n",
    "\n",
    "def area_difference(Cxy):\n",
    "    Cxy = Cxy.reshape(Cxy_gt.shape)\n",
    "    \n",
    "    Cxy_T_Cxy = Cxy.T @ Cxy\n",
    "    Cxy_T_Cxy = Cxy_T_Cxy / Cxy_T_Cxy.sum()\n",
    "    \n",
    "    return 0.5 * np.sum(np.square(\n",
    "        Cxy_T_Cxy - V_gt / V_gt.sum()\n",
    "        ))\n",
    "    \n",
    "    \n",
    "def conformal_difference(Cxy):\n",
    "    # return 0\n",
    "    Cxy = Cxy.reshape(Cxy_gt.shape)\n",
    "    \n",
    "    predicted = (np.diag(-1 / evals_x[:]) @ \\\n",
    "        Cxy[:, :].T @ \\\n",
    "        np.diag(evals_y[:]) @ \\\n",
    "        # Cxy[:, :])[0:, 0:] - R_gt[0:, 0:]       \n",
    "        Cxy[:, :])[1:, 1:]\n",
    "    \n",
    "    predicted = predicted / predicted.sum()\n",
    "    actual = R_gt[1:, 1:] / R_gt[1:, 1:].sum()\n",
    "    \n",
    "    return 0.5 * np.mean(np.square(\n",
    "        predicted - actual      \n",
    "    ))\n",
    "    \n",
    "\n",
    "def objective_diff_operators(Cxy, info):\n",
    "    \n",
    "    Cxy = Cxy.reshape(Cxy_gt.shape)\n",
    "    \n",
    "    # descriptor preservation\n",
    "    desc_pres = 0.5 * np.sum(np.square(Cxy @ evecs_trans_x - evecs_trans_y))\n",
    "\n",
    "    # laplace commutativity    \n",
    "    laplace_comm = 0.5 * (np.square(Cxy) * ev_sqdiff).sum()\n",
    "\n",
    "    # area and conformal difference\n",
    "    area_diff = area_difference(Cxy)\n",
    "    conf_diff = conformal_difference(Cxy)\n",
    "    \n",
    "    # print every 10000 iterations\n",
    "    if info['Nfeval'] % info['print_every'] == 0:\n",
    "        print(f\"{info['Nfeval']}: desc {desc_pres:.7f}, laplace {laplace_comm:.7f}, area {area_diff:.7f}, conf {conf_diff:.7f}\")\n",
    "    info['Nfeval'] += 1    \n",
    "    \n",
    "    return info['desc_weight']*desc_pres + laplace_comm + info['area_weight']*area_diff + info['conf_weight']*conf_diff\n",
    "\n",
    "\n",
    "print('Cxy_gt')\n",
    "objective_diff_operators(Cxy_gt, {'Nfeval':0, 'print_every':10000,'desc_weight': 1000, 'area_weight': 1, 'conf_weight': 1})\n",
    "print('---------------------------------')\n",
    "\n",
    "\n",
    "# initialization\n",
    "# Cxy_0 = np.eye(Cxy_gt.shape[0]) #+ np.random.randn(*Cxy_gt.shape) * 0.05\n",
    "Cxy_0 = Cxy_lstsq[:50, :50].numpy()\n",
    "# Cxy_0 = np.random.randn(*Cxy_gt.shape) * 0.5\n",
    "\n",
    "\n",
    "# minimize\n",
    "res = opt.fmin_l_bfgs_b(\n",
    "    func=objective_diff_operators,\n",
    "    x0=Cxy_0.reshape(-1),\n",
    "    args=({\n",
    "        'Nfeval':0,\n",
    "        'print_every':10000,\n",
    "        'desc_weight': 1,\n",
    "        'area_weight': 1,\n",
    "        'conf_weight': 1\n",
    "        },),\n",
    "    approx_grad=True,\n",
    "    maxiter=300000,\n",
    "    maxfun=300000\n",
    ")\n",
    "\n",
    "Cxy_opt = res[0].reshape(Cxy_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cxy_gt\n",
      "0: desc 0.0139030, comm 0.0003710\n",
      "---------------------------------\n",
      "0: desc 0.1181455, comm 0.1285492\n",
      "5000: desc 0.1104173, comm 0.1142726\n",
      "10000: desc 0.0207682, comm 0.0050332\n",
      "15000: desc 0.0094452, comm 0.0011580\n",
      "20000: desc 0.0085205, comm 0.0001767\n",
      "25000: desc 0.0081553, comm 0.0001090\n",
      "30000: desc 0.0081117, comm 0.0000563\n",
      "35000: desc 0.0080885, comm 0.0000531\n",
      "40000: desc 0.0080854, comm 0.0000512\n"
     ]
    }
   ],
   "source": [
    "ev_sqdiff = np.square(evals_x[None, :] - evals_y[:, None])\n",
    "ev_sqdiff = ev_sqdiff / ev_sqdiff.sum()\n",
    "\n",
    "def objective_laplace_comm(Cxy, info):\n",
    "    \n",
    "    Cxy = Cxy.reshape(Cxy_gt.shape)\n",
    "    \n",
    "    # descriptor preservation\n",
    "    desc_pres = 0.5 * np.sum(np.square(Cxy @ evecs_trans_x - evecs_trans_y))\n",
    "\n",
    "    # laplace commutativity\n",
    "    # laplace_diff = np.sum(np.square(\n",
    "    #     Cxy @ np.diag(evals_x) - np.diag(evals_y) @ Cxy\n",
    "    #     ))\n",
    "    \n",
    "    laplace_diff = 0.5 * (np.square(Cxy) * ev_sqdiff).sum()\n",
    "    \n",
    "    # print every 10000 iterations\n",
    "    if info['Nfeval'] % info['print_every'] == 0:\n",
    "        print(f\"{info['Nfeval']}: desc {desc_pres:.7f}, comm {laplace_diff:.7f}\")\n",
    "    info['Nfeval'] += 1    \n",
    "    \n",
    "    return desc_pres + laplace_diff\n",
    "\n",
    "\n",
    "print('Cxy_gt')\n",
    "objective_laplace_comm(Cxy_gt, {'Nfeval':0, 'print_every':10000,'desc_weight': 1000, 'area_weight': 1, 'conf_weight': 1})\n",
    "print('---------------------------------')\n",
    "\n",
    "\n",
    "# initialization\n",
    "# Cxy_0 = np.eye(Cxy_gt.shape[0]) #+ np.random.randn(*Cxy_gt.shape) * 0.05\n",
    "# Cxy_0 = Cxy_lstsq[:50, :50].numpy()\n",
    "Cxy_0 = np.random.randn(*Cxy_gt.shape) * 0.5\n",
    "\n",
    "\n",
    "# minimize\n",
    "res_comm = opt.fmin_l_bfgs_b(\n",
    "    func=objective_laplace_comm,\n",
    "    x0=Cxy_0.reshape(-1),\n",
    "    args=({\n",
    "        'Nfeval':0,\n",
    "        'print_every':5000,\n",
    "        'desc_weight': 1,\n",
    "        'area_weight': 1,\n",
    "        'conf_weight': 1\n",
    "        },),\n",
    "    approx_grad=True,\n",
    "    maxiter=100000,\n",
    "    maxfun=100000\n",
    ")\n",
    "Cxy_opt_comm = res_comm[0].reshape(Cxy_gt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: desc 0.0160948, area 33.2356864, conf 61.0985776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110.42909380248226"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective(Cxy_opt, {'Nfeval':0, 'print_every':10000,'desc_weight': 1000, 'area_weight': 1, 'conf_weight': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Cxy_opt\n",
      "Cxy_est - Cxy_gt: 131.31\n",
      "Pyx_est - Pyx_gt: 12741.73\n",
      "Geodesic error GT: 92.73, EST: 294.46\n",
      "------ Cxy_opt_comm\n",
      "Cxy_est - Cxy_gt: 131.79\n",
      "Pyx_est - Pyx_gt: 12400.13\n",
      "Geodesic error GT: 92.73, EST: 320.83\n",
      "\n",
      "------ Cxy_lstsq\n",
      "Cxy_est - Cxy_gt: 146.22\n",
      "Pyx_est - Pyx_gt: 12059.97\n",
      "Geodesic error GT: 92.73, EST: 387.44\n",
      "\n",
      "------ Cxy_hks_lstsq\n",
      "Cxy_est - Cxy_gt: 169.58\n",
      "Pyx_est - Pyx_gt: 23494.65\n",
      "Geodesic error GT: 92.73, EST: 1646.21\n"
     ]
    }
   ],
   "source": [
    "import utils.fmap_util as fmap_util\n",
    "import metrics.geodist_metric as geodist_metric\n",
    "\n",
    "\n",
    "def compare_with_gt(Cxy_est, Cxy_gt, evecs_x, evecs_y, verts_x, verts_y, corr_x, corr_y):\n",
    "    \n",
    "    # hard correspondence \n",
    "    p2p_gt = fmap_util.fmap2pointmap(\n",
    "        torch.tensor(Cxy_gt),\n",
    "        torch.tensor(evecs_x),\n",
    "        torch.tensor(evecs_y)\n",
    "        )\n",
    "    p2p_est = fmap_util.fmap2pointmap(\n",
    "        torch.tensor(Cxy_est, dtype=torch.float32),\n",
    "        torch.tensor(evecs_x),\n",
    "        torch.tensor(evecs_y)\n",
    "        )\n",
    "    \n",
    "    # soft correspondence\n",
    "    Pyx_gt = evecs_y @ Cxy_gt @ evecs_trans_x\n",
    "    Pyx_est = evecs_y @ Cxy_est @ evecs_trans_x\n",
    "    \n",
    "    # distance matrices\n",
    "    dist_x = torch.cdist(verts_x, verts_x)\n",
    "    dist_y = torch.cdist(verts_y, verts_y)\n",
    "\n",
    "    # geodesic error\n",
    "    geo_err_gt = geodist_metric.calculate_geodesic_error(dist_x, corr_x, corr_y, p2p_gt, return_mean=False)    \n",
    "    geo_err_est = geodist_metric.calculate_geodesic_error(dist_x, corr_x, corr_y, p2p_est, return_mean=False)\n",
    "    \n",
    "    # print results\n",
    "    print(f'Cxy_est - Cxy_gt: {np.sum(np.abs(Cxy_est - Cxy_gt)):.2f}')\n",
    "    print(f'Pyx_est - Pyx_gt: {np.sum(np.abs(Pyx_est - Pyx_gt)):.2f}')\n",
    "    print(f'Geodesic error GT: {geo_err_gt.abs().sum():.2f}, EST: {geo_err_est.abs().sum():.2f}')\n",
    "    \n",
    "    \n",
    "print('------ Cxy_opt')\n",
    "compare_with_gt(\n",
    "    Cxy_opt,\n",
    "    Cxy_gt,\n",
    "    evecs_x,\n",
    "    evecs_y,\n",
    "    data_x['verts'],\n",
    "    data_y['verts'],\n",
    "    data_x['corr'],\n",
    "    data_y['corr']\n",
    "    )    \n",
    "    \n",
    "print('------ Cxy_opt_comm')\n",
    "compare_with_gt(\n",
    "    Cxy_opt_comm,\n",
    "    Cxy_gt,\n",
    "    evecs_x,\n",
    "    evecs_y,\n",
    "    data_x['verts'],\n",
    "    data_y['verts'],\n",
    "    data_x['corr'],\n",
    "    data_y['corr']\n",
    "    )\n",
    "\n",
    "print('\\n------ Cxy_lstsq')\n",
    "compare_with_gt(\n",
    "    Cxy_lstsq[:50, :50].numpy(),\n",
    "    Cxy_gt,\n",
    "    evecs_x,\n",
    "    evecs_y,\n",
    "    data_x['verts'],\n",
    "    data_y['verts'],\n",
    "    data_x['corr'],\n",
    "    data_y['corr']\n",
    "    )\n",
    "\n",
    "print('\\n------ Cxy_hks_lstsq')\n",
    "compare_with_gt(\n",
    "    Cxy_hks_lstsq[:50, :50].numpy(),\n",
    "    Cxy_gt,\n",
    "    evecs_x,\n",
    "    evecs_y,\n",
    "    data_x['verts'],\n",
    "    data_y['verts'],\n",
    "    data_x['corr'],\n",
    "    data_y['corr']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1, -1, -1],\n",
       "        [-1,  1, -1],\n",
       "        [ 1,  1, -1]]),\n",
       " array([[ 0. , -0.5,  0.5],\n",
       "        [-0.5,  0. ,  0.5],\n",
       "        [-0.5, -0.5, -0. ]]),\n",
       " array([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]]))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = np.array([\n",
    "    [1, -1, -1],\n",
    "    [-1, 1, -1],\n",
    "    [1, 1, -1]\n",
    "])\n",
    "mat_inv = np.linalg.inv(mat)\n",
    "\n",
    "mat, mat_inv, mat_inv @ mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

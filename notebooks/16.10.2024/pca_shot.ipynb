{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# models\n",
    "from my_code.models.diag_conditional import DiagConditionedUnet\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "import my_code.datasets.template_dataset as template_dataset\n",
    "\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "\n",
    "import networks.diffusion_network as diffusion_network\n",
    "import matplotlib.pyplot as plt\n",
    "import my_code.utils.plotting_utils as plotting_utils\n",
    "import utils.fmap_util as fmap_util\n",
    "import metrics.geodist_metric as geodist_metric\n",
    "from my_code.sign_canonicalization.training import predict_sign_change\n",
    "import argparse\n",
    "from pyFM_fork.pyFM.refine.zoomout import zoomout_refine\n",
    "import my_code.utils.zoomout_custom as zoomout_custom\n",
    "from utils.shape_util import compute_geodesic_distmat\n",
    "from my_code.diffusion_training_sign_corr.test.test_diffusion_cond import select_p2p_map_dirichlet, log_to_database, parse_args\n",
    "import accelerate\n",
    "import my_code.sign_canonicalization.test_sign_correction as test_sign_correction\n",
    "import networks.fmap_network as fmap_network\n",
    "from my_code.utils.median_p2p_map import dirichlet_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling and PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def apply_pca(input_data, title, pca_components=3, use_scaler=True, show_ratio=True, show_pairplot=True, color_by='body_type'):\n",
    "\n",
    "    if use_scaler:\n",
    "        scaler = StandardScaler()\n",
    "        input_data_scaled = scaler.fit_transform(input_data.reshape(input_data.shape[0], -1))\n",
    "    else:\n",
    "        input_data_scaled = input_data.reshape(input_data.shape[0], -1)\n",
    "        \n",
    "    pca = PCA(n_components=32)\n",
    "    input_data_pca = pca.fit_transform(input_data_scaled)\n",
    "\n",
    "\n",
    "    if show_ratio:\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(5, 4))\n",
    "\n",
    "        # plot explained variance\n",
    "        axs.plot(pca.explained_variance_ratio_, '.-')\n",
    "        axs.set_title(f'{title}: explained variance ratio')\n",
    "\n",
    "    if show_pairplot:\n",
    "        pca_df = pd.DataFrame(input_data_pca[:, :pca_components],\n",
    "                              columns=[f'PCA_{i}' for i in range(pca_components)])\n",
    "        # pca_df['name'] = names_y\n",
    "        \n",
    "        if color_by == 'body_type':\n",
    "            pca_df['color_by'] = [i // 10 for i in range(input_data_pca.shape[0])]\n",
    "        elif color_by == 'pose':\n",
    "            pca_df['color_by'] = [i % 10 for i in range(input_data_pca.shape[0])]\n",
    "        else:\n",
    "            raise ValueError(f'color_by={color_by} not supported')\n",
    "\n",
    "\n",
    "        # use numbers as markers\n",
    "        sns.pairplot(pca_df, diag_kind='kde', hue='color_by', palette='tab10')\n",
    "\n",
    "    if show_ratio or show_pairplot:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self):\n",
    "        self.experiment_name='single_template_remeshed'\n",
    "        self.checkpoint_name='checkpoint_99.pt'\n",
    "        \n",
    "        self.dataset_name='FAUST_orig'\n",
    "        self.split='train'\n",
    "        \n",
    "        self.num_iters_avg=64\n",
    "        self.num_samples_median=10\n",
    "        self.confidence_threshold=0.3\n",
    "        \n",
    "        self.smoothing_type=None\n",
    "        self.smoothing_iter=None\n",
    "        \n",
    "        self.zoomout_num_evecs_template=-1\n",
    "        \n",
    "        # self.reduced_dim=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# configuration\n",
    "experiment_name = args.experiment_name\n",
    "checkpoint_name = args.checkpoint_name\n",
    "\n",
    "### config\n",
    "exp_base_folder = f'/home/s94zalek_hpc/shape_matching/my_code/experiments/ddpm/{experiment_name}'\n",
    "with open(f'{exp_base_folder}/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "### Sign correction network\n",
    "sign_corr_net = diffusion_network.DiffusionNet(\n",
    "    **config[\"sign_net\"][\"net_params\"]\n",
    "    )        \n",
    "sign_corr_net.load_state_dict(torch.load(\n",
    "        f'{config[\"sign_net\"][\"net_path\"]}/{config[\"sign_net\"][\"n_iter\"]}.pth'\n",
    "        ))\n",
    "sign_corr_net.to(device)\n",
    "\n",
    "\n",
    "### test dataset\n",
    "dataset_name = args.dataset_name\n",
    "split = args.split\n",
    "\n",
    "single_dataset, test_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, split, 200, preload=False, return_evecs=True, centering='bbox',\n",
    "    )\n",
    "sign_corr_net.cache_dir = single_dataset.lb_cache_dir\n",
    "\n",
    "num_evecs = config[\"model_params\"][\"sample_size\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyshot\n",
    "\n",
    "\n",
    "Cxy_corr_list = []\n",
    "\n",
    "shot_list = []\n",
    "\n",
    "for i in tqdm(range((len(test_dataset))), desc='Calculating fmaps to template, evec signs'):\n",
    "\n",
    "    data = test_dataset[i]\n",
    "    \n",
    "    verts_first = data['first']['verts'].unsqueeze(0).to(device)\n",
    "    verts_second = data['second']['verts'].unsqueeze(0).to(device)\n",
    "    \n",
    "    faces_first = data['first']['faces'].unsqueeze(0).to(device)\n",
    "    faces_second = data['second']['faces'].unsqueeze(0).to(device)\n",
    "\n",
    "    evecs_first = data['first']['evecs'][:, :num_evecs].unsqueeze(0).to(device)\n",
    "    evecs_second = data['second']['evecs'][:, :num_evecs].unsqueeze(0).to(device)\n",
    "    \n",
    "    corr_first = data['first']['corr']\n",
    "    corr_second = data['second']['corr']\n",
    "    \n",
    "\n",
    "    if config[\"sign_net\"][\"with_mass\"]:\n",
    "        mass_mat_first = torch.diag_embed(\n",
    "            data['first']['mass'].unsqueeze(0)\n",
    "            ).to(device)\n",
    "        mass_mat_second = torch.diag_embed(\n",
    "            data['second']['mass'].unsqueeze(0)\n",
    "            ).to(device)\n",
    "    else:\n",
    "        mass_mat_first = None\n",
    "        mass_mat_second = None\n",
    "\n",
    "\n",
    "\n",
    "    # predict the sign change\n",
    "    with torch.no_grad():\n",
    "        sign_pred_first, support_vector_norm_first, _ = predict_sign_change(\n",
    "            sign_corr_net, verts_first, faces_first, evecs_first, \n",
    "            mass_mat=mass_mat_first, input_type=sign_corr_net.input_type,\n",
    "            evecs_per_support=config[\"sign_net\"][\"evecs_per_support\"],\n",
    "            \n",
    "            mass=data['first']['mass'].unsqueeze(0), L=data['first']['L'].unsqueeze(0),\n",
    "            evals=data['first']['evals'][:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "            evecs=data['first']['evecs'][:,:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "            gradX=data['first']['gradX'].unsqueeze(0), gradY=data['first']['gradY'].unsqueeze(0)\n",
    "            )\n",
    "        sign_pred_second, support_vector_norm_second, _ = predict_sign_change(\n",
    "            sign_corr_net, verts_second, faces_second, evecs_second, \n",
    "            mass_mat=mass_mat_second, input_type=sign_corr_net.input_type,\n",
    "            evecs_per_support=config[\"sign_net\"][\"evecs_per_support\"],\n",
    "            \n",
    "            mass=data['second']['mass'].unsqueeze(0), L=data['second']['L'].unsqueeze(0),\n",
    "            evals=data['second']['evals'][:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "            evecs=data['second']['evecs'][:,:config[\"sign_net\"][\"net_params\"][\"k_eig\"]].unsqueeze(0),\n",
    "            gradX=data['second']['gradX'].unsqueeze(0), gradY=data['second']['gradY'].unsqueeze(0)\n",
    "            )\n",
    "\n",
    "    # correct the evecs\n",
    "    evecs_first_corrected = evecs_first.cpu()[0] * torch.sign(sign_pred_first).cpu()\n",
    "    evecs_first_corrected_norm = evecs_first_corrected / torch.norm(evecs_first_corrected, dim=0, keepdim=True)\n",
    "    \n",
    "    evecs_second_corrected = evecs_second.cpu()[0] * torch.sign(sign_pred_second).cpu()\n",
    "    evecs_second_corrected_norm = evecs_second_corrected / torch.norm(evecs_second_corrected, dim=0, keepdim=True)\n",
    "        \n",
    "    # functional maps        \n",
    "    Cxy_corr = torch.linalg.lstsq(\n",
    "        evecs_second_corrected[corr_second].to(device),\n",
    "        evecs_first_corrected[corr_first].to(device),\n",
    "        ).solution.cpu()\n",
    "    \n",
    "    Cxy_corr_list.append(Cxy_corr)\n",
    "    \n",
    "    \n",
    "    # shot descriptors\n",
    "    shot_descrs_second = torch.tensor(pyshot.get_descriptors(\n",
    "        verts_second.cpu().numpy().astype(np.float64)[0],\n",
    "        faces_second.cpu().numpy().astype(np.int64)[0],\n",
    "        radius=100,\n",
    "        local_rf_radius=100,\n",
    "        # The following parameters are optional\n",
    "        min_neighbors=3,\n",
    "        n_bins=20,\n",
    "        double_volumes_sectors=True,\n",
    "        use_interpolation=True,\n",
    "        use_normalization=True,\n",
    "    ), dtype=torch.float32)\n",
    "    \n",
    "    # print(shot_descrs_second.shape)\n",
    "    \n",
    "    # given a [6890, 352] desriptor, group the descriptors into bins of 11, then take the average of the bin to get a [6890, 32] descriptor\n",
    "    \n",
    "    assert shot_descrs_second.shape[1] % 32 == 0\n",
    "    bin_size = shot_descrs_second.shape[1] // 32\n",
    "    \n",
    "    shot_descrs_second_grouped = []\n",
    "    for i in range(32):\n",
    "        shot_descrs_second_grouped.append(shot_descrs_second[:, i*bin_size:(i+1)*bin_size].mean(dim=1))\n",
    "    shot_descrs_second_grouped = torch.stack(shot_descrs_second_grouped, dim=1)\n",
    "    \n",
    "    # shot_descrs_second_grouped = shot_descrs_second.view(6890, -1, 32).mean(dim=1)\n",
    "    \n",
    "    # normalize the descriptors\n",
    "    shot_descrs_second_grouped = torch.nn.functional.normalize(shot_descrs_second_grouped, p=2, dim=0)\n",
    "    \n",
    "    # project them onto the support vectors\n",
    "    \n",
    "    shot_descrs_second_grouped_proj = shot_descrs_second_grouped.T.to(device) @ support_vector_norm_second[0]\n",
    "    \n",
    "    # print(shot_descrs_second_grouped_proj.shape)\n",
    "    \n",
    "    shot_list.append(shot_descrs_second_grouped_proj.cpu())\n",
    "    \n",
    "    \n",
    "    # break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "Cxy_corr = torch.stack(Cxy_corr_list, dim=0)\n",
    "shot_list = torch.stack(shot_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_descrs_second.shape[1] / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# shot 5 random images from shot_list\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "rand_idx = np.random.choice(len(shot_list), 5, replace=False)\n",
    "\n",
    "for i, idx in enumerate(rand_idx):\n",
    "    axs[i].imshow(shot_list[idx].numpy())\n",
    "    axs[i].set_title(f'{idx}')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_pca(Cxy_corr, 'Cxy_corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_pca(shot_list, 'shot_list', color_by='pose', pca_components=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "352 / 32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
